<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://blog.zerokirin.online</id>
    <title>Zer0kiriN</title>
    <updated>2021-04-08T19:40:43.145Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="http://blog.zerokirin.online"/>
    <link rel="self" href="http://blog.zerokirin.online/atom.xml"/>
    <subtitle>记录</subtitle>
    <logo>http://blog.zerokirin.online/images/avatar.png</logo>
    <icon>http://blog.zerokirin.online/favicon.ico</icon>
    <rights>All rights reserved 2021, Zer0kiriN</rights>
    <entry>
        <title type="html"><![CDATA[传输层]]></title>
        <id>http://blog.zerokirin.online/post/chuan-shu-ceng/</id>
        <link href="http://blog.zerokirin.online/post/chuan-shu-ceng/">
        </link>
        <updated>2021-04-08T19:16:02.000Z</updated>
        <content type="html"><![CDATA[<p>提供逻辑上<strong>进程间</strong>通信的功能，使应用看起来像是再两个传输层实体之间有一条端到端的逻辑通信信道</p>
<h2 id="主要协议-udp和tcp">主要协议 UDP和TCP</h2>
<ul>
<li>
<p>用户数据报协议 UDP（User Datagram Protocol）</p>
<p>是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。</p>
<p>常用于游戏，音视频流媒体等，对数据完整性要求不是很高，但是对实时性有比较高要求的传输</p>
</li>
<li>
<p>传输控制协议 TCP（Transmission Control Protocol）</p>
<p>是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。</p>
<p>由于有拥塞控制，流量控制，及时性必然不如UDP，但可靠</p>
</li>
</ul>
<h2 id="udpuser-datagram-protocol-用户数据报协议">UDP(User Datagram Protocol) 用户数据报协议</h2>
<figure data-type="image" tabindex="1"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>伪首部</p>
<p>从IP首部提取出源IP地址和目的IP地址，然后是0x00，然后是IP首部中协议字段的值，UDP是17，然后是UDP的长度，总共12字节。</p>
<p>伪首部仅用作校验和，仅在发送和接收的时候被临时拼出来，计算出校验和后就抛弃，将校验和填入首部</p>
</li>
<li>
<p>源端口（可选）</p>
<p>UDP是无序应答的，因此没有必要记住源端口</p>
</li>
<li>
<p>目的端口</p>
</li>
<li>
<p>长度</p>
<p>就是UDP长度，和伪首部中的一样，最小值是8字节，因为首部已经占了8字节了</p>
<p>由于IP数据包的最大值不能超过64K字节（只有两个字节用来标识长度，2^16= 64K），所以最大长度不能超过（65,535 − 8字节UDP报头 − 20字节）</p>
</li>
<li>
<p>校验和（可选）</p>
<p>若不需要则全部填充0</p>
</li>
<li>
<p>整体结构，图源维基百科</p>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://files.catbox.moe/glwzey.png" alt="整体结构" loading="lazy"></figure>
<h2 id="tcptransmission-control-protocol传输控制协议">TCP（Transmission Control Protocol）传输控制协议</h2>
<h3 id="tcp结构">TCP结构</h3>
<figure data-type="image" tabindex="3"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/55dc4e84-573d-4c13-a765-52ed1dd251f9.png" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>序号（sequence number）：为每一个字节都编上序号。这里的值代表本报文发送的数据的第一个字节的序号。例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。</p>
</li>
<li>
<p>确认号（acknowledgement number）：期望收到的下一个报文段的起始序号，也即已经收到的数据的字节长度加1。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。</p>
</li>
<li>
<p>数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。</p>
</li>
<li>
<p>保留字段：6bits，保留今后使用，目前置0处理。（但在RFC 3168和RFC 3540中增加了三个标识符，保留字段只剩3bits）</p>
</li>
<li>
<p>标识符</p>
<p>URG：紧急比特，1bit，当 URG=1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)<br>
ACK：确认比特，1bit，只有当 ACK=1时确认号字段才有效。当 ACK=0 时，确认号无效<br>
PSH：推送比特，1bit，接收方 TCP 收到推送比特置1的报文段，就尽快地交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付<br>
RST：复位比特，1bit，当RST=1时，表明TCP连接中出现严重差错(如由于主机崩溃或其他原因)，必须释放连接，然后再重新建立运输连接<br>
SYN：同步比特，1bit，同步比特 SYN 置为 1，就表示这是一个连接请求或连接接受报文<br>
FIN：终止比特，1bit，用来释放一个连接。当FIN=1 时，表明此报文段的发送端的数据已发送完毕，并要求释放运输连接</p>
</li>
<li>
<p>窗口（WIN）：窗口字段用来控制对方发送的数据量，单位为字节。TCP 连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上限。</p>
</li>
<li>
<p>校验和（checksum）：生成12字节的伪首部然后计算出来</p>
</li>
<li>
<p>紧急指针：紧急指针指出在本报文段中的紧急数据的最后一个字节的序号。</p>
</li>
<li>
<p>选项字段：最多40字节。每个选项的开始是1字节的kind字段，说明选项的类型。</p>
<ul>
<li>0：选项表结束（1字节）</li>
<li>1：无操作（1字节）用于选项字段之间的字边界对齐。</li>
<li>2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。</li>
<li>3：窗口扩大因子（3字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。</li>
<li>4：sackOK—发送端支持并同意使用SACK选项。</li>
<li>5：SACK实际工作的选项。</li>
<li>8：时间戳（10字节，TCP Timestamps Option，TSopt）
<ul>
<li>发送端的时间戳（Timestamp Value field，TSval，4字节）</li>
<li>时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="tcp连接过程">TCP连接过程</h3>
<h4 id="三次握手">三次握手</h4>
<figure data-type="image" tabindex="4"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt="img" loading="lazy"></figure>
<ul>
<li>首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。</li>
<li>A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个随机的初始序号 x。</li>
<li>B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个随机的初始序号 y。</li>
<li>A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。</li>
<li>B 收到 A 的确认后，连接建立。</li>
</ul>
<h4 id="为什么是三次挥手">为什么是三次挥手</h4>
<p>通俗但不是根本原因的解释：</p>
<blockquote>
<p>A--&gt;B--&gt;A--&gt;B这样传三次能保证A有发有收，B也有发有收。多一次浪费少一次不够。</p>
</blockquote>
<p>详细版本，来源于知乎问题下的回答<a href="https://www.zhihu.com/question/24853633">TCP 为什么是三次握手，而不是两次或四次？ - 知乎 (zhihu.com)</a>）：</p>
<blockquote>
<p>TCP可靠传输的精髓在于，由操作系统随机的选取两个32位长的初始序列号（Initial Sequence Number）</p>
<p>假设A的初始序列号为1000，以该序列号为原点对将要发送的每个字节编号，然后把自己的初始序列号（ISN）发送个B，<strong>让B有个心理准备</strong>，什么编号的数据才是合法的，<strong>可靠的</strong>，同时B还要对A的数据进行确认，如果A收到的确认号为2001，则证明字节编号1001-2000，一共1000个字节的数据已经被<strong>完整接受</strong></p>
<p>（三次握手的过程中，初始x为1000，B的确认码是x+1=1001，所以真正发送的数据的第一个编号是1001，等B收到数据后返回给A的确认码是2001，代表着期望收到2001数据，也就是说，2000以前的数据已经完整收到了）</p>
</blockquote>
<p>所以原因是为了让双方创建好初始号ISN，完整的流程应该是四步：</p>
<ol>
<li>
<p>A 发送同步信号<strong>SYN</strong> + <strong>A's Initial sequence number</strong></p>
<blockquote>
<p>A --&gt; B SYN my sequence number is X</p>
<p>第一次握手SYN为1，表示请你记录下我的ISN</p>
</blockquote>
</li>
<li>
<p>B 确认收到A的同步信号，并记录 A's ISN 到本地，命名 <strong>B's ACK sequence number</strong></p>
</li>
</ol>
<blockquote>
<p>A &lt;-- B ACK your sequence number is X</p>
<p>第二次握手ACK为1，表示收到了</p>
</blockquote>
<ol start="3">
<li>B发送同步信号<strong>SYN</strong> + <strong>B's Initial sequence number</strong></li>
</ol>
<blockquote>
<p>A &lt;-- B SYN my sequence number is Y</p>
<p>第三次握手SYN为1，表示也请你记录下我的ISN</p>
</blockquote>
<ol start="4">
<li>A确认收到B的同步信号，并记录 B's ISN 到本地，命名 <strong>A's ACK sequence number</strong></li>
</ol>
<blockquote>
<p>A --&gt; B ACK your sequence number is Y</p>
<p>第四次握手ACK为1，表示我也受到了你的ISN了，我要开始传数据了哦</p>
</blockquote>
<p>很显然2和3这两个步骤可以合并，**只需要三次握手，**可以提高连接的速度与效率</p>
<p>最最根本的原因就是，三次通信过程是能够确保可靠传输的理论最小值，所以三次握手不是TCP的要求，而是为了满足在IP这种不可靠通信上建立可靠通信</p>
<h4 id="三次握手中丢包了">三次握手中丢包了</h4>
<ol>
<li>
<p>第一个包，A--&gt;B的带有SYN的包没了</p>
<p>A会周期性超时重传，直到B的确认，毕竟是追女孩子，要勤快一点</p>
</li>
<li>
<p>第二个，B--&gt;A的带有ACK+SYN的包没了</p>
<p>B会周期性重传，直到A的确认，女孩子同意了，怎么男的不回消息了？？？不是你先撩我的？？？我再问问</p>
</li>
<li>
<p>第三个包，A--&gt;B带有ACK的包没了</p>
<p>A知道B同意了就变为了Established，但B很好奇A怎么什么反应都没有</p>
<ol>
<li>如果A倒头就睡了打算明天传数据，B就会一直重传问A到底啥情况（对于B来说和 2 情况一样）</li>
<li>如果A直接给B发送了数据，B会自动更改为Established状态并接受状态，原来大猪蹄子只是睡着了没发晚安，不是渣男</li>
<li>如果B要给A发数据是发不了的，毕竟我同意了你竟然一点反应都没有，老娘一肚子火怎么可能跟你说正事，还是会一直重传ACK+SYN，你给老娘个答复！</li>
</ol>
<p>到这一步A--&gt;B的ACK必须被B接受才行，这代表双方都承认了关系的建立</p>
</li>
</ol>
<h4 id="现实情况">现实情况</h4>
<p>客户端发送的请求如果在网络中滞留，那么客户端要很长一段时间才能收到服务端的反馈，客户端等待时间过长后会超时重传，但是这个请求最后还是会到达服务器，如果没有保存两个ISN，那么就无法确认数据包是传输中还是建立连接的包，那么就会打开两个连接。如果有三次握手，双方保存了ISN，则发现错误后直接抛弃就好。</p>
<h4 id="四次挥手">四次挥手</h4>
<figure data-type="image" tabindex="5"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt="img" loading="lazy"></figure>
<p>ack，seq自始至终的含义是相同的，无需解释，ACK咋建立连接后全都是1，无需分析</p>
<ul>
<li>
<p>A发送释放连接的报文，FIN=1</p>
</li>
<li>
<p>B收到后还可以继续向A发送数据，但A不能向B发送数据</p>
</li>
<li>
<p>当B决定终止时向A发送释放连接报文，FIN=1</p>
</li>
<li>
<p>A收到后发出确认，进入TIME-WAIT状态，等待2个MSL（Maximum Segment Lifetime）时长后释放连接</p>
</li>
<li>
<p>B收到A的确认后释放连接</p>
</li>
</ul>
<h4 id="time-wait">Time-Wait</h4>
<p>A收到B的FIN报文后不是直接close而是先进入TIME-WAIT状态，等待两个MSL的时间，原因有两个：</p>
<ul>
<li>如果最后一个A--&gt;B的包丢了，那么对于A来说，A时刻+1MSL时还没到达B，B就应该重传了，B重传的时长最多是1MSL，因此A最多等待2MSL就能收到B的重传报文，如果没收到那就证明B已经ok了</li>
<li>让本链接持续时间内所产生的所有报文都从网络消失掉，使下一个新的连接创建的时候不会出现旧的报文</li>
</ul>
<h3 id="tcp可靠传输">TCP可靠传输</h3>
<p>TCP使用重传来实现可靠传输：如果一个已经发送的报文在超时时间内没有收到确认报文，则重传报文</p>
<p>一个报文的往返时间为RTT（Round Trip Time） <code>RTTs=(1-a)*(RTTs)+a*RTT</code> （并未被广泛使用，后来发明了新的算法）a一般为0.8-0.9</p>
<p>超时重传的超时时间为RTO（Restransmission TimeOut）<code>RTO=RTTs+4*RTTd</code></p>
<ul>
<li>
<p>RTO不能小于RTT否则会大量的重传</p>
</li>
<li>
<p>RTO不能太大，否则延迟会变得很大</p>
</li>
<li>
<p>因此RTO应该略大于RTT</p>
</li>
</ul>
<blockquote>
<h5 id="jacobson-karels-算法">Jacobson / Karels 算法</h5>
<p>前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看<a href="http://tools.ietf.org/html/rfc6298">RFC6289</a>）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思）</p>
<p><strong>SRTT</strong> <strong>= S</strong> <strong>RTT</strong>  <strong>+ α</strong> <strong>(</strong> <strong>RTT</strong> <strong>– S</strong> <strong>RTT</strong> <strong>)</strong>  —— 计算平滑RTT</p>
<p><strong>DevRTT</strong> <strong>= (1-β</strong> *<em>)* ** <strong>DevRTT</strong> <strong>+ β</strong></em> <strong>(|</strong> <strong>RTT-SRTT</strong> <strong>|)</strong> ——计算平滑RTT和真实的差距（加权移动平均）</p>
<p><strong>RTO= µ * SRTT + ∂ *DevRTT</strong> —— 神一样的公式</p>
<p>（其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中（Linux的源代码在：<a href="http://lxr.free-electrons.com/source/net/ipv4/tcp_input.c?v=2.6.32#L609">tcp_rtt_estimator</a>）。</p>
<p>——来源<a href="https://coolshell.cn/articles/11609.html#Karn_Partridge_%E7%AE%97%E6%B3%95">TCP 的那些事儿（下） | 酷 壳 - CoolShell</a></p>
</blockquote>
<h3 id="tcp分段">TCP分段</h3>
<p>这里引入两个概念</p>
<ul>
<li>MTU（Maximum Transmission Unit）最大传输单元，以太网的MTU为1500字节，因此IP包只有1480</li>
<li>MSS（Maximum Segment Size）最大分段大小，这是一个TCP协议中的定义，MSS应该等于MTU-40，也就是1460，但若是双方未指定MSS大小的话，默认情况下MSS大小是536字节，这是因为 <a href="http://tools.ietf.org/html/rfc791">RFC 791</a>里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，网络中不只有以太网，还有很多其他连接方式，而576减去IP头的20个字节和TCP头的20个字节就是536）。</li>
</ul>
<p>为什么要主动引入MSS呢，看起来不是和MTU差不多吗？</p>
<p>其实是因为网络层数据包对IP包来说是透明的，像UDP没有引入MSS，且不会主动分段的话，直接交由IP封装的结果就是这样：</p>
<figure data-type="image" tabindex="6"><img src="https://files.catbox.moe/272t08.png" alt="UDP分段" loading="lazy"></figure>
<p>等接收方拿到第二个包的时候直接就扔了，也就是UDP不讲究。。。</p>
<p>但是对于可靠传输的TCP，这是完全不能忍受的，因此TCP会自己分段，保证自己发出的时候就不大于IP的MTU，别让IP帮我分</p>
<figure data-type="image" tabindex="7"><img src="https://files.catbox.moe/xkj8vx.png" alt="TCP分段" loading="lazy"></figure>
<p>这样第二个包也会被接收端正确解析</p>
<h3 id="tcp滑动窗口">TCP滑动窗口</h3>
<p>窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过TCP报文中的WIN字段告知发送方应该发送多大的数据，发送方收到报文后设置自己的窗口大小。</p>
<ul>
<li>
<p>发送窗口</p>
<p>发送窗口内的字节都允许被发送，如果发送窗口左边的字节已经发送并且收到了确认（ack），那么就讲发送窗口向右滑动一定距离，直到左边第一个没被确认的字节为止。</p>
</li>
<li>
<p>接收窗口</p>
<p>接收窗口内的字节都允许被接受，接收窗口只会对最后一个按序到达的字节进行确认，确认后向右滑动接收窗口。</p>
<p>例如：接收窗口已经收到了字节{31，34，35...}，其中{31}是按序到达的，因此只对31进行确认，同时向右滑动，当发送方接收到31的确认时，就知道31号之前的都已经被正确接受了</p>
</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" alt="img" loading="lazy"></figure>
<h4 id="zero-window">Zero Window</h4>
<p>如果某种原因导致接收端返回的确认报文中WIN=0，那么发送端就不会发送数据了，等到接收方的WIN腾出来了应该怎么告诉发送端呢？</p>
<p>这就是ZWP（Zero Window Probe），发送端在窗口变为0后会发送ZWP包给接收方，让接收方来重新设置WIN大小，具体重传次数和间隔看实现方案。如果多次仍为0，就可以直接RST</p>
<h4 id="silly-window-syndrome">Silly Window Syndrome</h4>
<p>翻译成中文就是“愚蠢窗口综合征”，其实也就是TCP的流量控制部分。如果接收方繁忙，每次都只能腾出一两个字节的WIN，但发送方仍会义无反顾地发送数据，但这样很浪费空间，一两个字节要经过TCP包，IP包的封装，仅仅是报文头部就最少有40个字节</p>
<p>一次传输肯定是越接近MTU最好，这样对带宽的利用率最大，不会浪费，因此为了避免数据包太小，那就憋着，等窗口够大了再发送数据，类似于大巴车等人满了再发车一个道理。发送方和接收方都有解决办法：</p>
<ul>
<li>
<p>接收端：</p>
<p>使用David D Clark’s方案。如果收到的数据或者自己处理太慢了，导致WIN小于某个值，就直接窗口0，啥也别发了，等缓过来，<strong>数据大于等于MSS，或者接受buffer腾出一半空间了再设置正常的窗口大小</strong>就好</p>
</li>
<li>
<p>发送端：</p>
<p>使用著名的<a href="https://zh.wikipedia.org/wiki/%E7%B4%8D%E6%A0%BC%E7%AE%97%E6%B3%95">纳格算法</a>，本质思路也是延迟等待。</p>
<pre><code> if有新資料要傳送
   if訊窗大小&gt;= MSS and可傳送的資料&gt;= MSS
     立刻傳送完整MSS大小的segment
   else
    if管線中有尚未確認的資料
      在下一個確認（ACK）封包收到前，將資料排進緩衝區佇列
    else
      立即傳送資料  
</code></pre>
<p>有两个条件：</p>
<ul>
<li>窗口大小&gt;=MSS 且 数据大小&gt;=MSS，立刻发送数据段（Segment）</li>
<li>收到了之前发送的未确认数据的ACK回包，立刻发送数据</li>
</ul>
<p>不过要注意，纳格算法不能和<a href="https://zh.wikipedia.org/wiki/TCP%E5%BB%B6%E8%BF%9F%E7%A1%AE%E8%AE%A4">TCP延迟确认</a>同时开启，TCP延迟确认是将多个ACK回包合并成一个，节约利用资源（毕竟首部太大了），当两者同时开启的时候，一个憋着ACK不放，一个ACK不来不发，两人活生生就憋死了。</p>
<p>另外，纳格算法是默认打开的，但是对于SSH，telnet这种交互性程序，发送的都是小包，就需要主动关闭纳格算法。</p>
</li>
</ul>
<h3 id="tcp拥塞控制">TCP拥塞控制</h3>
<p>主要有四个阶段：</p>
<ol>
<li>慢启动（slow start）</li>
<li>拥塞避免（Congestion Avoidance）</li>
<li>拥塞发生</li>
<li>快速恢复（Fast Recovery）</li>
</ol>
<figure data-type="image" tabindex="9"><img src="https://segmentfault.com/img/remote/1460000023924957" alt="img" loading="lazy"></figure>
<h4 id="慢启动">慢启动</h4>
<ol>
<li>连接建立好后初始化一个cwnd（congestion window）=1，表示可以传输一个MSS大小的数据</li>
<li>每当收到一个ACK，cwnd++；线性上升（其实是指数增长）</li>
<li>2的结果是，每当过了一个RTT后，cwnd会刚好变为cwnd*2，因为第一次是一个ACK，所以增加一次，第二次是两个ACK所以增加两次</li>
<li>还有一个ssthresh（slow start threshold）慢启动阈值，<strong>cwnd&gt;=ssthresh后会进入拥塞避免阶段</strong></li>
</ol>
<h4 id="拥塞避免">拥塞避免</h4>
<ol>
<li>收到一个ACK时，cwnd = cwnd+1/cwnd；（其实是线性增长）</li>
<li>1的结果是，每当过了一个RTT后，cwnd =cwnd+1；因为cwnd正好等于可以发送的MSS数量大小，因此ACK的数量就等于cwnd</li>
</ol>
<h4 id="拥塞发生">拥塞发生</h4>
<p>当丢包的时候，有两种方法</p>
<ul>
<li>超时重传，也就是超过RTO的时长就重传，同时进行拥塞控制
<ol>
<li>sshthresh = cwnd/2</li>
<li>cwnd重置为1</li>
<li>进入慢启动过程</li>
</ol>
</li>
<li>快重传（Fast Retransmit），收到三个重复的ACK时就重传，无需等到RTO超时
<ul>
<li>TCP Tahoe：方法和超时一样</li>
<li>TCP Reno：
<ol>
<li>cwnd = cwnd/2</li>
<li>sshthresh = cwnd</li>
<li>进入快速恢复算法</li>
</ol>
</li>
</ul>
</li>
</ul>
<h4 id="快速恢复">快速恢复</h4>
<p>TCP Reno中定义的快速恢复算法是这样的：</p>
<ol>
<li>cwnd = sshthresh +3（意思是确认有三个数据包收到了）</li>
<li>重传这个重复的ACK指定的数据包</li>
<li>如果还是收到那个重复的ACK，cwnd = cwnd+1</li>
<li>如果收到了新的ACK，那么cwnd = sshthresh</li>
<li>进入拥塞避免状态</li>
</ol>
<p>然而如果不止重复ACK丢失的话，仅仅重传重复ACK，其他的还是会触发RTO超时重传，但是目前所说的所有方法都没办法知道到底是丢了几个数据包，除非使用SACK字段，但这需要通信双方都支持，基于SACK也有新的FACK算法进行拥塞控制，但若是不支持SACK就没办法了，因此提出了一个新的 TCP New Reno</p>
<ol>
<li>
<p>重传重复的数据包，根据返回的ack和已经发送的seq+长度进行对比，就可以推理出是否有其他包丢失</p>
<p>比如说发送方的seq = 1，长度20，正确的ack应该是21，如果此时收到了三个ack=5，如果说只有5号丢了，那第5号数据发送过去后返回的ack应该时21，如果返回是11，则证明11也丢了，甚至时12，13等等</p>
</li>
<li>
<p>与正确的ack不匹配的被称作Partial ACK，当发送方接收到Partial ACK后会一直重传没有被ack的第一个包，直到再也收不到Partial ACK，结束了快速恢复状态</p>
</li>
<li>
<p>进入拥塞避免阶段</p>
</li>
</ol>
<blockquote>
<p>本文大量引用他人文章，仅作个人笔记使用<br>
[CS-Notes (gitee.io)](http://cyc2018.gitee.io/cs-notes/#/notes/计算机网络 - 传输层)<br>
<a href="https://coolshell.cn/articles/11609.html#TCP%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3">TCP 的那些事儿（下） | 酷 壳 - CoolShell</a><br>
<a href="https://segmentfault.com/a/1190000023924934">万字长文 | 23 个问题 TCP 疑难杂症全解析 - SegmentFault 思否</a><br>
<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E7%8A%B6%E6%80%81%E7%BC%96%E7%A0%81">传输控制协议 - 维基百科，自由的百科全书 (wikipedia.org)</a><br>
<a href="https://draveness.me/whys-the-design-tcp-segment-ip-packet/">为什么 TCP/IP 协议会拆分数据 - 面向信仰编程 (draveness.me)</a></p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[网络层]]></title>
        <id>http://blog.zerokirin.online/post/wang-luo-ceng/</id>
        <link href="http://blog.zerokirin.online/post/wang-luo-ceng/">
        </link>
        <updated>2021-04-01T09:06:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="ip协议internet-protocol">IP协议（Internet Protocol）</h2>
<h3 id="数据报格式">数据报格式</h3>
<figure data-type="image" tabindex="1"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>版本：ipv4和ipv6</p>
</li>
<li>
<p>首部长度：一共4位，最多只有15，单位是4字节大小，数据报固定首部长度有20个字节，因此首部长度最短为5</p>
</li>
<li>
<p>区分服务：一般不使用</p>
</li>
<li>
<p>总长度：定义了报文的总长度，单位是字节，最短为固定首部长度（20）</p>
</li>
<li>
<p>标识：唯一的标识一个报文的所有分片，因为分片不一定按顺序到达，重组的时候需要知道顺序</p>
</li>
<li>
<p>标志：三个bit分别用于：</p>
<ul>
<li>位0：保留，必须为0；</li>
<li>位1：禁止分片（Don’t Fragment，DF），当DF=0时才允许分片；</li>
<li>位2：更多分片（More Fragment，MF），MF=1代表后面还有分片，MF=0 代表已经是最后一个分片。</li>
</ul>
<p>如果DF标志被设置为1，但路由要求必须分片报文，此报文会被丢弃。这个标志可被用于发往没有能力组装分片的主机。</p>
</li>
<li>
<p>片偏移：单位为8字节，当有分片时，指示该分片相对于报文起始地址的偏移量（对于最后一个分片的报文，由于片偏移不为零，尽管MF字段是0，依然能够确定这是个分片的数据包，而不是不分片数据包(MF=0)）</p>
<figure data-type="image" tabindex="2"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23ba890e-e11c-45e2-a20c-64d217f83430.png" alt="img" loading="lazy"></figure>
</li>
<li>
<p>生存时间：定义的是该数据包在互联网中存在的时长，以秒为单位，但后来被用作了跳数计算器，每经历一次转发就将该字段减一，当字段为0时，不在向下跳转，最大值255</p>
</li>
<li>
<p>协议：指出数据应该交给哪个协议进行处理，例如ICMP，TCP，UDP</p>
</li>
<li>
<p>首部校验和：只检查首部，每一跳都要重新计算（最起码TTL发生了改变，偏移量和标志位也有可能变化），然后对比，不相同就丢弃</p>
</li>
<li>
<p>源地址、目标地址：一共32位</p>
</li>
<li>
<p>可选字段：不常用，1-40字节不等，参考维基百科上的表格</p>
<table>
<thead>
<tr>
<th style="text-align:center">字段</th>
<th style="text-align:center">长度（位）</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>备份</strong></td>
<td style="text-align:center">1</td>
<td style="text-align:center">当此选项需要被备份到所有分片中时，设为1。</td>
</tr>
<tr>
<td style="text-align:center"><strong>类</strong></td>
<td style="text-align:center">2</td>
<td style="text-align:center">常规的选项类别，0为“控制”，2为“查错和措施”，1和3保留。</td>
</tr>
<tr>
<td style="text-align:center"><strong>数字</strong></td>
<td style="text-align:center">5</td>
<td style="text-align:center">指明一个选项。</td>
</tr>
<tr>
<td style="text-align:center"><strong>长度</strong></td>
<td style="text-align:center">8</td>
<td style="text-align:center">指明整个选项的长度，对于简单的选项此字段可能不存在。</td>
</tr>
<tr>
<td style="text-align:center"><strong>数据</strong></td>
<td style="text-align:center">可变</td>
<td style="text-align:center">选项相关数据，对于简单的选项此字段可能不存在。</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>填充：记得最上面的首部长度吗，当有可选字段的时候，首部长度就一定大于20字节了，而首部长度的单位是4字节，因此当可选字段不是4的整数倍的时候，需要填充为EOL（选项列表结束，0x00）</p>
</li>
</ul>
<h2 id="ip地址编址方式">IP地址编址方式</h2>
<p>IP 地址的编址方式经历了三个历史阶段：</p>
<ul>
<li>分类</li>
<li>子网划分</li>
<li>无分类</li>
</ul>
<h3 id="分类">分类</h3>
<p>由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。</p>
<p>IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;}</p>
<figure data-type="image" tabindex="3"><img src="https://pic3.zhimg.com/80/v2-13c1daebb7b5706a847f4e727d9dacde_720w.jpg" alt="img" loading="lazy"></figure>
<h3 id="子网划分">子网划分</h3>
<p>可以看出，两级 IP 地址 不够灵活, 对 IP 地址空间的利用率比较低。如, C 类地址的局域网最多分配 254 个主机号, B 类地址的局域网最多分配 65534 个主机号。如果有个单位有 255 台主机，则只能为其分配一个 B 类地址的 网络号。这样就会浪费很多 IP 地址。</p>
<p>通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。</p>
<p>IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;}</p>
<p>要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。</p>
<p>注意，外部网络看不到子网的存在。</p>
<h3 id="无分类">无分类</h3>
<p>无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。</p>
<p>IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;}</p>
<p>CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。</p>
<p>一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为超网 。</p>
<p>在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。</p>
<h3 id="网络地址和广播地址">网络地址和广播地址</h3>
<p>其实就是特殊的主机地址，由于IP = 网络号+主机号</p>
<ul>
<li>主机号全为0的时候就是网络地址</li>
<li>全为1的时候就是广播地址</li>
</ul>
<h4 id="举例">举例：</h4>
<p>一个主机的IP地址是202.112.14.137，掩码是255.255.255.224，要求计算这个主机所在网络的网络地址和广播地址</p>
<p><code>255.255.255.224</code> 转二进制：</p>
<pre><code>11111111 11111111 11111111 11100000
</code></pre>
<p>则IP地址的前27位是网络号，后5位是主机号</p>
<p><code>202.112.14.137</code>转二进制：</p>
<table>
<thead>
<tr>
<th>11001010 01110000 00001110 100</th>
<th>01001</th>
</tr>
</thead>
<tbody>
<tr>
<td>网络号</td>
<td>主机号</td>
</tr>
</tbody>
</table>
<p>广播地址是<code>11001010 01110000 00001110 100</code> <code>11111</code> 即<code>202.112.14.159</code></p>
<p>网络地址是<code>11001010 01110000 00001110 100</code> <code>00000</code> 即<code>202.112.14.128</code></p>
<h2 id="地址解析协议arpaddress-resolution-protocol">地址解析协议ARP（Address Resolution Protocol）</h2>
<p>将IP地址转换为MAC地址的协议</p>
<p>每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。</p>
<p>如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。</p>
<figure data-type="image" tabindex="4"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/8006a450-6c2f-498c-a928-c927f758b1d0.png" alt="img" loading="lazy"></figure>
<p>维基百科中说的更详细一些</p>
<blockquote>
<p>1.当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可。</p>
<p>2.如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个广播（ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？”</p>
<p>3.网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是00-BB-00-62-C2-02”，此回应以单播方式。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP高速缓存（ARP cache），下次再向主机B发送信息时，直接从ARP缓存表里查找就可。</p>
</blockquote>
<h2 id="网际控制报文协议icmpinternet-control-message-protocol">网际控制报文协议ICMP（Internet Control Message Protocol）</h2>
<blockquote>
<p>它用于网际协议（IP）中发送控制消息，提供可能发生在通信环境中的各种问题反馈。通过这些信息，使管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。</p>
<p>——维基百科</p>
</blockquote>
<p>ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。</p>
<figure data-type="image" tabindex="5"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e3124763-f75e-46c3-ba82-341e6c98d862.jpg" alt="img" loading="lazy"></figure>
<p>ICMP 报文分为差错报告报文和询问报文。</p>
<figure data-type="image" tabindex="6"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png" alt="img" loading="lazy"></figure>
<h3 id="常见应用">常见应用</h3>
<ul>
<li>
<p>Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。</p>
<p>Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。</p>
</li>
<li>
<p>Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。</p>
<ul>
<li>源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文；</li>
<li>源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。</li>
<li>不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。</li>
<li>之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。</li>
</ul>
</li>
</ul>
<h2 id="路由器的结构">路由器的结构</h2>
<p>路由器从功能上可以划分为：路由选择和分组转发。</p>
<p>分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。</p>
<figure data-type="image" tabindex="7"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/c3369072-c740-43b0-b276-202bd1d3960d.jpg" alt="img" loading="lazy"></figure>
<h3 id="路由转发流程">路由转发流程</h3>
<figure data-type="image" tabindex="8"><img src="https://files.catbox.moe/21o038.png" alt="路由转发" loading="lazy"></figure>
<ul>
<li>
<p>提取出目的主机的IP地址D，然后得到网络地址N</p>
</li>
<li>
<p>若N是此路由器直接连着的地址，直接解析，否则就是间接交付</p>
</li>
<li>
<p>间接交付</p>
<ul>
<li>若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；</li>
<li>若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；</li>
<li>若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="9"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/1ab49e39-012b-4383-8284-26570987e3c4.jpg" alt="img" loading="lazy"></figure>
<h2 id="路由选择协议">路由选择协议</h2>
<p>用于调整路由表的可以把路由选择协议划分为两大类：</p>
<ul>
<li>自治系统内部的路由选择：RIP 和 OSPF</li>
<li>自治系统间的路由选择：BGP</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GMP模型简介]]></title>
        <id>http://blog.zerokirin.online/post/gmp-mo-xing-jian-jie/</id>
        <link href="http://blog.zerokirin.online/post/gmp-mo-xing-jian-jie/">
        </link>
        <updated>2021-03-21T09:53:13.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>[<a href="https://learnku.com/articles/41728">典藏版] Golang 调度器 GMP 原理与调度全分析 | Go 技术论坛 (learnku.com)</a></p>
<p>大量文字和图片来源于上文，以下仅为个人理解转述，仅作笔记使用</p>
</blockquote>
<h2 id="进程线程">进程&amp;线程</h2>
<ul>
<li>
<p>根本区别：</p>
<ul>
<li>进程是操作系统资源分配的基本单位</li>
<li>线程是处理器<strong>任务调度和执行的基本单位</strong></li>
</ul>
</li>
<li>
<p>资源开销：</p>
<ul>
<li>每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销</li>
<li>线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小</li>
</ul>
</li>
<li>
<p>包含关系：</p>
<ul>
<li>线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。</li>
</ul>
</li>
<li>
<p>内存分配：</p>
<ul>
<li>同一进程的线程共享本进程的地址空间和资源</li>
<li>而进程之间的地址空间和资源是相互独立的</li>
</ul>
</li>
<li>
<p>影响关系：</p>
<ul>
<li>一个进程崩溃后，在保护模式下不会对其他进程产生影响</li>
<li>一个线程崩溃整个进程都死掉，所以多进程要比多线程健壮</li>
</ul>
</li>
</ul>
<h2 id="内核态用户态">内核态&amp;用户态</h2>
<p>简单的说，用户的应用程序运行在用户态，内核程序运行在内核态，<strong>任何资源调度都需要进入内核态执行</strong></p>
<p>详细一点，以32位linux操作系统为例，2^32 = 4G，所以每个进程最多可以访问4G的内存空间（虚拟内存），操作系统将高地址的1G空间分配给了内核态，低地址的3G分配给用户态，又由于内核操作是唯一的，不随用户程序的不同而改变，因此可以说内核态的空间是所有进程共享的，而用户态的空间属于进程独有（实际上大家都是访问的虚拟地址，只不过对于内核态的代码始终映射到了同一空间，用户态就完全随机了）</p>
<p>再详细一点，intel提供了R0-R3一共四个等级的权限，而linux使用了R0和R3两个等级作为区分，R3最低，应用程序运行在3级的时候就是用户态，运行在0级的时候就是内核态，用户态到内核态一共有三种转换方式：</p>
<ul>
<li>
<p>系统调用（主动）</p>
<ul>
<li>使用系统提供的服务，比如请求键盘输入，这时会从用户态切换到内核态，因为用户态的程序无法调用系统资源，任何资源调用都是由内核态程序完成的</li>
<li>本质就是用户程序向系统发出了一个中断信号<code>int 80h</code>，通过中断信号告诉操作系统来将应用程序调入内核态</li>
</ul>
</li>
<li>
<p>异常（被动）</p>
<ul>
<li>当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li>
</ul>
</li>
<li>
<p>外围设备中断（被动）</p>
<ul>
<li>当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li>
</ul>
</li>
</ul>
<h2 id="协程">协程</h2>
<h3 id="线程的优缺点">线程的优缺点</h3>
<ul>
<li>
<p>缺点</p>
<ul>
<li>即便他的资源依赖进程，上下文切换的时候无需切换内存空间，但上文提到过，线程是操作系统任务调度的最小资源，也就意味着线程的切换仍然是内核操作，<strong>这就会使应用程序频繁的处于用户态内核态的切换中</strong>，这中间无疑是对cpu的浪费</li>
<li>创建一个线程需要8MB大小的空间（ubuntu18.04默认的线程栈大小），一千个线程就是8g的空间，非常夸张</li>
</ul>
</li>
<li>
<p>优点</p>
<ul>
<li>系统调度的最小单元，意味着它是<strong>真正的并行执行</strong>，可以同时运行在多个不同的cpu核心上</li>
</ul>
</li>
</ul>
<h3 id="协程的概念">协程的概念</h3>
<p>根据上文可以看到多线程模型在运算效率上很高，因为它可以充分利用多核优势，但是每次线程的切换都需要内核介入，就导致在某些场景下大量的资源被浪费在程序状态的转换上，有没有可能让内核不介入线程的切换呢？</p>
<p>协程应运而生，也可以说它是用户态的线程，将线程调度这一概念放到了用户态去做，让用户态的程序自己控制调度程序，避免频繁切换。</p>
<p>协程的执行则是通过绑定到不同的线程去执行，因为只有线程才是执行的最小单位，因此<strong>怎么将线程和协程绑定能最大化利用资源则是重中之重</strong></p>
<figure data-type="image" tabindex="1"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/ANDQLx3g9U.png!large" alt="协程" loading="lazy"></figure>
<p>golang中通过提出了goroutine来实现协程这个概念，用go scheduler在用户态做调度。</p>
<p>协程和线程主要区别：</p>
<ul>
<li>线程是由操作系统调度的，是抢占式的</li>
<li>协程是协作式的，执行完毕由调度器控制自动让出资源</li>
<li>协程说到底还是绑定到线程执行的，因此绑定到同一个线程下的协程只能是串行，无法做到并行处理</li>
</ul>
<h2 id="gmp模型">GMP模型</h2>
<p>提出三个概念</p>
<figure data-type="image" tabindex="2"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/zaZ4nQYcZe.png!large" alt="GMP" loading="lazy"></figure>
<ul>
<li>G goroutine 协程</li>
<li>M thread 线程</li>
<li>P processor <strong>它包含了运行 goroutine 的资源</strong>，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/Ugu3C2WSpM.jpeg!large" alt="GMP" loading="lazy"></figure>
<p><s>（这图做的是真好，一目了然，都不需要讲什么了）</s></p>
<h5 id="p的数量">P的数量</h5>
<p>通过<code>GOMAXPROCS</code>这个变量来控制整个程序中P的数量，这是在调度器初始化的时候就确定好的，P不随程序运行改变，默认值是cpu核心数，因为整个模型中，P通过绑定M去执行操作，而M也就是线程，最多可以并行执行的数量就是cpu核心数，因此这样可以最大化利用资源，减少浪费</p>
<h5 id="m的数量">M的数量</h5>
<p>由于每个P都必须绑定一个M，通过绑定的M去执行P上的G，因此M的数量至少等于P（休眠状态另算）</p>
<p>当M被阻塞时，P上的G就无法继续执行，此时就会创造一个新的M，因此通常来说M的数量要大于P</p>
<h3 id="调度器初始化的过程">调度器初始化的过程</h3>
<figure data-type="image" tabindex="4"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/j37FX8nek9.png!large" alt="调度器初始化" loading="lazy"></figure>
<p>特殊的 M0 和 G0</p>
<h5 id="m0">M0</h5>
<p>M0 是启动程序后的编号为 0 的主线程，相当于程序的起点，企业的创始人，在这里初始化了调度器，然后启动第一个G（也就是主函数main），在这后M0就和其他的M一样了，从创始人沦为打工仔</p>
<h5 id="g0">G0</h5>
<p>G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，相当于一个总经理把任务G指派给M执行，G0 不指向任何可执行的函数，他自己不干活，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。</p>
<h3 id="一个程序运行的全过程">一个程序运行的全过程</h3>
<ol>
<li>runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。</li>
<li>调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。</li>
<li>示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。</li>
<li>启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。</li>
<li>G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境</li>
<li>M 运行 G</li>
<li>G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。</li>
</ol>
<h3 id="一个goroutine的执行顺序">一个goroutine的执行顺序</h3>
<figure data-type="image" tabindex="5"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/a4vWtvRWGQ.jpeg!large" alt="调度执行顺序" loading="lazy"></figure>
<p>从上图我们可以分析出几个结论：</p>
<ol>
<li>有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；</li>
<li>G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；</li>
<li>一个 M 调度 G 执行的过程是一个循环机制；</li>
<li>当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；</li>
<li>当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，<strong>然后这个 G 会被放入全局队列中</strong>。</li>
</ol>
<h2 id="完整的调度过程全解析">完整的调度过程全解析</h2>
<p><s>（这图画的真的绝了，看图说话吧）</s></p>
<ol>
<li>
<p>P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 <code>go func()</code> 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。</p>
<figure data-type="image" tabindex="6"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/Pm8LOYcsWQ.png!large" alt="1" loading="lazy"></figure>
</li>
<li>
<p>G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2（偷取其他队列的G直到没有G），从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。</p>
<figure data-type="image" tabindex="7"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/JWDtmKG3rK.png!large" alt="2" loading="lazy"></figure>
</li>
<li>
<p>假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。</p>
<figure data-type="image" tabindex="8"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/UpjRxzIBd3.png!large" alt="3" loading="lazy"></figure>
</li>
<li>
<p>G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行<strong>负载均衡</strong> (把 P1 中本地队列中前一半的 G，还有新创建 G <strong>转移</strong>到全局队列)</p>
<p>这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。</p>
<figure data-type="image" tabindex="9"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/chqTgsiuWi.png!large" alt="4" loading="lazy"></figure>
</li>
<li>
<p>G2 创建 G8 时，P1 的本地队列未满（挪走了前一半去全局了），所以 G8 会被加入到 P1 的本地队列。</p>
<figure data-type="image" tabindex="10"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/nukEY92G6D.png!large" alt="5" loading="lazy"></figure>
</li>
<li>
<p>规定：<strong>在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行</strong>。</p>
<p>假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程**（没有 G 但为运行状态的线程，不断寻找 G）**。</p>
<figure data-type="image" tabindex="11"><img src="https://cdn.learnku.com/uploads/images/202003/11/58489/2FWNXSuHfX.png!large" alt="6" loading="lazy"></figure>
</li>
<li>
<p>M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：<code>findrunnable()</code>）。M2 从全局队列取的 G 数量符合下面的公式：</p>
<pre><code class="language-go">n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))
</code></pre>
<p>从全局队列取出差不多平均给每个M-P的数量的G，，不要拿太多，给其他M-P留一些</p>
<figure data-type="image" tabindex="12"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/0fn8DGqI8N.jpeg!large" alt="7" loading="lazy"></figure>
<p>假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。</p>
</li>
<li>
<p>假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。</p>
<p>全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：<strong>从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列</strong>。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。</p>
<figure data-type="image" tabindex="13"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/qn1NRMLqnp.png!large" alt="8" loading="lazy"></figure>
</li>
<li>
<p>G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。</p>
<figure data-type="image" tabindex="14"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/1DjlseEGTT.png!large" alt="9" loading="lazy"></figure>
<p>为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 <code>GOMAXPROCS</code> 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。</p>
</li>
<li>
<p>假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M&gt;=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断：</p>
<ul>
<li>如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定</li>
<li>否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。</li>
</ul>
<p>本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。</p>
<figure data-type="image" tabindex="15"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/k3HKE9U21M.png!large" alt="10" loading="lazy"></figure>
</li>
<li>
<p>G8 创建了 G9，假如 G8 进行了<strong>非阻塞系统调用</strong>。</p>
<figure data-type="image" tabindex="16"><img src="https://cdn.learnku.com/uploads/images/202003/12/58489/zBvpl8ENSb.png!large" alt="11" loading="lazy"></figure>
<p>M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[go语法基础巩固（channel）]]></title>
        <id>http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-channel/</id>
        <link href="http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-channel/">
        </link>
        <updated>2021-03-20T21:37:01.000Z</updated>
        <content type="html"><![CDATA[<h2 id="channel分为有缓冲和无缓冲">channel分为有缓冲和无缓冲</h2>
<p>channel有两种定义方式</p>
<pre><code class="language-go">var c1 = make(chan int) //无缓冲
var c2 = make(chan int,n) //有缓冲
close(c2)
</code></pre>
<ul>
<li>对无缓冲的c1的操作是同步的
<ul>
<li>必须同时存在接收者和发送者才会执行，否则会阻塞</li>
</ul>
</li>
<li>对有缓冲的c2是存在异步操作的
<ul>
<li>缓冲区满了则无法继续写入，进入阻塞，未满之前不阻塞程序</li>
<li>缓冲区空了则无法读取，进入阻塞，没有空之前不阻塞</li>
</ul>
</li>
</ul>
<h2 id="close关闭一个channel">close关闭一个channel</h2>
<ul>
<li>不能对一个关闭了的，或者本来就未通过make()初始化的channel执行关闭操作，会panic</li>
<li>关闭channel在某种角度上讲只是不允许继续写入，对于已经存入缓冲的数据还是可以读取的</li>
</ul>
<pre><code class="language-go">func main() {
	c1 := make(chan int, 5)
	for i := 0; i &lt; 5; i++ {
		c1 &lt;- i
	}
	close(c1)
	for i := 0; i &lt; 6; i++ {
		m, ok := &lt;-c1
		fmt.Println(m, ok)
	}
}
//结果：
//0 true
//1 true
//2 true
//3 true
//4 true
//0 false， 只有到这一步才因为没有数据而返回了默认的零值
</code></pre>
<p>总结一下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作\对象</th>
<th style="text-align:center">nil channel</th>
<th style="text-align:center">closed channel</th>
<th style="text-align:center">not nil, not closed channel</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">close</td>
<td style="text-align:center">panic</td>
<td style="text-align:center">panic</td>
<td style="text-align:center">正常关闭</td>
</tr>
<tr>
<td style="text-align:center">读 &lt;- ch</td>
<td style="text-align:center">阻塞</td>
<td style="text-align:center">读到对应类型的零值</td>
<td style="text-align:center">阻塞或正常读取数据。缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞</td>
</tr>
<tr>
<td style="text-align:center">写 ch &lt;-</td>
<td style="text-align:center">阻塞</td>
<td style="text-align:center">panic</td>
<td style="text-align:center">阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞</td>
</tr>
</tbody>
</table>
<h2 id="channel的实现原理">channel的实现原理</h2>
<blockquote>
<p><a href="https://segmentfault.com/a/1190000019839546">深度解密Go语言之channel - SegmentFault 思否</a></p>
</blockquote>
<p>以下内容均为个人转述总结，仅作笔记使用，参考出处如上</p>
<h3 id="channel结构">channel结构</h3>
<pre><code class="language-go">type hchan struct {
    // chan 里元素数量
    qcount   uint
    // chan 底层循环数组的长度
    dataqsiz uint
    // 指向底层循环数组的指针
    // 只针对有缓冲的 channel
    buf      unsafe.Pointer
    // chan 中元素大小
    elemsize uint16
    // chan 是否被关闭的标志
    closed   uint32
    // chan 中元素类型
    elemtype *_type // element type
    // 已发送元素在循环数组中的索引
    sendx    uint   // send index
    // 已接收元素在循环数组中的索引
    recvx    uint   // receive index
    // 等待接收的 goroutine 队列
    recvq    waitq  // list of recv waiters
    // 等待发送的 goroutine 队列
    sendq    waitq  // list of send waiters

    // 保护 hchan 中所有字段
    lock mutex
}

type waitq struct {
    first *sudog //对goroutine的封装
    last  *sudog //对goroutine的封装
}
</code></pre>
<p>和map一样，底层实际上是一个hchan结构体，调用了makechan()来创建channel，根据创建的时候是否有缓冲决定了buf指针是否有意义，sendx和recvx均为缓冲数组服务</p>
<pre><code class="language-go">func goroutine(a &lt;-chan int) {
    val := &lt;- a
    fmt.Println(&quot;received data: &quot;, val)
    return
}
func main(){
	var ch = make(chan int, 10)
    go goroutine(ch) //隐式转换为只读channel
    go goroutine(ch) //隐式转换为只读channel
    time.Sleep(time.Second)
}

</code></pre>
<p>上面go出去了两个读取ch的goroutine，所以此时接收队列应该是两个，结构如下（图源参考文章）</p>
<figure data-type="image" tabindex="1"><img src="https://image-static.segmentfault.com/311/648/3116484337-5d35b2f0069a8_article732" alt="recvq" loading="lazy"></figure>
<p>可以看到G1，G2其实就是个sudog结构的双向循环列表，recvq分别通过first和last指向了头尾</p>
<p>发送队列也是个wait结构，因此和接收队列几乎一致</p>
<h3 id="写入">写入</h3>
<ol>
<li>
<p>先判断是否有接收队列，如果有则直接拷贝到接收队列中，不复制到buf</p>
</li>
<li>
<p>对于有缓冲的channel，若还有空间，则将数据拷贝到buf中，同时更改相应的index</p>
</li>
<li>
<p>若没有空间或非缓冲则阻塞，然后创建一个sudog（sudog实际上是goroutine的封装，因此新的sudog实际就是包括了执行函数的这个goroutine</p>
<p>将新的sudog加入发送队列，当前goroutine被系统挂起，等待接受进程唤醒</p>
</li>
</ol>
<h3 id="读取">读取</h3>
<ol>
<li>
<p>先判断是否有缓冲，若无缓冲则直接从发送者的栈拷贝到接收者的栈，发送者是通过遍历sendq找到的</p>
</li>
<li>
<p>若有缓冲则从buf所指的空间拷贝数据（只要不为空就会一直有数据写入，不会有主动寻找sendq的时机）</p>
</li>
<li>
<p>若没有数据则将自己挂起到接收队列等待被发送进程找到，也是创建一个sudog</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[go语法基础巩固（string）]]></title>
        <id>http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-string/</id>
        <link href="http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-string/">
        </link>
        <updated>2021-03-18T11:39:34.000Z</updated>
        <content type="html"><![CDATA[<h2 id="字符串不能用下标访问">字符串不能用下标访问</h2>
<pre><code class="language-go">var str = &quot;Hello, 世界&quot;
</code></pre>
<p>在<code>golang</code>中，字符串几乎一定是<code>utf-8</code>编码的，而在<code>utf-8</code>中，中文有些是3个字节，有些是4个字节，英文是一个字节，而字符串这个类型的本质其实是一个字符slice，对str遍历可得</p>
<pre><code class="language-go">func main() {

	var str = &quot;Hello, 世界&quot;
	for i := 0; i &lt; len(str); i++ {
		fmt.Printf(&quot;%c &quot;, str[i])
	}
	fmt.Println()
	for i := 0; i &lt; len(str); i++ {
		fmt.Printf(&quot;%q &quot;, str[i])
	}
	fmt.Println()
	for i := 0; i &lt; len(str); i++ {
		fmt.Printf(&quot;%v &quot;, str[i])
	}
}
</code></pre>
<p>结果是</p>
<pre><code>H e l l o ,   ä ¸  ç   
'H' 'e' 'l' 'l' 'o' ',' ' ' 'ä' '¸' '\u0096' 'ç' '\u0095' '\u008c' 
72 101 108 108 111 44 32 228 184 150 231 149 140 
</code></pre>
<p>根据v和q的值可以看到，对于能解析的会被q解析为字符，解析不了的直接输出<code>utf-8</code>编码过后的结果，因此无法直接通过下标访问，但是可以将字符串转为rune数组</p>
<pre><code class="language-go">var str = &quot;Hello, 世界&quot;
fmt.Println(string([]rune(str[7:])))
//结果是 世界
</code></pre>
<p>go中对rune的定义是</p>
<pre><code class="language-go">type rune = int32
</code></pre>
<p>在转为rune数组的过程中，会将单个字符的全部字节放入（32位正好是<code>utf-8</code>的可变字符范围)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[go语法基础巩固（map）]]></title>
        <id>http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-map/</id>
        <link href="http://blog.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-map/">
        </link>
        <updated>2021-03-18T10:34:15.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p><a href="https://www.bookstack.cn/read/qcrao-Go-Questions/map.md">map - 《Go 语言问题集(Go Questions)》 - 书栈网 · BookStack</a></p>
</blockquote>
<h2 id="map遍历是无序的">map遍历是无序的</h2>
<p>参考大佬的文章,本文仅仅是用我个人语言总结了一遍，仅作个人笔记使用</p>
<h3 id="map的结构">map的结构</h3>
<pre><code class="language-go">type hmap struct {
    // 元素个数，调用 len(map) 时，直接返回此值
    count     int
    flags     uint8
    // buckets 的对数 log_2
    B         uint8
    // overflow 的 bucket 近似数
    noverflow uint16
    // 计算 key 的哈希的时候会传入哈希函数
    hash0     uint32
    // 指向 buckets 数组，大小为 2^B
    // 如果元素个数为0，就为 nil
    buckets    unsafe.Pointer
    // 扩容的时候，buckets 长度会是 oldbuckets 的两倍
    oldbuckets unsafe.Pointer
    // 指示扩容进度，小于此地址的 buckets 迁移完成
    nevacuate  uintptr
    extra *mapextra // optional fields
}
</code></pre>
<p>首先是经过hash函数（由编译阶段确定是什么hash函数）获得了key，将k-v存在一个bucket（实际上是一个指向bmap的指针）中，bucket个数是2^B</p>
<pre><code>hmap[hash(key)]-&gt; bucket[2^B]-&gt; bmap[0:8]
</code></pre>
<p>每个bmap最多可以存储8对hash后结果相同的数据，因此还要再bmap中查找一边key，才能找到真正对应的值，属于时间换空间，经过编译器处理后bmap结构如下，当8个不够用时，overflow会指向新的一个bmap</p>
<pre><code class="language-go">type bmap struct {
    topbits  [8]uint8
    keys     [8]keytype
    values   [8]valuetype
    pad      uintptr
    overflow uintptr
}
</code></pre>
<p>一般来说好的hash算法会尽量让每个bucket被平均分配，而不是一个超过太多，另一个是空的，但是当数据太多一样会发生拥挤，因此有一个指标叫做装载因子</p>
<pre><code class="language-go">loadFactor := count / (2^B)
</code></pre>
<p>两个条件都会触发</p>
<ol>
<li>
<p>装载因子大于6.5的时候</p>
</li>
<li>
<p>当overflow的bucket过多（bmap并不真正拥有overflow，overflow实际上是hmap中的结构）</p>
<ul>
<li>
<p>B&lt;15时，overflow的bucket数量大于2^B</p>
</li>
<li>
<p>B&gt;=15时，overflow的bucket数量大于2^15</p>
</li>
</ul>
</li>
</ol>
<p>此时会触发map的扩容，两种情况不一样</p>
<ol>
<li>
<p>条件一说明虽然很均匀，但是大家都快装满了，因此直接B+1解决问题</p>
</li>
<li>
<p>有两种可能</p>
<ul>
<li>
<p>不停的插入删除大量数据导致创建了过多的bucket，导致每个bucket都很空，但是都指向了一堆新的bucket，这时候就创建一个新的bucket将旧的bucket全部集中起来</p>
</li>
<li>
<p>极端情况：hash(key)都一样，怎么移动都没用，此时大家都集中在同一个bmap里面，就会创建很多bucket，但此时hash表已经退化为链表了</p>
</li>
</ul>
</li>
</ol>
<p>由于扩容的时候是不停的key-value的搬迁，因此非常影响性能，所以go是渐进式搬迁，每次插入修改删除key的时候移动两个，旧的bucket并没有真正被搬迁，而是挂载到了hmap的oldbuckets字段，直到完全迁移结束</p>
<p>如果是条件一则bucket变为两倍，如果条件二则不增加</p>
<h3 id="为什么无序">为什么无序？</h3>
<p>因为每次遍历map的时候实际上是遍历bucket，当B加一后，原来后B位的key变化了，多了一位，因此会分配到两个不一样的bucket中（但是同样可能不变），所以无法控制具体情况，自然就是无序的</p>
<ul>
<li>
<p>特殊情况：硬编码map</p>
<p>对于固定的map，不修改则完全不变，但是会给不熟悉的人带来疑惑，所以从go1.0 开始，遍历的时候是随机选择一个bucket中的cell（8个之一）开始，完全杜绝有序情况。</p>
</li>
</ul>
]]></content>
    </entry>
</feed>