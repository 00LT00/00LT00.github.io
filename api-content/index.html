{"posts":[{"title":"字节二面面经","content":"问题 dns工作方式 dns多个ip地址怎么选择 http长连接怎么控制 长连接怎么关闭呢 https是什么 rsa握手流程 给证书签名的作用是什么 tcp传输的可靠性是靠什么保证的 什么是聚簇索引呢 myisam是否是聚簇索引，他的索引保存的是什么 索引是通过什么数据结构保存的 B+树和B树的优缺点 有用过事务吗，是什么场景下使用呢 事务有几个特性 caid是什么 原子性是怎么保证的 undo log 里面有哪些东西 持久性是怎么保证的 隔离性是怎么保证的 mvcc是怎么实现的 lru怎么实现 浅析 计网 dns dns工作方式 dns可以理解为一个转换域名到ip地址的服务器，默认端口是53，默认使用udp协议 主要的工作方式有两种，迭代和递归 迭代就是服务器去一个一个问其他上级dns服务器，直到根域名或者有缓存过的记录 递归是服务器只管向上级问一次，上级dns再向上级问，对每个服务器来说，只有一次请求，一次返回 目前常采用迭代方式，也就是向dns服务器发送解析请求，服务器自己挨个向上级查询，然后返回结果 dns多个ip地址怎么选择 随机，我也不知道这有什么好问的，就是随机啊。。。 http长连接 http/1.0引入了长连接的方式，也就是在一个tcp连接中尽可能地多传输数据，减少tcp握手挥手的性能损耗 http怎么控制长连接 Connection: keep-alive Connection: close 通过在请求头中增加字段，http/1.0 默认是close，到http/1.1时，默认为keep-alive 当设置为keep-alive时，tcp连接不会主动断开，只有超过了服务器设置的超时时间才会主动停止 close时就断开tcp连接 https是什么 在http的基础上，增加了tls作为加密协议，将原来的明文通信变成密文通信 最早是ssl，套接字安全层，ssl3.0完善后成为为tls1.0，传输层安全协议，主要目的就是建立双方的加密通信 目前主流是1.2版本，1.3去年才刚刚上线，还没有普及 https握手流程怎么样的 1.2中的握手主要有两类，rsa和dh，但rsa在1.3版本中被废弃，dh的实际实现也换成了安全性更高的ecdh（用椭圆曲线的计算取缔了素数分解问题，效率更高，安全性更高） 握手流程可以看那篇讲https的文章，不赘述了 数字签名的作用 保证信息完整性，验证信息来源是否真实 对摘要做一次私钥加密，这样只有公钥才可以解开，再验证一次摘要是否正确，可以保证未被修改 CA证书的验证也是基于数字签名，每台电脑会内置受信任的CA机构的公钥，对其解密再验证摘要就可以保证CA证书没有被篡改 TCP tcp传输的可靠性靠什么保证 确认和重传机制 建立连接时约定好的起始序列号seq 确认号ack 校验和checksum 丢包时重传 数据排序 依据滑动窗口接受机制可以确定最后一个正确到达的数据包，定位错误数据 流量控制 双方通过约定滑动窗口的大小，控制发送速率 拥塞控制 慢启动 拥塞避免 快速重传 快速恢复 mysql 什么是聚簇索引呢 数据和索引放在一起，索引记录的就是数据本身 myisam是否是聚簇索引，他的索引保存的是什么 不是，它里面存放的是数据的文件地址 索引是通过什么数据结构保存的 innoDB和myisam都是B+Tree，也支持hash B+树和B树的优缺点 B+树的数据都在叶子节点，因此可以将索引放到一起，减少磁盘io更快的定位数据，实现范围查找更加容易 B树在索引到数据时可以快速返回，无需到达叶子节点，对于单一查询来说性能更好 事务有几个特性 四个，acid caid是什么 原子性和隔离性保证了一致性，最后可以持久化到磁盘中 原子性 要么全部成功，要么全部失败 隔离性 A事务的操作对B不可见，B事务的操作也不应该影响到A的正确性 一致性 完整性保持一致（p话） 其实就是说，没有并发错误，所有的事情都是按照预想的来的，没有破坏任何对完整性的保护 持久性 事务正确结束后，所做的更改就应该永久留在数据库中 原子性是怎么保证的 undo log undo log 里面有哪些东西 事务操作的反向操作，比如： insert a insert b insert c undo log中应该是： delete c delete b delete a 持久性是怎么保证的 redo log，每次先写日志，再写磁盘，这样就算断电，也能保证以重做日志为准进行恢复 为什么是redo log而不是直接写到数据中 因为磁盘的io，不管你读多少数据，都要从磁盘中找到对应的页块，一般来说是16kb，然后将其整体读入，那每次修改都直接修改磁盘，就会导致整个数据库对于磁盘的io非常依赖，而众所周知，磁盘的读写速度慢得离谱，所以为了保证性能，将所有记录优先记录到日志中，因为日志是连续读写的，没有随机读写所带来的io问题（其实也有，但已经很少了） 隔离性是怎么保证的 在mysql中，隔离分为四个级别 读未提交 读已提交 可重复读 串行化 真正与隔离性有关的主要是读已提交和可重复读，这里要引入个概念叫做封锁协议，它描述的是加锁时机，实际上可以把它当作一个思想来看 三级封锁协议： 任何写操作需要加X锁，直到事务结束 在一级封锁协议的基础上，读取数据时必须加S锁，读取完马上释放S锁 在一级封锁协议的基础上，读取数据时必须加S锁，直到事务结束才释放 笔者认为可以把2，3级分别看作是读已提交和可重复读的实现思想，而锁和mvcc分别对应着悲观锁和乐观锁的具体实现 当使用for update 等查询语句时，我们称此次查询为当前读，读已提交和可重复读正好对应着封锁协议中的二三级，通过添加对应的行锁（可重复读下有gap和next-key锁）来实现隔离 若是直接使用select查询，则会在该事务的第一次查询时，创建一个readview，也因此其被称之为快照读，同时每个数据行里都额外的保存了三个字段：最后一个对其改动的事务id，行的id（也就是主键，或者是union id），回滚指针，分别为trx，id，roll 读已提交的readview是每次查询都创建一个新的readview，可重复读是在事务开始的第一次查询创建，分别对应着二三级封锁协议的思想，每次查询时根据readview和隐藏字段的对比，选择出可以展示的数据行 mvcc是怎么实现的 readview中，主要包括了当前活跃的所有事务的事务组trxs，以及trxs的最小事务id，最大事务id，创建readview的事务id，我们分别称之为min,max,cur 数据行的隐藏字段主要是对其更改的事务id，我们称为trx，还有个回滚指针，他们的关系如下图 因为min，max是以创建readview时活跃的事务的最大最小来划分的，所以 绿色的区域代表着创建时，一定是提交了的事务，所以他的提交一定是可以看到的 红色代表着，创建时还没开始的事务，那么它的任何改动都无法看到 蓝色区域则表示存在活跃的事务，同时也存在后来才开始的但已提交了的事务，因此蓝色部分的判断为，该trx是否存在于活跃事务组中 若trx存在于trxs中，则创建时还未提交，因此不能展示 若不存在，则证明已经提交，所以可以展示 若trx正好就是cur，那自己对自己做的修改肯定可以看到 设计思路 lru是怎么实现的 首先，lru的意思是，Least Recently Used，最近最少使用，是一种缓存淘汰机制，由于是缓存淘汰机制，因此对性能有很高的要求，要求O(1)的读取速度，O(1)的删除速度，那么符合条件的数据结构就很清楚了 读取方面使用hashmap，而lru中，每次将读取的数据推后，保证最近最少使用的那个处于队头，这就涉及到空间的转移，那毫无疑问就是链表了 因此hashmap中存储对应元素项的指针，链表可以使用双向链表，每次使用的时候将该数据存放到队头或队尾，与此同时若长度超过限制则删除队尾或队头的数据 ","link":"http://www.zerokirin.online/post/zi-jie-er-mian-mian-jing/"},{"title":"字节一面面经","content":"问题 进程线程区别 进程间通信 线程间通信 go的channel是怎么实现的 go的调度模型 p的大小通常设置为多少，如果是io密集型应用呢 go的map实现方式 map退化成链表了怎么办 tcp的time wait状态 如果有太多的time wait状态该怎么办 mysql索引有哪几种 浅析 OS 进程线程区别？ 线程依赖于进程，比进程更轻量 进程是资源分配的基本单位 线程是调度的基本单位 线程可以共享同一个进程的资源 进程必须依靠IPC来通信 进程间通信方式 信号 信号量 有名管道 匿名管道 共享内存 消息队列 套接字 线程间通信 线程间通信的主要目的是用于多线程同步 互斥锁，条件变量（casp操作），读写锁，自旋锁 信号 信号量 go channel怎么实现的 核心是由发送队列，接收队列，和缓冲区组成 目前是用锁机制保护了先进先出的特性 发送的时候如果接收队列中有等待的goroutine则直接复制过去 接收的时候为了保证先进先出，会先从缓冲区复制到当前接收的goroutine，然后再把等待发送的goroutine唤醒，把内容复制到缓冲区，然后把阻塞的发送goroutine放回p队列 发送的时候还有一个保活操作，因为在阻塞的时候，该数据地址有可能已经没有引用了，gc扫描后会为白色，直接清理掉，因此在唤醒操作的后满做一次无意义的引用，可以使得该地址免于gc扫描 go的调度模型 其实就是gmp模型，车轱辘话来回说，细节详见后续博文 P的大小设置为多少，io密集型应用呢？ 默认设置为操作系统线程数量，例如我的4800h就是8核16线程，所以会初始化16个P队列 在调度过程中如果发生系统调用，P队列会主动与M解绑，由M去等待操作系统的io结束后，再自行寻找P队列进行操作 但是P和M的解绑是有延迟的，只有每次调度发生的时候才会彻底解绑，因此在io密集型应用中，会有大量的P处于等待状态，等待M的解绑，等待获取新的M 所以在io密集型应用中，需要将P设置的更大，更多，这样即使有很多很多P都在等待，依然有足够的P和M绑定，能够运行G，压榨cpu map退化成链表后？ go里通过多个hash函数，每次初始化的时候有个随机的种子，保证最大限度地随机，如果还是这么头铁，那go里面没有任何优化手段，实质上就是在一个bucket列表中挨个查找了 tcp time-wait状态 time-wait太多会怎样？ 占用太多端口 占用大量无意义的资源，即每次传输的数据远小于一次连接的建立断开所花费的经历 time-wait状态太多，怎么办？ tcp连接复用，人为在应用层将数据汇总发送，尽量让一个tcp连接承担更多的短数据传输 使用linux内核参数tcp_tw_reuse，这个参数能够在创建tcp连接的时候随机选一个处于time-wait状态的连接进行复用，此时，之前如果有延迟到来的数据，则会被抛弃，因为相当于开启了一个新的连接 mysql 索引有哪几种 主键索引 唯一索引 联合索引 普通索引 算法 如何判断二叉树是否对称？ 层次遍历同时遍历左右节点就行 ","link":"http://www.zerokirin.online/post/zi-jie-yi-mian-mian-jing/"},{"title":"端点面经","content":"问题 有缓冲的channel 读取的时候是否会阻塞 如果没有数据还想读取应该怎么办 如果没有数据select去读会不会阻塞 函数中对一个slice做append，在没有触发扩容的情况下，函数外部是否会改变 协程什么时候会切出去 协程是怎么主动放弃执行权的 http中path在请求头还是请求体 http 怎么指定json呢 http 怎么指定body编码格式 https 握手流程 什么是restful api 客户端怎么保证证书是服务端发来的 内连接左连接和右连接有什么区别 什么情况下需要用事务 事务的隔离级别有哪些 系统调用的过程是怎样的 怎么样从用户态切换到内核态 进程间的内存隔离 进程间通信方式 有名管道和匿名管道有什么区别呢 浅析 channel 有缓冲的channel在读取的时候如果没有数据依然是会阻塞的 读取channel的函数原型中有个形参叫做block，只有在select语句中，这个block的值是false，它控制了是否会进入自旋或是将读取的goroutine添加到接收队列中，如果是false的话，无法读取数据就直接返回了 函数的返回值有两个，selected和received received控制着是否有数据返回，也就是具体有没有读取到数据 selected只在select中用来判断是否执行该case slice slice的结构已经是老生常谈的话题了，它包括指向了具体是数据地址的unsafe.Pointer，len和cap 常问的一般是函数外调用及扩容问题，这次的问题是在函数内进行了一次没有扩容的append操作会怎样，首先看看底层实现 如果是直接传值调用的话，相当于对s做了一次拷贝，结果如图 在函数内部，直接修改s1的值的话，可以看到，其指向的地址和原变量s是相同的，因此外部也会跟着变化 但是执行append的时候稍有不同，在函数内部，对s1做append，势必会改变len和cap的值，而这两个值存在于新的变量s1中，在原变量s中是没有变化的，也就是说，哪怕数据已经写到了unsafe.Pointer指向的地址中，但是由于s无法看到len和cap的更改，因此他并不知道新的数据进来 要想在外部读取到数据，就需要用到unsafe.Pointer len := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) +uintptr(8))) //为什么是+8，因为unsafe.Pointer的最底层也是个int，而go中int的大小不固定，最小是32，随操作系统位数而定，因此不能看做int32的别名，在这里我们通过 fmt.Println(unsafe.Sizeof(s)) 的结果是24，可以推断出，每个int占8个字节，因此后移8位 *len = 5 http path在哪个部分 上面的url转换到http请求中就是如下格式 GET /path/to/myfile.html?key1=value1&amp;key2=value2 HTTP/1.1 Host: www.example.com http协议版本，path和query在请求行中 域名（host）在请求头中（host是唯一必备的请求头） 锚点不进行http传输，仅仅为浏览器定位页面使用 通过Content-Type指定传输的数据格式，常见的有 text/html 文本方式的html text/plain 纯文本 text/xml 文本方式的xml application/x-www-from-urlencoded 表单提交（普通表单，非上传） application/json 数据以json形式编码 application/xml 数据以xml形式编码 multipart/form-data 表单上传图片、文件类型等附件时必须用该类型 编码格式通过Content-Encoding和Content-Type 中的字段charset指定 charset 设置的是文本具体用什么编码，例如utf-8，gbk Content-Encoding 设置的是消息体通过什么编码方式压缩 https握手流程，目前tls1.1刚刚被废除，tls1.3还没有普及，tls1.2还是主流，主要分为两种形式，rsa和dh rsa版本如下 客户端初始化一个随机数client_random，向服务端发送client hello消息 服务端返回server hello消息，包括ca证书（ca证书里有服务端公钥）和随机数server_random，数字签名 客户端根据数字签名验证ca证书，同时生成新的随机数PreMaster，将PreMaster用服务端公钥加密，发送给服务端 现在双方都有client_random,server_random,PreMaster，通过这三个算出真正的主密钥 客户端算出来后给服务端发送 finished消息 服务段收到finished消息后验证是否有误，同时给客户端发送finished 双方都无误则成功握手 dh版本，主要是前面交换key的步骤不同 客户端初始化随机字符串client_random，向服务器发送client hello消息 服务端返回server hello，包括随机数server_random，再发送ca证书，server_pubkey 客户端验证证书及server_pubkey无误后向服务端发送client_pubkey 因为双方此时都有了下面这些，因此主密钥是可以通过dh算法算出来的（现在更多的用更安全的ECDHE算法） server_pubkey和client_pubkey可以生成PreMaster client_random和server_random 所以在客户端发送pubkey的时候就可以把自己的finished一起发送出去 服务端收到后验证是否有误，同时发送finished给客户端 双方确认无误，成功握手 客户端如何保证证书是服务端发来的 进行签名算法，上一步tls握手阶段的server hello消息会携带双方约定好的加密流程，例如 Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f) 可以看到这里密钥交换用了ECDHE方法因此就是dh流程，而身份验证则是RSA算法，这是一种非对称加密方式，而私钥只有服务器才有，所以只要服务端对发送的证书等信息做一次摘要加密（hash）后，再对摘要用私钥加密，然后将密文和摘要同时发送给客户端，客户端收到后，自行计算一次摘要得到hash-1，再用公钥解密服务端发送来的密文得到hash-2，如果两个相同，说明服务器的确有和证书里说的公钥的对应私钥，那么这个证书的来源就是可靠的 什么是restful api 看Url就知道要什么 看http method就知道干什么 看http status code就知道结果如何 ——怎样用通俗的语言解释REST，以及RESTful？ - 知乎 (zhihu.com) 这是我见过最简单，最清楚的描述，也是restful的核心思想，并不应该拘泥于patch，post等方法，重点是将api设计为人类高度可读的形式 url就是资源，method就是操作方式，code就是结果 Mysql 左连接和右连接有什么区别 内连接是指，左右两张表中相同的数据组成的集合 左连接是内连接和左边全表的并集 右连接是内连接和右边全表的并集 事务的隔离级别有哪些 读未提交 读已提交 可重复读 可串行化 什么时候使用事务 一次性对多个数据用多条sql语句修改时，在一个事务中，要么都执行，要么都不执行，这是原子性的体现，隔离性保证了多个事务之间互不相关，进而在原子性和隔离性的作用下，保证了数据库整体的一致性（这里的一致性指的是数据库的状态一直都是符合所有约束的） OS 系统调用的过程是怎样的，以printf函数为例 printf调用编写好的系统库函数（api） api找到该系统调用的系统调用号，将它还有该调用所需的参数一同放入各个寄存器中 用int指令，像系统发送软中断，中断号是 0x80 cpu收到中断，切换到内核态，准备函数运行需要的栈空间，同时保存cpu上下文 根据系统调用号执行对应的函数 准备函数返回值，并从内核态中恢复cpu上下文 执行ret指令切回用户态 怎样从用户态切换到内核态 每个进程在运行的时候会在用户空间和内核空间分别分配栈，将用户空间的栈指针保存到内核空间的栈中，将cpu的栈指针寄存器的值改为内核空间的栈 同时修改cpu的特权等级，将ring3（用户态）修改为ring0（内核态） 进程间的内存是如何保证相互隔离的 虚拟内存技术，有如下优点： 保证内存安全，防止用户空间访问内核空间 对进程透明，每个进程都有自己独立的内存空间，将进程的内存空间隔离，防止访问其他内存 可以灵活分配内存，例如，可以将一段连续的虚拟地址映射到分散的物理地址空间中 将部分内存中的数据存入磁盘，该磁盘被称为swap device，这样原内存就空出来了，可以存放更多的新数据，说白了就是强行扩充内存 进程间通信方式 管道（匿名管道） pipe 有名管道 fifo 信号 signal 消息队列 message 信号量 semaphore 共享内存 share memory 套接字 socket 有名管道和匿名管道的区别（翻译） PIPE FIFO 描述 无名的IPC对象 有名的IPC对象 通信 PIPE是系统本地的，不能用于网络的通信 FIFO可以在不同设备和网络间通信 可见 不存在于文件系统之中 在文件系统中存在 Process 在子进程和父进程之间通信 多个进程间，类似于服务器和客户端 Creation PIPE is created by pipe () function. FIFO is created by mkfifo () function. Read And Write Operation 读写需要同时进行 无需同时进行 Existence 被关闭或者父子进程退出时，PIPE消亡 FIFO一直存在，即使进程退出，它仍会存在直到系统重启 Control Over Ownership And Permissions 无法控制所有权和权限 FIFO就像文件一样，你可以控制所有权和他的权限 流通方向 PIPE只能单项流通 FIFO是双向的，同一个FIFO可以被用作读写 Mode Of Communication PIPE 提供简单数据流 FIFO 提供半双工数据流 Communication 具有共同祖先的进程的交流方式 共同祖先不是必要的 ","link":"http://www.zerokirin.online/post/duan-dian-mian-jing/"},{"title":"Channel底层如何实现阻塞的","content":" 每日一问系列（一） 我们都知道，channel在缓冲区满或者无缓冲的时候，发送数据会阻塞，缓冲区空或无缓冲的时候，接受也会阻塞 那么这个阻塞，是怎么实现的呢？ 之前我们只是粗略的讲解了channel的实现的结构体，这次我们详细的看看发送和接受的源码 源码位于go 1.15.4 src/runtime/chan.go 读取的两种方式 ch := make(chan int, 10) a := &lt;-ch b,ok := &lt;-ch golang有两种读取channel 的方式， // entry points for &lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { //看这里多了个返回值，received _, received = chanrecv(c, elem, true) return } 这两个函数也就是读取的两个方法，第二个带有一个名为received的返回值 他们同时都调用了chanrecv函数，所以重点就在这个函数中 读取函数 函数原型 // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). ***重点在这，如果block是false，且无法获取到数据，则直接返回(false,false) ***这个的另一个意思就是，即便缓冲区buf为空，也不会阻塞，而是直接返回，那么这个的使用场景是？ // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller's stack. func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) 上面调用chanrecv的函数里面都是写死了block为true，那么什么时候是false呢？ // compiler implements // // select { // case v = &lt;-c: // ... foo // default: // ... bar // } // // as // // if selectnbrecv(&amp;v, c) { // ... foo // } else { // ... bar // } // func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } // compiler implements // // select { // case v, ok = &lt;-c: // ... foo // default: // ... bar // } // // as // // if c != nil &amp;&amp; selectnbrecv2(&amp;v, &amp;ok, c) { // ... foo // } else { // ... bar // } // func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } select的用法就是，哪个可以取到数据就执行哪个case，而如果无法读取到则不会执行，所以肯定不能是阻塞的，所以两个用法的block的都是false chanrecv的返回值名字也很直白，selected和received selected只在执行select语句的时候判断case是否可以执行，至于数据是否获取到，则要看第二个参数received 那么我们详细来看chanrecv的内容吧，过程中我删掉了部分race检测的代码以及原有的英文注释 //原子操作检测是否能读取或者缓冲是否为空 func empty(c *hchan) bool { // c.dataqsiz is immutable. if c.dataqsiz == 0 { //无缓冲，检测发送队列是否是nil return atomic.Loadp(unsafe.Pointer(&amp;c.sendq.first)) == nil } //有缓冲，检测当前数量有多少 return atomic.Loaduint(&amp;c.qcount) == 0 } func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { //如果是nil if c == nil { //在select语句中block是false，所以会在这直接返回(false,false)，也就是说select永远不会进入一个对nil的chan操作的步骤 if !block { return } //阻塞了，所以读取nil并不会直接报错 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) } // chan中是空的，没有办法直接获取值，且在select中，无需等待取值 if !block &amp;&amp; empty(c) { //这里官方用了很长一段来描述为什么会这么写，大意是说 //在竞争检测关闭时，可能会有多个goroutine对channel进行操作 //比如说，一开始是，没有close的，非空的 //后来被关闭了，然后把数据排空了 //这时候由于检测语句的不合理安排以及并发访问 //很有可能会得出一个，没有close的，空了的结果 //所以对empty和closed都是原子操作去检测 if atomic.Load(&amp;c.closed) == 0 { //未关闭 //由于channel不能关了再开，所以如果检测到未关闭 //则证明在一开始就是未关闭的 //返回false，false //select不会继续下去，因为他还有收到值的可能性 return } //执行到这一定是closed的了，再检测一次empty是因为 //有可能在上面判断closed之前，有了新的数据，那么可能会是closed和非空 if empty(c) { //确定是空，若接受体不为空，也就是不用_抛弃，则直接置为0值 if ep != nil { typedmemclr(c.elemtype, ep) } //selected，可以执行这条路，但是v,ok=&lt;-ch的ok是false return true, false } } //后文初始化sudog的条件（暂时看不懂干嘛的，下次研究） var t0 int64 if blockprofilerate &gt; 0 { t0 = cputicks() } //加锁 lock(&amp;c.lock) //closed，且 缓冲buf 是空的 //无论有无缓冲区，都是这个流程 if c.closed != 0 &amp;&amp; c.qcount == 0 { unlock(&amp;c.lock) if ep != nil { //清空接收者 typedmemclr(c.elemtype, ep) } return true, false } //如果发送队列不为空的话执行，注意 //也就是要么无缓冲，要么缓冲buf满了，两种情况处理方法不一样，recv函数待会再讲 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) return true, true } //数据个数大于0，那肯定是有缓冲类型的 if c.qcount &gt; 0 { //通过这个chanbuf，获取到数据地址，存到qp中 qp := chanbuf(c, c.recvx) //把qp移动到ep中 if ep != nil { typedmemmove(c.elemtype, ep, qp) } //原来的数据置空 //还有一点就是，如果上一个ep是nil，也就是用_忽略了的话，这一步也会把数据清掉 typedmemclr(c.elemtype, qp) //循环链表，所以下标正常增长 c.recvx++ //涨到最大值后变为0，循环嘛 if c.recvx == c.dataqsiz { c.recvx = 0 } //取数据了，所以肯定要减小 c.qcount-- unlock(&amp;c.lock) return true, true } /* 前面我们已经排除了 * closed的，有发送队列的（缓冲类型溢出了，无缓冲类型有被阻塞的发送），缓冲区有值的 * 剩下的就是，未closed的，缓冲区没数据且发送队列空的 * 人话就是，轮到阻塞等待有缘人发送数据了 */ //select中没必要阻塞，直接就略过了 if !block { unlock(&amp;c.lock) return false, false } //从这里开始就是阻塞的流程 //获取当前运行的g的指针 gp := getg() //获取一个sudog结构体 mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil //当前g正在等待的sudog gp.waiting = mysg //对应的g mysg.g = gp //是否在select语句中 mysg.isSelect = false //标识是哪个chan mysg.c = c //唤醒时传递的参数，一般都是空 gp.param = nil //将这个sudog放到接收队列中，等待唤醒 c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. //这里设置个标志位，通知任何想要缩小栈空间情况，告诉他们这个g现在在等待channel的唤醒 //这里会有线程安全问题，所以用atomic操作 atomic.Store8(&amp;gp.parkingOnChan, 1) //暂停当前g，也就是实质上的阻塞，函数原型放在最后 gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up //唤醒，检查下有没有呗错误唤醒 if mysg != gp.waiting { throw(&quot;G waiting list is corrupted&quot;) } //等待的置空 gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil //释放sudog releaseSudog(mysg) return true, !closed } // Puts the current goroutine into a waiting state and calls unlockf. // If unlockf returns false, the goroutine is resumed. // unlockf must not access this G's stack, as it may be moved between // the call to gopark and the call to unlockf. // Reason explains why the goroutine has been parked. // It is displayed in stack traces and heap dumps. // Reasons should be unique and descriptive. // Do not re-use reasons, add new ones. func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) 再来让我们看看上面说的recv函数，上面的调用方式是这样的 recv(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) // recv processes a receive operation on a full channel c. // There are 2 parts: // 1) The value sent by the sender sg is put into the channel // and the sender is woken up to go on its merry way. // 2) The value received by the receiver (the current G) is // written to ep. // For synchronous channels, both values are the same. // For asynchronous channels, the receiver gets its data from // the channel buffer and the sender's data is put in the // channel buffer. // Channel c must be full and locked. recv unlocks c with unlockf. // sg must already be dequeued from c. // A non-nil ep must point to the heap or the caller's stack. //上面注释写的很清楚，两个情况，一个是缓冲区满了，一个是没有缓冲区的 //总归都是sg不为空，也就是发送队列有人在等着发送数据 func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { //缓冲区0，也就是无缓冲 if c.dataqsiz == 0 { if ep != nil { // copy data from sender //直接从发送者的sg中提取内容 recvDirect(c.elemtype, sg, ep) } } else { // Queue is full. Take the item at the // head of the queue. Make the sender enqueue // its item at the tail of the queue. Since the // queue is full, those are both the same slot. //缓冲区满了 //计算出当前应该提取的内容的位置 qp := chanbuf(c, c.recvx) // copy data from queue to receiver //这里校验ep是因为有可能有 &lt;-ch 直接取值的情况存在 if ep != nil { //将数据从刚刚计算好的位置拿出来 typedmemmove(c.elemtype, ep, qp) } // copy data from sender to queue //把发送队列的东西复制到刚刚拿走了的位置 typedmemmove(c.elemtype, qp, sg.elem) //下标加一，满了就置0 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } //设置一下已经发送的位置到哪了 //也就是新数据该往哪放了 c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } //发送完了就卸磨杀驴，该请的要清了 sg.elem = nil //把发送的g的信息保存一下 gp := sg.g //解锁函数，一般来说都是unlock(&amp;c.lock) unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } //唤醒这个发送者，因为他的数据已经发送完成了，就没必要阻塞了 goready(gp, skip+1) } 发送过程 和接受过程几乎一样，快速的看一下 /* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we'll see that it's now closed. */ func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from 'ready for sending' to // 'not ready for sending', even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn't closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread's view of c.closed and full(). //上面一大串的注释就是告诉你，如何在不获取锁的情况下判断是否准备好发送数据了，先判断close和和先判断full(c)都是正确的 if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) { return false } var t0 int64 if blockprofilerate &gt; 0 { t0 = cputicks() } lock(&amp;c.lock) //已经关闭了，所以要panic，不能继续发送了 if c.closed != 0 { unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) } //接收队列有东西，要么是缓冲区空了，要么是没有缓冲区 if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). //下文详细讲下这个函数 send(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) return true } //缓冲区还没满，这里dataqsiz至少大于0，所以是有缓冲的 if c.qcount &lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. //确定好应该存放的地址 qp := chanbuf(c, c.sendx) typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(&amp;c.lock) return true } //没有能放的位置了，只能阻塞了 //select中，非阻塞的直接返回了 if !block { unlock(&amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil //把自己放到发送队列中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) //阻塞住了 gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren't considered as roots of the // stack tracer. //这里和接受的方法不一样的是，多了个keepalive //原因是，在接受方法中，ep是一个外部传进来的，数据的目的地址，那么ep在外部一定是被使用的，所以ep一定不会在阻塞的时候被gc回收掉，如果没有使用，那回收了就回收了，问题不大 //但是，在这里ep是一个数据源地址，很有可能在发送以后就不存在了，那么阻塞的过程中就很有可能被回收掉，所以要加入一个保活的函数，策略就是，我后面还会用到这个变量，那么gc就不会扫描这个，这样只有被唤醒后，keepalive才会调用，然后ep数据已经发送出去了，回收就无所谓了 KeepAlive(ep) // someone woke us up. //收尾工作没什么好讲的了 if mysg != gp.waiting { throw(&quot;G waiting list is corrupted&quot;) } gp.waiting = nil gp.activeStackChans = false if gp.param == nil { if c.closed == 0 { throw(&quot;chansend: spurious wakeup&quot;) } panic(plainError(&quot;send on closed channel&quot;)) } gp.param = nil if mysg.releasetime &gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } 看看send函数 send(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) // send processes a send operation on an empty channel c. // The value ep sent by the sender is copied to the receiver sg. // The receiver is then woken up to go on its merry way. // Channel c must be empty and locked. send unlocks c with unlockf. // sg must already be dequeued from c. // ep must be non-nil and point to the heap or the caller's stack. func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { //前面一大串都是涉及到竞争检测的内容，本次暂时不分析 if sg.elem != nil { //看名字就很清楚了，从sg复制到ep sendDirect(c.elemtype, sg, ep) sg.elem = nil } //找到那个等待的g gp := sg.g //解锁 unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } //唤醒 goready(gp, skip+1) } 总结 主要有两个方面，一个是block参数，为了方便实现select语句，所以是非阻塞的操作，不能执行就不执行了 另一方面就是gopark和goready函数，通过这两个函数对g进行阻塞，其中发送任务还要用keepalive保活 不愧是每日一问，写了四天好家伙 ","link":"http://www.zerokirin.online/post/channel-di-ceng-ru-he-shi-xian-zu-sai-de/"},{"title":"Mysql 并发控制详解（四）——并发一致性错误的解决方式","content":"至此我们讲完了锁和MVCC，对数据库事务方面的理解应该更深了，还记得第一章我们讲的并发一致性问题吗，现在就让我们逐个分析 （读未提交和第一类丢失修改就不了，这个暂时真没搞明白） 隔离等级 未解决的并发一致性问题 解决的并发一致性问题 读未提交 幻影读，不可重复读，读脏数据，第二类丢失修改 第一类丢失修改 读已提交 幻影读，不可重复读，第二类丢失修改 读脏数据，第一类丢失修改 可重复读 幻影读，第二类丢失修改（具体类型具体分析） 不可重复读，读脏数据，第一类丢失修改 串行化 幻影读，不可重复读，读脏数据，两类丢失修改 封锁协议 讲之前发现还得把这个说清楚了，有三级封锁协议和两段锁协议，这个指的是数据库如何利用前面讲到的锁 三级封锁协议： 一级封锁协议 任何写操作需要加X锁，直到事务结束 二级封锁协议 在一级封锁协议的基础上，读取数据时必须加S锁，读取完马上释放S锁 三级封锁协议 在一级封锁协议的基础上，读取数据时必须加S锁，直到事务结束才释放 两段锁协议： 多个事务们的加锁和解锁分为两个阶段，要么一起加要么一起解 两段锁协议保证了加锁过程是可串行化调度（和那个串行化级别无关），是充分条件，也就是两段锁一定保证可串行化，但可串行化不一定要两段锁，例如 lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 两段锁协议，先一起加锁后一起解锁 lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) 分开加解锁，但它依然是可串行化调度 一级封锁协议协议 和 读未提交 举个例子，我们把mysql降为读未提交的级别，然后看看锁 --事务A mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 4 | 王哥 | | 7 | 王五 | | 8 | 赵四 | | 11 | 刘能 | +----+------+ 5 rows in set (0.01 sec) --事务B mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; update gap set name = '老王比' where id = 4; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 --注意这里B还没提交 --事务A mysql&gt; select * from gap; +----+--------+ | id | name | +----+--------+ | 1 | 张三 | | 4 | 老王比 | --虽然没提交但是已经查到了变化了 | 7 | 王五 | | 8 | 赵四 | | 11 | 刘能 | +----+--------+ 5 rows in set (0.01 sec) --再看看锁 mysql&gt; SELECT event_id,OBJECT_NAME,index_name,LOCK_TYPE,LOCK_MODE,LOCK_STATUS,LOCK_DATA FROM performance_schema.data_locks\\G; *************************** 1. row *************************** event_id: 13 OBJECT_NAME: gap index_name: NULL LOCK_TYPE: TABLE LOCK_MODE: IX --意向锁 LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** event_id: 13 OBJECT_NAME: gap index_name: PRIMARY LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP --一级封锁协议中提到的，更改的时候增加X锁 LOCK_STATUS: GRANTED LOCK_DATA: 4 2 rows in set (0.00 sec) 可以看到这里只有个记录锁和意向锁，可以浅显的理解为，读未提交是一级封锁协议的实现 同时它还可以解决第一类丢失修改，这个就不演示了，确实没有，为啥呢，等我问完老师再说 读已提交和脏读 脏读就是上面演示过的，明明没提交，就已经被看到了，那么这个隔离级别是怎么避免的呢？ 我们看二级封锁协议的定义，每个读取都要先添加S锁，那么实际上呢？ 同样，我们把mysql降到读已提交 mysql&gt; show variables like '%isolation%'; +-----------------------+----------------+ | Variable_name | Value | +-----------------------+----------------+ | transaction_isolation | READ-COMMITTED | +-----------------------+----------------+ 1 row in set, 1 warning (0.00 sec) --事务B mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; update gap set name = '老王比' where id &gt; 4; --即便是范围，但因为是RC等级，所以不存在gap锁，只有record锁 Query OK, 3 rows affected (0.04 sec) Rows matched: 3 Changed: 3 Warnings: 0 --这里看都是加了X锁的 mysql&gt; SELECT event_id,OBJECT_NAME,index_name,LOCK_TYPE,LOCK_MODE,LOCK_STATUS,LOCK_DATA FROM performance_schema.data_locks\\G; *************************** 1. row *************************** event_id: 8 OBJECT_NAME: gap index_name: NULL LOCK_TYPE: TABLE LOCK_MODE: IX LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** event_id: 8 OBJECT_NAME: gap index_name: PRIMARY LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 7 *************************** 3. row *************************** event_id: 8 OBJECT_NAME: gap index_name: PRIMARY LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 8 *************************** 4. row *************************** event_id: 8 OBJECT_NAME: gap index_name: PRIMARY LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 11 4 rows in set (0.00 sec) --事务A mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 4 | 王哥 | | 7 | 王五 | | 8 | 赵四 | | 11 | 刘能 | +----+------+ 5 rows in set (0.00 sec) 很显然，事务A在读取的过程中并没有加S锁，因为有X锁存在的前提下，S是无法加锁的，那么读取操作必然会被阻塞 所以读已提交并不是通过二级封锁协议实现的，而是通过MVCC实现的，说的好听些叫做一致性非锁定读 我们上一章讲过，在事务没有结束的时候，它的内部对外是不可见的，因此其它事务只能根据read view读取该行之前的版本，脏读问题自然没有了 但是封锁协议只是一种思想，而它的核心思想在于，读取完立即释放S锁，在MVCC的实现过程中就变成了每次select都创建一个新的read view 可以把二级封锁协议看作是读未提交的悲观锁实现方式，MVCC是乐观锁方式 悲观锁的问题就是并发量不足，这也是为什么会用MVCC去实现的原因 可重复读下的非锁定读 其实这个所谓的非锁定读，就是正常使用select语句不带for update或for share的读，也是mysql默认的隔离级别中所说的哪个可重复读，同样是通过MVCC实现的 它和RC的区别就是，它的select生成的read view 是第一个select 生成，一直到事务结束的 看看三级封锁协议，是不是很像，三级封锁协议也是，直到事务结束才释放锁，所以三级封锁协议和MVCC的实现方式都可以避免不可重复读的问题 和RC一样，可以把三级封锁协议看作是悲观锁版本，MVCC是乐观锁版本 既然是MVCC的实现方式，为什么我要把它专门分出来一个非锁定读？ 因为它没有解决我们之前提到过的，第二类丢失修改，和另一个很重要的错误，幻影读 错误的第二类丢失修改 我们先来看一个错误的实例 时间 转账事务A 取款事务B T1 开始事务 T2 开始事务 T3 查询账户余额为1000元 T4 查询账户余额为1000元 T5 取出100元把余额减少100元 T6 提交事务 T7 汇入100元，把余额增加100元 T8 提交事务 T9 余额是1000元，无白嫖 （这里的正确答案是1000元，并没有出错） 这个错误的例子常被人拿来宣称“RR的隔离级别可以解决第二类丢失修改” 这是彻头彻尾的胡扯，上一章讲MVCC的文章中说过，这种非锁定读也称作快照读，相对应的还有个叫做当前读，当前读是完全不受MVCC的限制的 而更改这个操作在它生成临时表的那一刻用的就是当前读 上述这个错误的例子中，即便T6时刻它仍然会显示余额为1000（因为MVCC），但是在T7，更改时它读出的临时表中，余额是900，因为他是当前读查出来的结果 那有人会说为什么不干脆就这么写了呢，为什么还要select呢？因为会有各种意外啊，而且直接这么写，某种程度上就是主动把隔离级别降到了RC，反而把这个问题变成了不可重复读的问题，简直是开倒车了 那趁着这个错误的例子，我们来讲讲幻影读 幻影读 第一章就说过了，幻影读不是不可重复读，它的本质是当你使用select 和增删改操作时，手动混合了当前读和快照读，导致一致性失效，而不可重复读是read view 的创建时机不同 把第一章的例子拿出来分析 --事务1 mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.04 sec) mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.04 sec) --事务2 mysql&gt; insert into gap values(8,'老王'); Query OK, 1 row affected (0.05 sec) --事务1 mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | --没有任何变化 +----------+ 1 row in set (0.00 sec) mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 5 | 李四 | | 7 | 王五 | | 11 | 赵6 | +----+------+ 4 rows in set (0.00 sec) --事务1 mysql&gt; insert into gap values(8,'赵四'); ERROR 1062 (23000): Duplicate entry '8' for key 'gap.PRIMARY' mysql&gt; update gap set name = '刘能' where id = 8; Query OK, 1 row affected (0.04 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 5 | 李四 | | 7 | 王五 | | 8 | 刘能 | | 11 | 赵6 | +----+------+ 5 rows in set (0.00 sec) 由于是可重复读级别，默认查询使用的是快照读，在第一个select的时候生成的read view直到事务结束才失效，所以插入后再查是找不到的（这不就是可重复读的基本定义嘛） 但插入和更新的时候会变成当前读，因此插入报错，那么更新后为什么能搜到呢？ 注意看上一章我们讲的MVCC，更新后它的隐藏列会更新是哪个事务更改了他，而那个事务ID正是当前的事务ID，所以在查询的时候，curr_trx_id == DB_TRX_ID，满足展示条件，就显示了出来 所以RR并没有解决幻影读，而上文讲的那个错误的第二类丢失更新本质上和幻影读一样，都是当前读和快照读发生了冲突 真正的第二类丢失修改 第二类的丢失修改流程是这样的 时间 转账事务A 取款事务B T1 开始事务 T2 开始事务 T3 查询账户余额为1000元 T4 查询账户余额为1000元 T5 取出100元把余额改为900元 T6 提交事务 T7 汇入100元把余额改为1100 元 T8 提交事务 T9 最后结果是1100元 （这个是真的会变成1100，白嫖100） 看到了吗，两个update 操作都是直接更新成了一个我们计算好的数值，而仅仅通过MVCC是无法避免这种错误的 这种操作会在该记录行上增加两个undo log，1100的回滚指针指向的是900而不是1000，因为在更新的时候是当前读，所以在T7时刻，innoDB是很清楚当前值已经被更改为900了 上一个案例我们知道，900+100又变回了1000，但是这次我们是手动写值的，这就意味着我们在业务代码中判断的更新的值是错误的，因此innoDB会看着你把900变成了1100，这波貌似不能怪mysql？ 在innoDB看来这是你自己写错了，和他没半毛钱关系，都不能算是卡了个MVCC的bug。。。 这也是为什么很多博客都在说，其实RR级别不能解决第二类丢失修改，因为这本来就不是MVCC应该控制的问题 那么怎么解决这类丢失修改和幻影读问题呢？还记得上面说过，MVCC是RR的乐观锁版本，而基于三级封锁协议的它的悲观锁版本就是最好的答案 RR with next-key MVCC的RR被称作一致性非锁定读，那么这个使用了next-key的RR就是一致性锁定读，也可以理解成它实现了三级封锁协议，是RR的悲观锁版本 前文中我们详细介绍了record lock，gap lock，next-key lock的锁定范围及使用方法，还有什么时候会加这些锁，而我们所有的实例中几乎都是 select * from ...... for [update|share] 通过加上for update，select就变成了一致性锁定读，也就是三级封锁协议的描述，读取数据时必须加S锁，直到事务结束才释放，此时将不再通过MVCC去判断展示的数据 幻读 由于我们的select ... for update 会给搜索到的数据添加next-key和gap锁，而插入操作的时候会先获取插入意向锁（实际上是个X的gap锁） 当该范围内有锁的时候，插入意向锁没法添加，所以就保证了我们搜索到的范围内不会被插入新的数据，从根本上避免了幻读的出现 第二类丢失修改 上面我们说过，这类错误是innoDB允许的，是他看着你自己改错了，那么要想避免这个错误，就要通过for update 通知innoDB，“帮我锁定下，我待会要根据这个查询出来的值更新” innoDB就会给查到的行增加X类型的锁，其他事务的查询就要等该事务结束后才能继续，这样就避免了查询出来后的值和改的时候不一样，也就是当前读和快照读的冲突 再把流程展示一下 时间 转账事务A 取款事务B T1 开始事务 T2 开始事务 T3 查询账户余额为1000元 for update 加了X锁 T4 查询账户余额为？元 for update 加X锁等待中 T5 取出100元把余额改为900元 T6 提交事务 释放X锁 T7 查询账户余额为900元 for update 获取了X锁 T8 汇入100元把余额改为1000 元 T9 提交事务 T10 最后结果是1000元 （白嫖失败，这次一定） 这样我们就通过带有next-key的RR级别，避免了丢失修改，但这种方法也有很大的缺点，如果需要频繁的对该表修改，这种方式就会频繁的加锁解锁，并发性能就会受到很大的影响 所以当前常用的做法是给该表增加一个显示的版本行，当更新写回的时候判断版本号是否更改过，如果改过则回滚，也就是我们所说的乐观锁，这样查询可以利用innoDB的MVCC，更新的时候用自己做的MVCC，避免了频繁加锁解锁导致的事务等待而浪费性能 总结 至此，我们所有的并发一致性错误已经全部解决了（其实还有很多新世代发现的错误，但这里笔者能力实在过于菜，无力顾及了） 四个事务隔离级别我们也讲了三个，最后一个串行化已经不能算并发了 通过三级封锁协议的思想和MVCC的实现，尽最大可能的保证了RC和RR的并发 另外两个超出MVCC能力的并发错误也通过next-key等锁解决了 事务，并发，锁，MVCC，封锁协议的问题暂时就告一段落同时十分感谢各位被偷图的老板 ","link":"http://www.zerokirin.online/post/mysql-bing-fa-kong-zhi-xiang-jie-si-bing-fa-yi-zhi-xing-cuo-wu-de-jie-jue-fang-shi/"},{"title":"Mysql 并发控制详解（三）——MVCC","content":"Multi-version concurrency control 多版本并发控制，首先我们先来问个问题，为什么要用MVCC？ 我们都知道mysql有四个事务隔离等级 读未提交 压根没有事务和版本这个概念，裸奔不需要mvcc 串行化 对所有的操作都加互斥锁，无需版本管理，因为整个数据库中只有一个唯一的版本 所以mvcc的应用场景是为了实现读已提交和可重复读，说的专业一点叫做一致性非锁定读，那么它是如何实现的呢？ 记录行中自带的版本信息 首先，在InnoDB引擎中，每行数据都有三个隐藏列 6-byte DB_TRX_ID 用来表示这行数据最后是被哪个事务增删改的（删除其实也算更新） 7-byte DB_ROLL_PTR 回滚指针，指向的是undo log 中对应的记录，主要是指向事务未提交的数据位置，也就是记录了要怎么回滚，一共有四种undo log，不过这不是本文的重点 6-byte DB_ROW_ID 行ID，就是主键ID或者是字段中的一个unique ID，如果都没有，那就用哪个隐藏的主键ID（一定记住，聚簇索引不可能没有主键） 千万注意，TRX_ID是递增的，通过事务ID确定版本号，所以版本号不可能开倒车吧 read view 是什么 再来看一个概念read view，它包括四个结构 rw_trx_ids：表示在生成 Read View 时，当前活跃的读写事务数组。 min_trx_id：表示在生成 Read View 时，当前已提交的事务号 + 1，也就是在 rw_trx_ids 中的最小事务号。 max_trx_id：表示在生成 Read View 时，当前已分配的事务号 + 1，也就是将要分配给下一个事务的事务号。 curr_trx_id：创建 Read View 的当前事务 id。 可以看到，一个read view 中记录了当前数据库中的各种事务版本，这样我们通过把每个行记录与read view对比，就可以判断出该记录的状态以及是否应该展示，所以read view在某种程度上起到了一个快照的作用 read view 和事务ID的关系 DB_TRX_ID &lt; min_trx_id 这一行的事务ID比已经提交了的事务ID小，所以在生成readview的时候他已经commit了，可以展示 DB_TRX_ID &gt;= max_trx_id 最后修改它的ID比这个时间点上最大的事务ID都大，那肯定不能展示 DB_TRX_ID &gt;= min_trx_id 时 DB_TRX_ID == curr_trx_id 自己创建的自己肯定可以看到，其他的那就都是其他事务创建的，还没提交所以看不到 这样，我们就能够根据read view 确定当前到底哪些可以被展示出来，而这种查找的时候根据read view匹配的方式被称作快照读，和它对应的叫做当前读，当前读就完全不受mvcc的限制 我们最开始提到了，RR和RC是通过mvcc实现的，在这两个隔离级别下，默认的select语句就是快照读，区别是 RR（可重复读） 事务开始后，第一次select就创建一个read view，后续的所有查询都是用的第一个read view RC（读已提交） 事务开始后，每一个select都会创建一个read view，也因此，它无法解决不可重复读的问题，因为事务过程中如果其他事务更新了记录，新的read view的min_trx_id会大于那个新记录的trx_id，就会把新记录也查出来 实例 图源MySQL 中你必须要懂的 MVCC (juejin.cn) 这个图做的很nice，偷偷搬过来 假设我们现在是RC级别（为了方便看看read view的更新） 假设当前这行记录长这样，和红色表头直接挨着的就是存在B+Tree上的数据，可以看到回滚指针没有值，表明当前数据未发生过更改 现在一个id为101的事务修改了它 可以看到它的回滚指针指到了undo log中的旧记录 事务 0 执行了一个 select 操作，事务 0 会生成一个 Read View。 注意，这个min_trx_id存的是最后一个提交的ID+1，所以此时此刻数据库中已经提交了ID是100，也就是说上面的修改并没有提交，所以根据匹配规则可以发现，该行的最新记录并不符合要求，就会沿着他的回滚指针找到第一个满足要求的也就是100的记录 事务 101 又更新了一下，然后提交事务 如果再select一次，生成的新的read view为 最新提交的变成了101，活跃的事务已经没有了（101提交了），那这时候就可以看到最新记录了 那个黄色的 age=21 的记录是不会展示出来的，因为对于其他事务来说，它是一个中间状态，只有他自己可以看到 总结 innoDB通过比较隐藏列和read view的关系，确定该记录是否展示，或者通过回滚指针找到第一个能展示的版本 RC 是每一次select 都会生成新的read view RR 是只有第一次select 生成新的，后续都不会更新了 也正是这个区别，决定了两者是否会产生不可重复读的问题 读未提交和串行化都不需要mvcc ","link":"http://www.zerokirin.online/post/mysql-mvcc-qian-xi/"},{"title":"Mysql 并发控制详解（二）——锁","content":"书接上回，我们罗列了一下事务隔离等级和并发一致性问题，那么这一章就让我们看看锁是怎么工作的，又是怎么和事务联系起来的 官方文档如下： Shared and Exclusive Locks 共享锁和独占锁 Intention Locks 意向锁 Record Locks 记录锁 Gap Locks 间隙锁 Next-Key Locks 临键锁 Insert Intention Locks 插入意向锁 逻辑意义上的锁 共享锁和独占锁 换句话说就是读锁和写锁（互斥锁，排他锁），简称S和X，innoDB中的行级锁就是这两种锁 读锁可以重复加，共享锁嘛 写锁和读锁不能共存，也就是独占的意思，当有读锁存在的时候不能加写锁 偷图『浅入浅出』MySQL 和 InnoDB - 面向信仰编程 (draveness.me) 意向锁 刚刚我们说到，行级锁包括读锁和写锁，而mysql支持多粒度的锁，也就是说，存在表级别的读锁和写锁，这样就带来个问题，如果要对某个表加锁，那么就要判断它的每一行是否有锁，这是非常影响性能的，因此提出了意向锁的概念 意向锁分为读写两种，简称IS和IX，是表级锁，他们之间是互相兼容的，继续偷图 这里的几个锁都代表了表级锁，因为意向锁只有表级，不能把行级混进来 要获取行级的S或X锁，必须先获取其表的意向锁 获取表锁的时候不需要意向锁 这样当我们要增加表级的S或X锁时，如果其中某行已经有了S或X锁，那么表上就会有对应的IS和IX锁，这样就不用每行都去检测了 物理意义上的锁 record lock record lock 记录锁是索引记录上的锁，也就是我们上述所说的行锁的实现，同样有S和X之分，它是后面的各种行锁的基础，也可以直接理解为，record lock就是行锁，因为innoDB用的是聚簇索引，所以所有的数据最后都是主键索引去找，锁住了主键索引也就代表锁住了这一行 它通过对索引进行锁定，让我们举个小例子，假设锁的结构和索引如下： mysql&gt; desc salaries; +-----------+------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-----------+------+------+-----+---------+----------------+ | id | int | NO | PRI | NULL | auto_increment | | emp_no | int | NO | MUL | NULL | | | salary | int | NO | MUL | NULL | | | from_date | date | NO | MUL | NULL | | | to_date | date | NO | | NULL | | +-----------+------+------+-----+---------+----------------+ 5 rows in set (0.00 sec) mysql&gt; show index from salaries\\G; *************************** 1. row *************************** Table: salaries Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 2837536 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: Visible: YES Expression: NULL *************************** 2. row *************************** Table: salaries Non_unique: 0 Key_name: idx_emp_date Seq_in_index: 1 Column_name: emp_no Collation: A Cardinality: 293002 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: Visible: YES Expression: NULL *************************** 3. row *************************** Table: salaries Non_unique: 0 Key_name: idx_emp_date Seq_in_index: 2 Column_name: from_date Collation: A Cardinality: 2837536 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: Visible: YES Expression: NULL 3 rows in set (0.00 sec) 对表中的第一行加共享类型的record锁 mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from salaries where id = 1 for share; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239768 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 39 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE --意向锁，因为要获取行锁，所以必须先加上意向锁 LOCK_MODE: IS LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495236984 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 39 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY --主键索引 OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD --这里看到了吗，锁的类型是record LOCK_MODE: S,REC_NOT_GAP --模式是S，是record锁而非gap锁（下文介绍） LOCK_STATUS: GRANTED --以获取锁的意思 LOCK_DATA: 1 --锁定的数据是id=1的主键索引 2 rows in set (0.00 sec) 可以看到，当我们通过主键索引找到数据的时候，会对该主键索引加锁，那么二级索引呢 mysql&gt; explain select * from salaries where emp_no = 10001 limit 1 for share\\G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: salaries partitions: NULL type: ref possible_keys: idx_emp_date,idx_emp_no key: idx_emp_date --用的是辅助索引 key_len: 4 ref: const rows: 17 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) ERROR: No query specified mysql&gt; select * from salaries where emp_no = 10001 limit 1 for share; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239768 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 39 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE LOCK_MODE: IS LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495236984 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 39 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: S,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 1 *************************** 3. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:43:2:2835495237328 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 41 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: idx_emp_date --看这里，第三个锁的是实际使用的索引 OBJECT_INSTANCE_BEGIN: 2835495237328 LOCK_TYPE: RECORD LOCK_MODE: S --共享模式 LOCK_STATUS: GRANTED LOCK_DATA: 10001, 1017050, 1 --对应索引上被锁住的数据 3 rows in set (0.00 sec) 上述可以看到，当我们使用辅助索引的时候就会对辅助索引加record锁，那么如果一开始就是用辅助索引呢？ mysql&gt; begin; --重开个事务 Query OK, 0 rows affected (0.00 sec) mysql&gt; explain select * from salaries where emp_no = 10001 limit 1 for share\\G; *************************** 1. row *************************** id: 1 select_type: SIMPLE table: salaries partitions: NULL type: ref possible_keys: idx_emp_date,idx_emp_no key: idx_emp_date --用的是辅助索引 key_len: 4 ref: const rows: 17 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) ERROR: No query specified mysql&gt; select * from salaries where emp_no = 10001 limit 1 for share; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239768 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE LOCK_MODE: IS LOCK_STATUS: GRANTED LOCK_DATA: NULL --看这里，两个锁的顺序不一样了，对比上面的可以看到，这次是辅助索引在上 *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:43:2:2835495236984 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: idx_emp_date --先辅助索引 OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: S LOCK_STATUS: GRANTED LOCK_DATA: 10001, 1017050, 1 --锁住的值 *************************** 3. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495237328 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY --然后才是主键索引 OBJECT_INSTANCE_BEGIN: 2835495237328 LOCK_TYPE: RECORD LOCK_MODE: S,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 1 3 rows in set (0.00 sec) 这也很好解释，先加意向锁，然后通过辅助索引找到主键索引，最后从主键索引那取数据 那我们再加个互斥锁呢？ mysql&gt; select * from salaries where emp_no = 10001 limit 1 for update; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239768 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE LOCK_MODE: IS LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:43:2:2835495236984 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: idx_emp_date OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: S LOCK_STATUS: GRANTED LOCK_DATA: 10001, 1017050, 1 *************************** 3. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495237328 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 47 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495237328 LOCK_TYPE: RECORD LOCK_MODE: S,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 1 --看这里，上面的和原来一样，共享锁的基础上加互斥锁并不意味着直接升级，而是额外加锁 *************************** 4. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239856 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 55 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239856 LOCK_TYPE: TABLE LOCK_MODE: IX LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 5. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:43:2:2835495237672 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 55 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: idx_emp_date OBJECT_INSTANCE_BEGIN: 2835495237672 LOCK_TYPE: RECORD LOCK_MODE: X LOCK_STATUS: GRANTED LOCK_DATA: 10001, 1017050, 1 *************************** 6. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495238016 ENGINE_TRANSACTION_ID: 59891 THREAD_ID: 274 EVENT_ID: 55 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495238016 LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 1 6 rows in set (0.00 sec) 如果先加互斥锁再加共享锁呢 --互斥锁 mysql&gt; select * from salaries where emp_no = 10001 limit 1 for update; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) --共享锁 mysql&gt; select * from salaries where emp_no = 10001 limit 1 for share; +----+--------+--------+------------+------------+ | id | emp_no | salary | from_date | to_date | +----+--------+--------+------------+------------+ | 1 | 10001 | 60117 | 1986-06-26 | 1987-06-26 | +----+--------+--------+------------+------------+ 1 row in set (0.00 sec) mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1215:2835495239768 ENGINE_TRANSACTION_ID: 59892 THREAD_ID: 274 EVENT_ID: 62 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE LOCK_MODE: IX --意向锁 LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:43:2:2835495236984 ENGINE_TRANSACTION_ID: 59892 THREAD_ID: 274 EVENT_ID: 62 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: idx_emp_date OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: X --互斥锁 LOCK_STATUS: GRANTED LOCK_DATA: 10001, 1017050, 1 *************************** 3. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:157:9:2:2835495237328 ENGINE_TRANSACTION_ID: 59892 THREAD_ID: 274 EVENT_ID: 62 OBJECT_SCHEMA: employees OBJECT_NAME: salaries PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495237328 LOCK_TYPE: RECORD LOCK_MODE: X,REC_NOT_GAP LOCK_STATUS: GRANTED LOCK_DATA: 1 3 rows in set (0.00 sec) 可以看到，当我们拥有了互斥锁后，再加共享锁就没有意义了，我们也可以称，互斥锁是比共享锁更高级别的锁定 Gap lock 间隙锁，这个锁只存在于可重复读这一隔离级别，同时这个锁不分S和X，它锁住的是一个区间，其他事务在这个区间内的插入删除更新操作都会被阻塞 同时它很特别的一点是，加多个Gap锁不会阻塞，可以有多个事务同时添加Gaplock，因为本质上他是为了保护一个区间不会插入，而不是为了锁定具体的数据 让我们看个小例子，先建表： mysql&gt; CREATE TABLE `gap` ( -&gt; `id` int(1) NOT NULL AUTO_INCREMENT, -&gt; `name` varchar(8) DEFAULT NULL, -&gt; PRIMARY KEY (`id`) -&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected, 2 warnings (0.03 sec) mysql&gt; mysql&gt; INSERT INTO `gap` VALUES ('1', '张三'); Query OK, 1 row affected (0.01 sec) mysql&gt; INSERT INTO `gap` VALUES ('5', '李四'); Query OK, 1 row affected (0.00 sec) mysql&gt; INSERT INTO `gap` VALUES ('7', '王五'); Query OK, 1 row affected (0.00 sec) mysql&gt; INSERT INTO `gap` VALUES ('11', '赵六'); Query OK, 1 row affected (0.00 sec) 让我们对其中一部分数据加锁： mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from gap where id between 3 and 8 for share; +----+------+ | id | name | +----+------+ | 5 | 李四 | | 7 | 王五 | +----+------+ 2 rows in set (0.00 sec) --查看锁 mysql&gt; select * from performance_schema.data_locks\\G; *************************** 1. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:1216:2835495239768 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 288 OBJECT_SCHEMA: employees OBJECT_NAME: gap PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: NULL OBJECT_INSTANCE_BEGIN: 2835495239768 LOCK_TYPE: TABLE LOCK_MODE: IS LOCK_STATUS: GRANTED LOCK_DATA: NULL *************************** 2. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:158:4:3:2835495236984 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 288 OBJECT_SCHEMA: employees OBJECT_NAME: gap PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: S LOCK_STATUS: GRANTED LOCK_DATA: 5 *************************** 3. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:158:4:4:2835495236984 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 288 OBJECT_SCHEMA: employees OBJECT_NAME: gap PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495236984 LOCK_TYPE: RECORD LOCK_MODE: S LOCK_STATUS: GRANTED LOCK_DATA: 7 --上面的都是正常记录锁，可以不看 *************************** 4. row *************************** ENGINE: INNODB ENGINE_LOCK_ID: 2835531521376:158:4:5:2835495237328 ENGINE_TRANSACTION_ID: 284310508232032 THREAD_ID: 274 EVENT_ID: 289 OBJECT_SCHEMA: employees OBJECT_NAME: gap PARTITION_NAME: NULL SUBPARTITION_NAME: NULL INDEX_NAME: PRIMARY OBJECT_INSTANCE_BEGIN: 2835495237328 LOCK_TYPE: RECORD --行锁，所以类型是record锁 LOCK_MODE: S,GAP --看这里，Gap锁出现了，S和X没有意义，因为11本身没有被锁 LOCK_STATUS: GRANTED LOCK_DATA: 11 --看GAP锁到底锁到了哪一行？ 4 rows in set (0.00 sec) 看最后我们会发现，明明锁定的id区间是3-8，但最后却锁到了11头上，最后的这个Gap锁意味着，从他以前直到上一条record锁的所有数据都会被锁定，插入操作都会被阻塞 其实是这样，表里的记录有1,5,7,11，而8没有对应的记录，因此它会按照索引向后找到第一个记录（如果没有就不设置Gap锁了），然后给它添加Gap锁也就是11，而这样就代表锁住了 (7,11) 的区间 所以Gap锁最大的缺点是，即便我们查询的数据范围并不大，只有3-8，但他却把9,10这两个无辜的行也占住了，在事务释放之前不能进行插入操作 想起了上文提到过的记录锁吗 *************************** 2. row *************************** LOCK_TYPE: RECORD --这里看到了吗，锁的类型是record LOCK_MODE: S,REC_NOT_GAP --模式是S，是record锁而非gap锁（下文介绍） 我们已经见过的LOCK_MODE的值现在有（X和S暂时不去管他）： S S,GAP S,REC_NOT_GAP 暂时先放着，等我们把next-key locks讲完就能串起来了 Next-Key lock 临键锁，next-key lock = record lock + Gap lock 这玩意在data_locks中都找不到，因为它其实也不是什么物理上的锁，而是一个锁机制，它和Gap一样都是只存在于可重复读的隔离级别，它存在的意义是为了解决幻影读的问题，让我们接着上面的例子看看 mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 7 | 王五 | | 8 | 赵四 | | 11 | 刘能 | +----+------+ 4 rows in set (0.00 sec) mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from gap where id between 5 and 9 for update; --锁的是5-9 +----+------+ | id | name | +----+------+ | 7 | 王五 | | 8 | 赵四 | +----+------+ 2 rows in set (0.03 sec) 现在id上一共有4个区间 (1,7],(7,8],(8,11],(11,+∞)，看看锁有哪些啊 mysql&gt; SELECT event_id,OBJECT_NAME,index_name,LOCK_TYPE,LOCK_MODE,LOCK_STATUS,LOCK_DATA FROM performance_schema.data_locks; +----------+-------------+------------+-----------+-----------+-------------+-----------+ | event_id | OBJECT_NAME | index_name | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +----------+-------------+------------+-----------+-----------+-------------+-----------+ | 19 | gap | NULL | TABLE | IX | GRANTED | NULL | | 19 | gap | PRIMARY | RECORD | X | GRANTED | 7 | | 19 | gap | PRIMARY | RECORD | X | GRANTED | 8 | | 19 | gap | PRIMARY | RECORD | X,GAP | GRANTED | 11 | +----------+-------------+------------+-----------+-----------+-------------+-----------+ 4 rows in set (0.00 sec) 我们锁的区间是5-9，但是行锁分别是7，8，11，最后一个Gap锁上面讲过了不再赘述 那么，前面的(5,7)这个是怎么锁的呢？插入下看看 mysql&gt; insert into gap values(6,'随便吧'); ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction mysql&gt; SELECT event_id,index_name,LOCK_TYPE,LOCK_MODE,LOCK_STATUS,LOCK_DATA FROM performance_schema.data_locks; --省略了表名，方便排版 +----------+------------+-----------+------------------------+-------------+-----------+ | event_id | index_name | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +----------+------------+-----------+------------------------+-------------+-----------+ | 11 | NULL | TABLE | IX | GRANTED | NULL | | 11 | PRIMARY | RECORD | X,GAP,INSERT_INTENTION | WAITING | 7 | | 19 | NULL | TABLE | IX | GRANTED | NULL | | 19 | PRIMARY | RECORD | X | GRANTED | 7 | | 19 | PRIMARY | RECORD | X | GRANTED | 8 | | 19 | PRIMARY | RECORD | X,GAP | GRANTED | 11 | +----------+------------+-----------+------------------------+-------------+-----------+ 6 rows in set (0.00 sec) 看看看，插不进去，而且查看锁的时候会发现一个新的event_id，它多出来了个等待中的锁，lock_mode待会讲 为什么6也被阻止了？试试看4 mysql&gt; insert into gap values(4,'随便吧'); ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 怎么4也插不进去了？？？？这就是next-lock在起作用了，让我们再看看锁定7-11会怎么样 mysql&gt; select * from gap where id between 7 and 11 for update; +----+------+ | id | name | +----+------+ | 7 | 王五 | | 8 | 赵四 | | 11 | 刘能 | +----+------+ 3 rows in set (0.04 sec) mysql&gt; SELECT event_id,index_name,LOCK_TYPE,LOCK_MODE,LOCK_STATUS,LOCK_DATA FROM performance_schema.data_locks; +----------+------------+-----------+---------------+-------------+------------------------+ | event_id | index_name | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +----------+------------+-----------+---------------+-------------+------------------------+ | 23 | NULL | TABLE | IX | GRANTED | NULL | | 23 | PRIMARY | RECORD | X,REC_NOT_GAP | GRANTED | 7 | | 23 | PRIMARY | RECORD | X | GRANTED | supremum pseudo-record | | 23 | PRIMARY | RECORD | X | GRANTED | 8 | | 23 | PRIMARY | RECORD | X | GRANTED | 11 | +----------+------------+-----------+---------------+-------------+------------------------+ 5 rows in set (0.00 sec) 再插入4呢 mysql&gt; insert into gap values(4,'随便吧'); Query OK, 1 row affected (0.01 sec) 成功了，why?那个lock_data的supremum pseudo-record是什么？ 好的让我们把三个锁串起来看吧，看看上文说的lock_mode的区别，假设有上个记录和当前记录分别是 prev,cur LOCK_MODE 锁模式 锁住的范围 X next-key lock (prev,cur] X,GAP gap lock (prev,cur) X,REC_NOT_GAP record lock cur X就代表了一个next-lock锁，他会锁住从它到上一个节点中间的所有记录，和gap非常像，区别是，gap并不会对当前记录加锁，而next-lock会，所以还记得开头怎么说的吗 next-key lock = record lock + Gap lock！ 那么它的缺点也是，把本来无辜的数据行也锁住了，比如上面的id=4就插不进去 supremum pseudo-record 中文翻译叫做，上限 虚拟记录，很直白，就是一个表示了上限的虚拟记录，当我们锁定7-11的时候，11已经是当前的最大记录了，因此他的后面就是这个虚拟记录，对他加next-key lock就可以保证从11到正无穷的区间都会被锁住 总算快讲完了 Insert Intention Locks 插入意向锁，其实和意向锁没关系，他更像是Gap锁的一个分支 | 11 | PRIMARY | RECORD | X,GAP,INSERT_INTENTION | WAITING | 7 | 这是上文插入时，等待中的锁，这就是个插入意向锁，看他的LOCK_MODE其实和Gap差不多 当有插入操作的时候，他会通过Gap先锁住当前要插入的区间，和Gap不同的是，Gap没有S和X的区别，同一区间的Gap是不会阻塞的，但当Gap变成了插入意向锁的时候就不一样了，因为插入操作一定是个互斥的X锁，所以如果当前区间已经存在了一个Gap锁或者Next-key锁的话他就会被阻塞，也就实现了对区间插入的限制 注意事项 以上所有的测试都是建立在主键或者唯一索引的基础上，如果是个普通索引那么情况会有所不同，但其实区别不大，主要是record锁的区别，当我们通过where能够直接找到记录行的时候 如果是通过唯一索引，那么只会有一个record类型的锁，并不会锁住其他区间 如果是普通索引，那么他会给自己添加next-key锁以及它下一个索引记录添加gap锁，人话就是从 (prev,cur]，(cur,next)这两个区间都会被锁（next这个记录要和主键一起才能确定是否被锁） 我们知道innoDB是聚簇索引，所以二级索引最终都是通过主键索引去访问数据的，也因此当我们查找到了主键索引后，会给主键索引添加一个record锁（X,REC_NOT_GAP），匹配到几个主键索引就添加几个，不会在主键上添加其他任何锁 如果没有主键？不可能的小伙子，只是你没有显示指出主键而已，要存数据肯定是有个隐式的虚拟主键的 总结 锁有两种模式，S和X，读写不兼容，表锁行锁都有； 意向锁是为了减少扫描次数，当有IS和IX的时候肯定不能对表加X锁 行锁的本质是record lock，但它只锁具体的行 范围锁Gap的本质是对它下一个索引记录添加行锁（record锁），表示锁住这个区间 next-key锁真的就是record和gap的结合，真的就是这个意思 两章也只是讲了锁，下一章还有个关键内容——MVCC ","link":"http://www.zerokirin.online/post/mysql-shi-wu-ge-chi-deng-ji-he-suo-xiang-jie-er/"},{"title":"Mysql 并发控制详解（一）","content":"一致性 我们都知道数据库原理中著名的ACID atomicity 原子性 consistency 一致性 isolation 隔离性 durability 持久性 这其中一致性是通过原子性和隔离性保证的，如何保证一致性是数据库的最重要的问题，这是一切的开头 并发一致性问题 这里借用下CS-Notes (gitee.io)的图，图很清楚，但是有几个地方有明显问题 丢失修改 emmm丢失修改有两类，名字很粗暴的叫做第一类和第二类 第一类丢失修改，当前所有的主流数据库都不允许这件事发生，如果事务A回滚了，那么数据库的最新版本就是1100元 （这个我也不知道数据库是怎么实现的，我已经尽可能地搜了(中-english)，但是都是干巴巴的一句话，说什么即便是最低的读未提交也不会这样，那就把它当个特性吧，反正他已经消失在历史舞台了） 时间 取款事务A 转账事务B T1 开始事务 T2 开始事务 T3 查询账户余额为1000元 T4 查询账户余额为1000元 T5 汇入100元把余额改为1100元 T6 提交事务 T7 取出100元把余额改为900元 T8 撤销事务 T9 余额恢复为1000 元（丢失更新） （这个不会发生，回滚了也是1100） 第二类丢失修改，严格来说这个不能算是数据库自身的bug，更像是不可重复读的一个特殊例子，但也不能算作是不可重复读，这里先描述现象，后面我们再详解 时间 转账事务A 取款事务B T1 开始事务 T2 开始事务 T3 查询账户余额为1000元 T4 查询账户余额为1000元 T5 取出100元把余额改为900元 T6 提交事务 T7 汇入100元 T8 提交事务 T9 把余额改为1100 元（丢失更新） （这个是真的会变成1100，白嫖100） 读脏数据 不可重复读 幻影读 时间点 事务A 事务B 1 开启事务 2 开启事务 3 查询数据“老王”，不存在 4 插入数据“老王” 5 提交事务 6 查询数据“老王”，不存在 7 插入数据“老王”，不成功 8 更新数据“老王”，成功 ？ 9 查询数据“老王”，成功 ？ 官网对幻影读的讲解非常模糊，网上还有很多乱讲的东西，比如什么范围中间插入后，个数发生变化，错 我们先看个例子： --事务1 mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.04 sec) mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.04 sec) --事务2 mysql&gt; insert into gap values(8,'老王'); Query OK, 1 row affected (0.05 sec) --事务1 mysql&gt; select count(*) from gap; +----------+ | count(*) | +----------+ | 4 | --没有任何变化 +----------+ 1 row in set (0.00 sec) mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 5 | 李四 | | 7 | 王五 | | 11 | 赵6 | +----+------+ 4 rows in set (0.00 sec) 那么幻读幻到哪去了？继续看 --事务1 mysql&gt; insert into gap values(8,'赵四'); ERROR 1062 (23000): Duplicate entry '8' for key 'gap.PRIMARY' 看到了么，明明没有查到，但是却没法添加，但他却可以被更新 mysql&gt; update gap set name = '刘能' where id = 8; Query OK, 1 row affected (0.04 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql&gt; select * from gap; +----+------+ | id | name | +----+------+ | 1 | 张三 | | 5 | 李四 | | 7 | 王五 | | 8 | 刘能 | | 11 | 赵6 | +----+------+ 5 rows in set (0.00 sec) 明明没有的数据，凭空冒了出来这才是幻读，和不可重复读有很大区别。 事务隔离等级 read uncommitted 读未提交 read committed 读已提交 repeatable read 可重复读 serializable 串行化 从上到下依次严格，每个隔离等级都解决了一个并行问题 隔离等级 未解决的并发一致性问题 解决的并发一致性问题 读未提交 幻影读，不可重复读，读脏数据，第二类丢失修改 第一类丢失修改 读已提交 幻影读，不可重复读，第二类丢失修改 读脏数据，第一类丢失修改 可重复读 幻影读，第二类丢失修改（具体类型具体分析） 不可重复读，读脏数据，第一类丢失修改 串行化 幻影读，不可重复读，读脏数据，两类丢失修改 暂时先不要关注隔离等级，让我们先了解下实现他们的前置知识——锁和MVCC ","link":"http://www.zerokirin.online/post/mysql-shi-wu-ge-chi-deng-ji-he-suo-xiang-jie-yi/"},{"title":"Mysql基础回顾","content":"ORM库用起来是真的爽，面试的时候被问sql也是真的爽，人自闭了重新复习吧 增删改查 select (8)SELECT (9)[ALL|DISTINCT|DISTINCTROW|TOP] (11){*|talbe.*|[table.]field1[AS alias1][,[table.]field2[AS alias2][,…]]} (1)FROM &lt;left_table[,…]&gt; (3)[[{LEFT|RIGHT|INNER|CROSS}] JOIN &lt;right_table&gt; (2) ON &lt;condition&gt;] (4)[WHERE &lt;where_condition&gt;] (5)[GROUP BY {col_name | expr | position}, ... (6)[WITH ROLLUP]] (7)[HAVING &lt;where_condition&gt;] (10)[ORDER BY {col_name | expr | position} [ASC | DESC]} 这是一个缩略版的select的解释顺序，括号中的数字代表解释的优先级，可以看到观察到几个点 order by，field_list 等的优先级可以说是整个流程的最低级 group by 和 having 比where的优先级要低，也就是说所有的分组操作都是来源于where筛选后的结果 having做的是对分组后的结果集的再次查询，因此应该先使用where过滤，比如说找到非A用户的登录记录，筛选条件是可以放到having后的，但是A用户已经被分组了，同时参与了count等运算，只是最后剔除了这一组，所以说having可以看作是where的补充，能不用就不用 group by 和 order by 都支持position，也就是下标访问，不过是从1开始的，数组就是field_list insert insert into 有三种写法，官网的语句太复杂了，简化一下 一种就是最基础的 INSERT INTO tbl_name [(a,b,c)] VALUES (1,2,3)[, (4,5,6), (7,8,9)]; --或者是 INSERT INTO tbl_name [(a,b,c)] VALUES ROW(1,2,3)[, ROW(4,5,6), ROW(7,8,9)]; table后面可选择列名，如果不选的话，values后面每个括号中的内容都要按字段顺序填入 多个括号就是批量插入的意思 这种是用set代替了values INSERT INTO friend SET name = 'Kim', isBFF = true ; 用法和普通的一样，类似于update语句，个人感觉更符合直觉一点，但是不支持批量插入 比较特殊的，从另一个表搜索数据然后插入 INSERT INTO tbl_temp2 (fld_id) SELECT tbl_temp1.fld_order_id FROM tbl_temp1 WHERE tbl_temp1.fld_order_id &gt; 100; --8.0.19版本后支持用table字段替代select INSERT INTO ta TABLE tb; --select * from tb;支持limit和order by insert的特殊用法 插入的行的主键已经存在 ON DUPLICATE KEY UPDATE ，存在就更新，大概有三种用法 --可以引用a，b列的值，类似于分别设置c=1+2和c=4+5 INSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6) ON DUPLICATE KEY UPDATE c=VALUES(a)+VALUES(b); --8.0.19版本后增加了AS关键字，可以通过表名来引用行 INSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6) AS new ON DUPLICATE KEY UPDATE c = new.a+new.b; --更骚的是还支持指定列名 INSERT INTO t1 SET a=1,b=2,c=3 AS new(m,n,p) ON DUPLICATE KEY UPDATE c = m+n; --如果是插入，影响条数1，更新是2，内容不变的话是0 --这个用法在insert into select中也是可以的，其实就是把values...这部分换成了select...只放例子不再赘述 INSERT INTO t1 SELECT * FROM (SELECT c, c+d AS e FROM t2) AS dt ON DUPLICATE KEY UPDATE b = e; --insert ...select语句的update部分不能使用VALUES()会报错 insert开头的可选项 指令 已存在 不存在 举例 insert 报错 插入 insert into names(name, age) values(“小明”, 23); insert ignore 忽略 插入 insert ignore into names(name, age) values(“小明”, 24); replace 替换 插入 replace into names(name, age) values(“小明”, 25); 重点看第三个，replace和on duplicate key的区别 如果主键不存在，都是insert，无区别 如果存在，replace是真的delete后再insert，原有数据被清空，因此新行的值要写全不然会置零 on duplicate key是只更新update后面描述的结果，不是删除插入 delete 这个没什么好说的用法不多基础语法如下： --删除一个表的数据 DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name [[AS] tbl_alias] [PARTITION (partition_name [, partition_name] ...)] --这里是分区 [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] --多个表一起删或者作为辅助查询，下面两个用法一样，只是写法不同 DELETE [LOW_PRIORITY] [QUICK] [IGNORE] tbl_name[.*] [, tbl_name[.*]] ... FROM table_references --此处的写法和select中的join一样，支持各种join [WHERE where_condition] --实例1. DELETE t1, t2 FROM t1 INNER JOIN t2 INNER JOIN t3 WHERE t1.id=t2.id AND t2.id=t3.id; DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name[.*] [, tbl_name[.*]] ... USING table_references [WHERE where_condition] --实例2. DELETE FROM t1, t2 USING t1 INNER JOIN t2 INNER JOIN t3 WHERE t1.id=t2.id AND t2.id=t3.id; --没啥子区别，join部分一模一样 --比较实用的例子，从t1中删掉t2没有的行 DELETE t1 FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL; update 最朴实无华的语法（非官方定义） UPDATE Tab1, [Tab2, [INNER JOIN | LEFT JOIN] Tab1 ON Tab1.C1 = Tab2.C1] SET Tab1.C2 = [Tab2.C2, Tab2.C3 =] expression WHERE Condition; 如果只更新一个表就很简单，直接再set后面写出谁等于谁就好 UPDATE t SET id = id + 1 ORDER BY id DESC; --这里用了orderby desc是因为，如果升序来，会先把1-&gt;2，这样就有两个2的记录了，违反了主键约束原则，因此降序更新 多个表的例子（多表时不能用order by 和limit） UPDATE items,month SET items.price=month.price WHERE items.id=month.id; --这里默认是inner join 左连接例子 UPDATE Employees e LEFT JOIN Performance p ON e.performance = p.performance SET salary = salary + salary * 0.025 WHERE p.percentage IS NULL; 需要注意的一个问题是，update中where的子语句不能直接使用当前表的结果，例如： mysql&gt; UPDATE items &gt; SET retail = retail * 0.9 &gt; WHERE id IN &gt; (SELECT id FROM items &gt; WHERE retail / wholesale &gt;= 1.3 AND quantity &gt; 100); ERROR 1093 (HY000): You can't specify target table 'items' for update in FROM clause 需要将子查询移到一个新的派生表中 UPDATE items, (SELECT id FROM items WHERE id IN (SELECT id FROM items WHERE retail / wholesale &gt;= 1.3 AND quantity &lt; 100)) AS discounted SET items.retail = items.retail * 0.9 WHERE items.id = discounted.id; 数据类型 数据分为数值类型，字符串类型，时间类型，空间类型 数值类型 整型 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 byte (-128，127) (0，255) 小整数值 SMALLINT 2 bytes (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 bytes (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 bytes (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 bytes (-9,223,372,036,854,775,808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 借用菜鸟的表格，可以看到每种类型的大小已经固定了，而在类型声明的时候有可能会有这种情况 CREATE TABLE test( id1 int(1), id2 tinyint(1) ); 这里内的值我们暂时称为M，M表示的意思就是实际的显示位数，但是上述写法是没有意义的，因为int和tinyint本身的长度是已经确定的，加括号的真正写法是 CREATE TABLE test( int_test_M int(3) ZEROFILL, ); 只有用zerofill 修饰才有意义，加了zerofill后，会默认添加unsigned参数，也就是变成无符号数（非负数） mysql&gt; desc test1; +------------+--------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------------------+------+-----+---------+-------+ | int_test_M | int(3) unsigned zerofill | YES | | NULL | | +------------+--------------------------+------+-----+---------+-------+ 1 row in set (0.02 sec) mysql&gt; select * from test1; +------------+ | int_test_M | +------------+ | 001 | --这里吧一位的长度补足了 | 1111 | --没啥用了 +------------+ 2 rows in set (0.00 sec) As of MySQL 8.0.17, the ZEROFILL attribute is deprecated for numeric data types; you should expect support for it to be removed in a future version of MySQL. Consider using an alternative means of producing the effect of this attribute. For example, applications could use the LPAD() function to zero-pad numbers up to the desired width, or they could store the formatted numbers in CHAR columns. 官方文档已经说了zerofill这玩意已经快废弃了，就别用这种骚操作了 另外还有两个整数型 BIT[(M)] 表示Mbits的数据大小，默认M为1，存储二进制数据，长度就是M，超过了大小则无法插入 BOOL/BOOLEAN 本质上是TINYINT(1)，1是'true' 0是'false'，其他的值既不是true也不是false 浮点数 类型 大小 范围（有符号） 范围（无符号） 用途 FLOAT 4 bytes (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 bytes (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 先说float和double，这是最常见的单精度和双精度浮点数，这里我们在M的基础上引入D，M说过了就是位数，D则代表了小数点后的位数，默认情况下float的D是7，double的D是15 这里float还有个特殊的骚操作，float[p]，用p代替了DM，p在0-24时当作float，25-53时当作double 但是给float和double指定精度的操作都是mysql特有的，并不是sql标准语法，并且官方文档已经说明，从8.0.17开始将不再建议此写法，同时有可能在未来的版本中删除，因此不要写这种奇奇怪怪的东西了，又不方便拓展又不能节省空间，何必呢 这里再说下DECIMAL，这个类型和float，double完全不一样，默认情况下他的(M,D)是(10,0)，M最大支持65，D最大30，千万不要把他理解成double，这是完全不一样的类型，众所周知，计算机内浮点数的存储方式和整型不一样，因为阶码和尾数的存在永远只能近似，但是DECIMAL完全不一样（三遍） DECIMAL的英文含义就是十进制，因此它的存储结构和他的名字类似 数位 字节 最大值（有符号） 最大值位数 0 0 0 0 1-2 1 127 3 3-4 2 32767 5 5-6 3 8388607 7 7-9 4 2147483647 10 这样，每一个位数的最大值9999999都可以被他的空间完全表示出来，位数逢十进一，每10位占4个字节，整数和小数分开存储，举个例子，decimal(26,14)，小数14位，9+5，所以需要4+3=7字节大小存储小数，整数12位，9+3，也就是4+2=6字节存储，一共6+7=13字节大小 通过这种饱和式的存储方式，可以实现真正意义上的精度，再也不会有1-0.0000000001!=0.9999999999的情况出现，当然缺点就是存储空间大，但如果不是非要用那么大的精度的话，其实还好 当然这个类型也支持unsigned和zerofill，但是同样在8.0.17后已经不被推荐了，以后少用 字符串类型 字符串类型也大概可以分成两类，字符串和二进制字符串，当然还有一类比较特殊的ENUM和SET，我们先讲这两个 ENUM 枚举，SET 集合 共同点： 虽然显示格式是字符串，但是实际上存储的是其定义时的索引位置 直接插入整型变量的时候会当作索引 如果插入的字符串变量不在声明之中，会尝试将其索引化 空值是null，''是一个合法的值，代表着索引0的值，不是null 区别就是ENUM只能存定义里的其中一个，SET是存任意多个 在存储上，ENUM只需要存储对应字符串的索引即可，最多支持65535个可选项，因此索引值最大也就是65535，正好是2Bytes的存储上限 而SET，集合就不一样了，集合有很多操作，比如交并补，因此set中子项的保存形式是以二进制字符串中1的位置来确定的，SET('a','b','c','d') 的索引值如下表 SET Member Decimal Value Binary Value '' 0 0000 'a' 1 0001 'b' 2 0010 'c' 4 0100 'd' 8 1000 这样集合的交并补就变成了两个二进制数的与或非操作 SET最大支持64个子项，也就是最大8Bytes，具体的字节数为 (N+7)/8四舍五入 在匹配的时候可以使用函数FIND_IN_SET()也可以用 like '%value%' 字符串和二进制字符串 类型 大小 用途 CHAR(M) 0-255 个字符 定长字符串 VARCHAR(M) 取决于整行的大小 变长字符串 TINYBLOB 0-255 bytes 不超过 255 个字符的二进制字符串 TINYTEXT 0-255 bytes 短文本字符串 BLOB(M) 0-65 535 bytes 二进制形式的长文本数据 TEXT(M) 0-65 535 bytes 长文本数据 MEDIUMBLOB 0-16 777 215 bytes 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215 bytes 中等长度文本数据 LONGBLOB 0-4 294 967 295 bytes 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295 bytes 极大文本数据 表是从菜鸟拿的，错得离谱。。。 先从老生常谈的char与varchar说起 char char是固定长度字符串，一般用法是char(M)，如果省略M，默认值1最大长度255，早在5.0以后M就不是字节了，M代表的是字符，菜鸟这么多年都没改过表格吗。。。 一个utf8编码下的中文字符占了3个字节，256*3=768字节，这才是CHAR的标准上限，但是如果使用utf8mb4过长的编码格式，就会超过768字节，innoDB会将多余的字节存到其他位置，所以只要是5.0版本以后就根本不需要care字节数的问题 存储时如果不足M长度，自动在末尾补' '填充，这也是为啥char类型的末尾' '会消失 varchar varchar和char的区别不只是可变长度，其存储结构也不一样 在varchar中开头需要预留1或者2个字节作为长度的值，分别能表示255和65535个字节的长度，但这是字节数的理论上限，M的范围呢？ 在innoDB中要求每一行一共能存储65535字节大小的数据，这是所有列共享的，因此M的大小还受到其他的列的影响，假如只有一列，那么一个中文字符大小3个字节，算上开头的两个表示长度的字节，一个NULL标记字节，65535-2-1=65532，65532/3=21844，这就是M在这种情况下的理论最大值 可以看到这个值是很不稳定的，因为还要考虑其他的列，因此不建议设这么大 BINARY和VARBINAR 这俩和char，varchar非常相似，几乎一样，官方文档直说区别仅仅是保存的二进制字符串而已，不再赘述 剩下的主要就是BLOB和TEXT 在mysql的官方文档中，可以看到它和varchar与varbinary十分类似 In most respects, you can regard a BLOB column as a VARBINARY column that can be as large as you like. Similarly, you can regard a TEXT column as a VARCHAR column. BLOB and TEXT differ from VARBINARY and VARCHAR in the following ways: For indexes on BLOB and TEXT columns, you must specify an index prefix length. For CHAR and VARCHAR, a prefix length is optional. See Section 8.3.5, “Column Indexes”. BLOB and TEXT columns cannot have DEFAULT values. 主要的区别就是TEXT和BLOB需要指定前缀位数作为索引，不可以设置默认值 他们的存储方式取决于InnoDB Row Formats， 在mysql5.7.9以后默认是dynamic 我们暂且只介绍dynamic模式，在这种存储方式下，数据会尽可能的填充满整个行，但不是我们所谓的65535的上限值，官方提供了一个例子 mysql&gt; CREATE TABLE t4 ( c1 CHAR(255),c2 CHAR(255),c3 CHAR(255), c4 CHAR(255),c5 CHAR(255),c6 CHAR(255), c7 CHAR(255),c8 CHAR(255),c9 CHAR(255), c10 CHAR(255),c11 CHAR(255),c12 CHAR(255), c13 CHAR(255),c14 CHAR(255),c15 CHAR(255), c16 CHAR(255),c17 CHAR(255),c18 CHAR(255), c19 CHAR(255),c20 CHAR(255),c21 CHAR(255), c22 CHAR(255),c23 CHAR(255),c24 CHAR(255), c25 CHAR(255),c26 CHAR(255),c27 CHAR(255), c28 CHAR(255),c29 CHAR(255),c30 CHAR(255), c31 CHAR(255),c32 CHAR(255),c33 CHAR(255) ) ENGINE=InnoDB ROW_FORMAT=DYNAMIC DEFAULT CHARSET latin1; ERROR 1118 (42000): Row size too large (&gt; 8126). Changing some columns to TEXT or BLOB may help. In current row format, BLOB prefix of 0 bytes is stored inline. 算算字节数，255*33=8415这点字节还远不到65535，但是却提示超过了8126，这个数是哪来的呢？ 原来65535是mysql层判断的，实际存储的时候还需要存储引擎去判断，innoDB的策略是略小于存储页面大小的一半，默认的页面大小是16KB，它的一半就是8192，因此在innoDB看来最大行不能超过8126字节，这样上限我们就搞清楚了 TEXT与BLOB类型都会尽可能的存在这一行中，也就是B+树的叶子节点中，当长度已经满了的时候，会从所有的字段中选择最长的一列放到外部存储，dynamic的思想是，如果要用外部页面存储，就把整个数据都放过去，页内只留20字节的指针指向外部存储，对于长度小于40字节的TEXT和BLOB，并不会转移到外部，而是直接存在行内 BLOB和TEXT都支持M的用法（但是真的别用了，挺没意义的，都已经用这个类型了还纠结长度不如取用varchar，人家速度还快），如果用了M，会返回一个能满足M的要求的最小的预定义的TEXT或BLOB，举个例子： mysql&gt; alter table test1 add text_test text(20); mysql&gt; desc test1; +----------------+--------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +----------------+--------------------------+------+-----+---------+-------+ | int_test_M | int(3) unsigned zerofill | YES | | NULL | | | bit_test_M | bit(3) | YES | | NULL | | | decimal_test_M | decimal(65,0) | YES | | NULL | | | binary_test | binary(6) | YES | | NULL | | | set_test | set('1','一') | YES | | NULL | | | text_test | tinytext | YES | | NULL | | +----------------+--------------------------+------+-----+---------+-------+ 6 rows in set (0.02 sec) 可以看到，text_test并没有像其他的一样有M，而是直接分配了一个tinytext，blob同理，至此字符串基本上讲完了 时间类型 类型 大小 ( bytes) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 '-838:59:59'/'838:59:59' HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07，本质是一个存着时间戳的四字节整型 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 datetime和timestamp有个区别就是，当存入数据库的时候，datetime存储的是当前时区的时间，而时间戳是全球统一的，无需担心时区的问题 8.0.19版本开始，可以在datetime和timestamp类型修改的时候添加时间偏移量 8.0.22版本开始，支持通过CAST()函数将timestamp转换成特定时区的datetime值 举两个魔改的官方例子解释 mysql&gt; SELECT @@system_time_zone; --提示了系统时区，现在是EST，北美东部标准时间，-05:00，我国是+08:00 +--------------------+ | @@system_time_zone | +--------------------+ | EST | +--------------------+ mysql&gt; CREATE TABLE ts ( -&gt; id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY, -&gt; col TIMESTAMP NOT NULL -&gt; ) AUTO_INCREMENT = 1; mysql&gt; SET @@time_zone = 'SYSTEM'; -- -05:00 mysql&gt; INSERT INTO ts (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00'); --这里插入了三个，后两个的含义是，当前时区为+05:30的10.10.10，和当前时区-08:00的10.10.10，如果转换成UTC，分别应该-5.30和+8.00，但和第一个值明显对不上，原因看下一个 mysql&gt; SET @@time_zone = '+00:00'; mysql&gt; INSERT INTO ts (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00'); --这里已经将时区切换成标准UTC时间了，再让我们看看结果，下面的23和56都是一样的，也就是说，当我们手动添加时区的偏移量的时候，会屏蔽掉设置的时区 mysql&gt; SET @@time_zone = 'SYSTEM'; --这里又切换回了-5的时区，导致UTC时间的10.10.10，在显示的时候按照-5的时区显示，变成了05.10.10 mysql&gt; SELECT col, UNIX_TIMESTAMP(col) FROM ts ORDER BY id; +---------------------+---------------------+ | col | UNIX_TIMESTAMP(col) | +---------------------+---------------------+ | 2020-01-01 10:10:10 | 1577891410 | --这里代表了-5:00的时区下的时间 | 2019-12-31 23:40:10 | 1577853610 | | 2020-01-01 13:10:10 | 1577902210 | | 2020-01-01 05:10:10 | 1577873410 | --这里才是真实的UTC标准时间 | 2019-12-31 23:40:10 | 1577853610 | | 2020-01-01 13:10:10 | 1577902210 | +---------------------+---------------------+ mysql&gt; CREATE TABLE dt ( -&gt; id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, -&gt; col DATETIME NOT NULL -&gt; ) AUTO_INCREMENT = 1; mysql&gt; INSERT INTO dt (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00'); mysql&gt; SET @@time_zone = '+00:00'; mysql&gt; INSERT INTO dt (col) VALUES ('2020-01-01 10:10:10'), -&gt; ('2020-01-01 10:10:10+05:30'), ('2020-01-01 10:10:10-08:00'); --从这里的1，4可以看到，不管在哪个时区下，datetime的值只取决于获取时的时间，不随时区变化而改变 --但是一旦手动设置了偏移量，偏移量的大小都会先计算一次时区偏移，比如23的结果，都是在10.10.10的基础上-5，然后再-05.30和+08.00 --也就是说它老把自己当成UTC时间，手动改修改偏移量后然后自作聪明的想存进该时区时间，所以会先算一次时区，再计算时间戳 mysql&gt; SET @@time_zone = 'SYSTEM'; mysql&gt; SELECT col, UNIX_TIMESTAMP(col) FROM dt ORDER BY id; +---------------------+---------------------+ | col | UNIX_TIMESTAMP(col) | +---------------------+---------------------+ | 2020-01-01 10:10:10 | 1577891410 | | 2019-12-31 23:40:10 | 1577853610 | | 2020-01-01 13:10:10 | 1577902210 | | 2020-01-01 10:10:10 | 1577891410 | | 2020-01-01 04:40:10 | 1577871610 | | 2020-01-01 18:10:10 | 1577920210 | +---------------------+---------------------+ 可以看到，timestamp和datetime在面对不一样的时区时做的操作是完全不同的，相比之下timestamp更通用一些 timestamp和datetime还支持自动更新 created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP --创建时间 updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP --更新时间 至此时间类型也差不多讲完了，空间类型这个是真的一般用不到，等用到了再细究不迟，这里就不再赘述了，现在才发现其实mysql的官方文档才是最好的教程，远比网上搜的东西清楚 ","link":"http://www.zerokirin.online/post/mysql-ji-chu-hui-gu/"},{"title":"如何在github上开源自己的包","content":"由于go没有自带的栈结构，因此我们手写了两种stack方便刷题及日后使用，顺便尝试下开源 由于栈有切片和链表两种实现方式，因此仓库内有两个package，此时有两种发布方式 1. 将两个package当作一个module发布 此时只要在根目录上创建go.mod文件，文件内容如下 module github.com/00LT00/go-stack go 1.15 这样我们的module根目录地址就是github.com/00LT00/go-stack 此时总文件结构 │ go.mod │ README.md │ ├─nodelistStack │ stack.go │ stack_test.go │ └─sliceStack stack.go stack_test.go 下属的nodelistStack和sliceStack作为go-stack这个module的子package存在 import &quot;github.com/00LT00/go-stack&quot; 此时go.mod文件中会有版本号，和最后一次提交的时间与md5相关 当然也可以打tag，或者通过github release发布一个新的版本，比如现在的最新版就是 require github.com/00LT00/go-stack v0.4.0 // 根目录下没有package有可能会报错，应手动写入go.mod中 当然只是引入了go-stack是肯定不能用的，毕竟根目录下毛都没有，要想用肯定要引入两个package之一 import ( stack1 &quot;github.com/00LT00/go-stack/sliceStack&quot; stack2 &quot;github.com/00LT00/go-stack/nodelistStack&quot; ) 这样的不足之处在于两者依赖同一个tag，如果对其中一个进行修改，打出来的新tag对两个都会生效，因此还有第二种方式 2. 发布两个不一样的module 文件结构如下 │ README.md │ ├─nodelistStack | go.mod │ stack.go │ stack_test.go │ └─sliceStack go.mod stack.go stack_test.go 两个go.mod文件开头就自由发挥 module github.com/00LT00/go-stack/nodelistStack go 1.15 module github.com/00LT00/go-stack/sliceStack go 1.15 这时可以通过github release 发布不同的版本号解决问题 这里就给子目录单独创建了一个版本号 v0.1.3 虽然引用方式和之前没有任何变化，仍然是 import ( stack2 &quot;github.com/00LT00/go-stack/nodelistStack&quot; ) 但是go.mod文件中已经发生了变化 require github.com/00LT00/go-stack/nodelistStack v0.1.3 此时这就是一个单独的module，自己管理自己的package，这样的好处是，可以单独对两个目录发布不一样的版本 可以参考go mod 官方文档 If a module is defined in a subdirectory within the repository, that is, the module subdirectory portion of the module path is not empty, then each tag name must be prefixed with the module subdirectory, followed by a slash. For example, the module golang.org/x/tools/gopls is defined in the gopls subdirectory of the repository with root path golang.org/x/tools. The version v0.4.0 of that module must have the tag named gopls/v0.4.0 in that repository. ","link":"http://www.zerokirin.online/post/ru-he-zai-github-shang-kai-yuan-zi-ji-de-bao/"},{"title":"Golang 运行时（一）","content":"内存分区 一个应用程序在运行的时候会分出对应的区域 text 代码区 用于存放cpu执行的机器指令，只读 data 数据区 初始化后的全局变量 初始化后的静态变量（包括全局和局部） 常量 bss 未初始化区 未初始化的全局变量 未初始化的静态变量 尽管会被默认分配为零值，但仍属于未初始化区 stack 栈区 由编译器自动分配释放的，一般用于存储哈描述的参数值、返回值、局部变量等。一般只有1M，可自动扩充，基本上也就是函数运行的空间，所以无限递归会造成的是栈溢出 分配的方式是从高地址向低地址 heap 堆区 由程序员手动分配，手动回收或者较高级语言有GC自动回收 分配的地址是在栈区地址和.bss区之间 逃逸分析 func toHeap() *int { var x int return &amp;x } func toStack() int { y := new(int) *y = 1 return *y } func main() { } 如果我们暂时忘记go，用C/C++语言的思维来看，上述的toHeap()函数就是一个典型的空指针错误，在函数内部创建了一个变量，调用结束后将指针返回，而该地址是随着函数的调用而被分配在函数栈上的，因此当调用结束后栈会被清空，该指针就成了一个野指针。而对于toStack函数来说，手动使用new从堆上分配了一块变量，直到使用对应的delete函数手动释放空间 但是在go中，情况完全不同，go在一定程度上消除了堆栈的区别，在编译的时候会自动进行逃逸分析，将逃逸的对象放到堆上，不逃逸的对象放到栈上 由于x是返回值，而这个指针会被函数外部进行操作，从外部是可以找到这个变量的，因此就可以说是变量逃逸 第一种情况就可以说发生了逃逸，go会在编译阶段将x放到堆上，而y在函数结束后就无法访问了，因此分配到栈上，随着函数结束而消失 Go的GC判断变量是否回收的实现思路：从每个包级的变量、每个当前运行的函数的局部变量开始，通过指针和引用的访问路径遍历，是否可以找到该变量，如果不存在这样的访问路径，那么说明该变量是不可达的，也就是说它是否存在并不会影响后续计算结果。 逃逸案例 指针逃逸 func f() *int{ var i int i = 1 return &amp;i } 局部变量大小过大 s := make([]int, 0, 10000)//其实就是stack区不够分了，所以分到heap上 动态类型逃逸 cap:= 20 s := make([]int, 0, cap) //大小是动态的，不能确定，因此放入heap 闭包引用逃逸 //闭包函数在这里声明了两个隐式变量a，b，当f()被多次调用的时候，其使用的是被Fibonacci()创建出来大的时候的a，b，因此a，b不会随着f()函数的结束而小时，因此会被分配到heap func Fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a } } f:= Fibonacci() 切片，map逃逸 i := 1 s := make([]*int, 0, 10) //m没有被转移给其他的函数调用，也没有分配过大的空间，也不是全局变量，因此没有必要分配到heap上 s = append(s, &amp;i) //i被添加到m中，没有人知道什么时候会用到，因此无论有没有被用到，都会分配到heap上 j := 1 m := make(map[int]*int) //一个道理，也是分配在stack上 m[1] = &amp;j //heap上 分配位置的原则 变量是否被取地址 变量是否发生逃逸 ","link":"http://www.zerokirin.online/post/golang-yun-xing-shi-yi/"},{"title":"Golang基础语法题","content":" 使用值为nil的slice、map会发生啥？ slice可以正常添加内容，map会报错，需要通过make分配地址 // map 错误示例 func main() { var m map[string]int m[&quot;one&quot;] = 1 // error: panic: assignment to entry in nil map // m := make(map[string]int)// map 的正确声明，分配了实际的内存 } // slice 正确示例 func main() { var s []int s = append(s, 1) } 再往细了说，slice底层用指针维护了一个数组，无论是empty还是nil都可以通过append进行扩容，毕竟append强制返回一个原类型的结构，但是map的底层是一个叫做hmap的东西，非常复杂，需要通过makemap这个函数进行初始化才能进行使用（比如说最起码得给人一个hash函数不是）因此对着nil直接赋值是不现实的 map中key是否存在？ 对于不存在的key，map一定会返回默认零值，因此需要通过第二个参数来判断 // 错误的 key 检测方式 func main() { x := map[string]string{&quot;one&quot;: &quot;2&quot;, &quot;two&quot;: &quot;&quot;, &quot;three&quot;: &quot;3&quot;} if v := x[&quot;two&quot;]; v == &quot;&quot; { fmt.Println(&quot;key two is no entry&quot;) // 键 two 存不存在都会返回的空字符串 } } // 正确示例 func main() { x := map[string]string{&quot;one&quot;: &quot;2&quot;, &quot;two&quot;: &quot;&quot;, &quot;three&quot;: &quot;3&quot;} if _, ok := x[&quot;two&quot;]; !ok { fmt.Println(&quot;key two is no entry&quot;) } } 两种取值方式调用的是不同的函数，但他们的区别也仅仅就是判断下key存不存在而已 string类型可以修改吗 不能，go中的string类型本质是一个slice，里面存储的是utf-8，但是utf-8是不固定长的（utf-8的意义就是为了压缩字节数）英文字母和数字是1个字节，但中文是3或4字节，这就导致如果直接对下标进行操作的话，会导致编码错乱。 要修改可以转换成[]byte类型，此时实质上是把每个字符转换成了rune类型，rune也就是int32的别名，因此4字节可以存储下完整的utf-8中文字符了，不用担心结构错乱 switch 默认带有break，如果想和其它语言一样继续执行下一个case，可以写上fallthrough 解析json时的默认数据格式 Bool 对应JSON布尔类型 float64 对应JSON数字类型 string 对应JSON字符串类型 []interface{} 对应JSON数组 map[string]interface{} 对应JSON对象 nil 对应JSON的null 简短声明 只能在函数内部进行简短声明，如果是函数外部则只能用var struct的变量不能用:=（别问我为什么，官方文档说的无法推断） 不能重复申明，至少有一个新的变量名才行 map迭代顺序 完全无序，1.9版本以前，如果是对硬编码的map还可以说有序，但是1.10版本在迭代的时候已经纯随机了，详见go语法基础巩固（map） recover recover函数是用来捕捉祖父级调用时的异常，需要用在defer中 func main(){ defer func(){ r:= recover() log.Println(r) }() panic(&quot;error&quot;) } 闭包函数传参数 如果不传参数进去，他们引用的都是同一个变量， 这样当迭代的时候，还没有执行到的goroutine打印出来的是已经变化了的i，不是调用时的i func main(){ for i:=0;i&lt;10;i++{ go func(i int){ fmt.Println(i) }(i) //如果不传参会导致他们实际使用的是同一个变量 } ...... } goroutine内存泄露 本质上就是goroutine函数执行过程中没有正确的结束，因此就不会被释放，最终可能会导致内存越来越高 for select 一起使用的时候break 标签跳出 若无标签，直接break只是退出select语句而已 func main() { var ch chan int exit: for { select { case v, ok := &lt;-ch: if !ok { break exit//跳出了整个exit循环，直接到最下方了 } fmt.Println(v) } } fmt.Println(&quot;exit&quot;) } sort包对slice进行快排及搜索操作 注：当要找的目标不存在时，返回的值是其在排序后因该存在的位置 func main() { ints := []int{1, 2, 5, 4, 3, 7} sort.Ints(ints) fmt.Println(sort.SearchInts(ints, 6)) fmt.Println(sort.SearchInts(ints, 4)) fmt.Println(ints) } ------------ 5 //没有6，但是6应该放在第5个位置（从0开始） 3 //4在第3个位置 [1 2 3 4 5 7] 数组和切片的区别 数组 切片 值类型 引用类型 var arr [5]int var sli []int 固定长度 可变长度 作为函数参数时是值传递，复制一份 引用传递，相当于传了地址，本质上还是通一slice new make 区别 new make 初始化一个指向类型的指针 为slice，map，chan初始化出其需要的 返回值是指向分配的零值的指针，因此对引用类型的变量返回的就是nil 返回的是类型的一个经过初始化的实例 for 循环多变量赋值 for循环中如果有多个变量，需要平行赋值 for i, j := 0, 0; i &lt; j; i, j = j+1, i+1 { //最后一个 i++,j++是不被允许的，因为这本身就是两个语句 ...... } go的接口是什么 interface，方法的集合，不关心数据，只关心如何实现，只要实现了interface定义的方法，就可以说实现了该接口，也因此，一个空的interface{}可以说是被所有的数据类型所共有的一个父类，也可以说所有的数据类型都是的本质都是interface，其底层包括eface（无方法），iface（有方法）两种结构 对于第一种，在动态赋值的时候，其内部的_type指针会随数据类型变化 //不带函数的interface var e interface{} tty, err := os.OpenFile(&quot;/dev/tty&quot;, os.O_RDWR, 0) if err != nil { return nil, err } e = tty 这里的e完全就是个工具人，赋值以后的结构就是 第二种除了其原本的静态类型指针以外，还有一个动态混合类型指针，eg. //带函数的interface var r io.Reader tty, err := os.OpenFile(&quot;/dev/tty&quot;, os.O_RDWR, 0) if err != nil { return nil, err } r = tty 这本来是一个静态类型的io.Reader，但是我们知道os.File类型一样实现了Reader方法，因此可以说os.File实现了io.Reader接口，因此r = tty是被允许的这时候，结构就变为了 可以看到，其依然是静态类型io.Reader，但是实际上他已经是动态混合类型了 因此我们可以通过对interface的操作实现多态 类型断言 当想知道interface的具体类型时就需要断言 var e interface{} tty, err := os.OpenFile(&quot;/dev/tty&quot;, os.O_RDWR, 0) if err != nil { return err.Error() } e = tty //接上例 _, ok := e.(*os.File) //断言是否是该类型 if !ok { return &quot;error&quot; } switch v := e.(type) { //根据e的不同类型选择不同的方法 case *os.File: return v.Name() default: return &quot;error&quot; } 方法和函数是两个概念 但是怎么看他们也都差不多。。。我更愿意把方法称作成员函数，方法只不过是在函数的基础上，写上了这是属于谁的函数而已 func(s Service)Run(){//最奇怪的用法，这里的s是通过值传递调用的，因此这里无论做什么都不能影响原本的s，而且对于大型结构体还会导致频繁的复制。。暂时没用过。。。 } func(s *Service)Run(){//方法，大写开头，因此是公开函数，函数外部可以调用 foo() //同一个包内调用 } func foo(){//函数,小写开头，所以是包内函数，其他package不能访问 } type P struct { val int } func main() { p := new(P) p.val = 1 fmt.Printf(&quot;%p,%p,%v\\n&quot;, &amp;p, p, p) p.addr() p.addr2() fmt.Printf(&quot;%p,%p,%v\\n&quot;, &amp;p, p, p) } func (p P) addr() { i := &amp;p p.val = 2 fmt.Printf(&quot;%p,%p,%v\\n&quot;, &amp;i, &amp;p, p) } func (p *P) addr2() { fmt.Printf(&quot;%p,%p,%v\\n&quot;, &amp;p, p, p) p.val = 3 } ------------------------------ 0xc000006028,0xc0000120b0,&amp;{1} 0xc000006038,0xc0000120e0,{2} 0xc000006040,0xc0000120b0,&amp;{1} 0xc000006028,0xc0000120b0,&amp;{3} 可以看到134行很明显是同一个地址，前面的是放p指针的地址，因此函数调用的时候只复制了地址过去，而第2行就明显的是值传递了 slice的扩容机制 如果申请容量长度大于2倍的旧容量，则最终容量就是新申请的容量 如果旧其切片长度小于1024则新容量变为两倍 如果是大于等于1024，则旧容量增加原来的4分之一，直到大于新容量为止，然后进行内存对齐操作，因此是大于等于 如果容量计算溢出了，那新容量就是溢出之前的值 一旦触发扩容，则扩容后的slice就指向了新的地址 empty slice 和nil slice func main() { s1 := make([]int, 0) var s2 []int str, _ := json.Marshal(struct { S1 interface{} `json:&quot;s1&quot;` S2 interface{} `json:&quot;s2&quot;` }{ S1: s1, S2: s2, }) fmt.Printf(&quot;%+s&quot;, str) } ------------------- {&quot;s1&quot;:[],&quot;s2&quot;:null} Data Race问题 互斥锁sync.Mutex或者是管道，管道的效率高一点 range slice 遍历 用range遍历slice得到的是要给值的拷贝，要对值修改需要用下标访问 nil interface func main() { var data *byte var in interface{} fmt.Println(data, data == nil) // &lt;nil&gt; true fmt.Println(in, in == nil) // &lt;nil&gt; true in = data fmt.Println(in, in == nil) // &lt;nil&gt; false // data 值为 nil，但 in 值不为 nil } in原本是一个nil，最后被赋值了一个nil，nil也是个类型，因此赋值过后in就不是nil了，但他指向的值还是nil（没有十年脑血栓写不出这种代码，少一天都不行） 本来以为是个什么考题，结果都是一些基础知识，就当再复习一遍吧 ","link":"http://www.zerokirin.online/post/golang-ji-chu-yu-fa-ti/"},{"title":"一次完整的请求及改进","content":"准备阶段 当你通过网线或者是WIFI连接到宿舍路由器时，无论进行何种访问，首当其冲的都是要清楚的知道自己所处的网络位置，因此需要初始化IP地址，默认网关，子网掩码，这决定了最基础的，你在当前局域网内的网络位置 DHCP 发现服务 笔记本A的操作系统首先生成一个DHCP发现报文 放入一个UDP报文，目的端口67（DHCP服务器），源端口68（DHCP客户端） UDP报文被放入一个IP数据报，目的IP地址为255.255.255.255（广播地址），源IP地址为0.0.0.0，因为此时A还没有有效的IP地址，所以才要获取呀 IP数据报被放入一个以太网帧，该帧的目的地址是FF:FF:FF:FF:FF:FF（广播地址），源地址是A自己的MAC地址，该帧会被广播到所有与交换机（在这里也就是寝室路由器，它充当了交换机的功能）相连的所有设备 这个以太网帧是第一个由A发送到交换机的帧，该交换机将在所有的出端口把此帧广播出去，包括路由器（寝室路由器的另一个功能）连接的端口 路由器收到该广播帧后进行解析，抽出IP数据报，一看目的地址是广播地址，因此进行处理，根据IP报头中的信息确定是UDP协议，然后抽出UDP，根据UDP端口67到达DHCP服务器，DHCP解析得到DHCP发现报文 服务提供 由于一个局域网下可能会有多个路由器，也会有多个提供DHCP服务的服务器，因此不能直接选定，需要由客户机自己选择DHCP服务器，因此返回的服务提供报文的 目的地址是广播地址 源地址是自身IP地址 还有DHCP服务号，用于最终选择哪个DHCP服务器 yiaddr（你的IP地址），指最终分给客户端的IP地址 其他若干信息，包括租期时间等等 发起请求 A生成一个DHCP请求报文 目的端口67，源端口68 目的IP地址依然是广播地址，源地址是0.0.0.0 以太网帧的目的地址依然是广播地址，源地址是A自己的MAC地址 以太网帧通过交换机广播到所有设备上 路由器收到广播后解析，最终得到DHCP请求报文 以上和发现步骤相同，不同的是DHCP请求报文多带了一个DHCP服务号，这样即使由多个DHCP服务器，依然能确定选择哪个获取IP地址 对应的DHCP服务器将原来已经预分配的yiaddr作为IP地址，将IP地址，子网掩码，默认网关路由器，DNS服务器封装为一个DHCP ACK报文 处理返回 和服务提供步骤相同，不一样的是服务提供报文没有子网掩码等， 将DHCP ACK报文封装进UDP，目的端口是68（客户端） 放入IP数据报，和服务提供步骤一样，源IP地址是自身IP地址，目的地址是广播地址 最后放入一个以太网帧，源地址是路由器MAC，目的地址是电脑A 由于交换机有自学习能力，在发现服务的时候就已经知道对应的MAC地址怎么转发了 返回到A，A记录并更新自己的状态 到这里一个设备已经完整的加入到我们的局域网了 DNS和ARP 踏出请求的第一步就是获取对应的IP地址，这就是DNS查询 将google.com放入一个UDP报文，目的端口53，源端口就是大于1024的随机一个 包装到IP报文中，目的地址是DNS服务器的IP地址，源地址就是自身的IP地址 由于路由表上没有直接对DNS服务的记录，因此会转发到默认网关路由器上 然而A只是知道了默认网关的IP地址，但以太网帧又不知道转到哪，这就需要ARP协议 A生成一个具有目的IP地址（默认网关）的ARP查询报文 把报文放到一个以太网帧中，该帧的目的地址是广播地址，把帧发送给交换机，交换机（一般情况下是路由器的交换部分）将转发给所有设备 每个设备都会解析报文，如果目的地址和自己的地址符合，就准备一个ARP回答报文，包括自己的IP地址和MAC地址 放到以太网帧中，目的地址是A的地址，通过交换机发送给A A收到回答报文后将IP地址和MAC地址保存到ARP表中，下次直接调用就好 这样就有了默认网关的MAC地址 将IP报文包装到以太网帧中，目标地址是默认网关的MAC，经过交换机转发给默认网关 默认网关根据自身的路由表选择将报文转发给下一跳路由器，同时更新目的地址，源地址保持不变，最终目的地址应该就是DNS服务器的MAC地址，路由表的更新由RIP，OSPF等域内协议以及域间协议BGP维护 经过重重转发到了DNS服务器，服务器收到查询报文后找到对应的IP地址，生成一个包括IP地址和google.com的UDP报文 然后就是放入IP报文和以太网帧，一路转发回到最初的起点A 至此A终于知道了IP地址开始正式的访问 TCP和HTTPS 建立HTTP连接 TCP三次握手 A生成一个TCP请求报文，四元组（源地址，目的地址，源端口号，目的端口号）填写好，FLAG为SYN 通过中间的路由器和交换机不断地转发到达目的地，然后被解析，服务端生成一个TCP报文，FLAG为SYN ACK A收到报文后就已经进入连接状态了，对于A来说已经建立连接完成了，下一步就是发送数据，但对于服务端来说还处于同步等待状态，不过它会在下一次收到ACK报文的时候进入连接状态，这个报文可能是已经带有数据的 至此，几乎所有准备工作都已经做完了，终于可以开始请求网页了。 HTTP请求 请求报文 请求行 回车符和换行符就是 请求头 除了Host外都是可选的 空行 除了回车符和换行符以外无其他空格 数据 GET / HTTP/1.1 Host: www.google.com （注意这里是个空行） 将报文放入一个TCP报文，然后依据建立好的TCP连接发送出去 响应报文 google.coom服务器收到80端口的请求，生成响应报文，将请求的web页面内容放入响应体。 状态行 请求成功的状态码就是200，描述 ok 响应头 空行 响应数据，正文部分 HTTP/1.1 200 OK Content-Length: 3059 Server: GWS/2.0 Date: Sat, 11 Jan 2003 02:44:04 GMT Content-Type: text/html Cache-control: private Set-Cookie: PREF=ID=73d4aef52e57bae9:TM=1042253044:LM=1042253044:S=SMCc_HRPCQiqy X9j; expires=Sun, 17-Jan-2038 19:14:07 GMT; path=/; domain=.google.com Connection: keep-alive &lt;html&gt; Hello Google &lt;/html&gt; 响应体经过路由器的重重转发，回到了A，A终于拿到了google.com的内容，浏览器将返回来的响应体进行渲染，渲染出了最终的页面。 TCP四次挥手 连接完成后，当A已经不需要继续请求的时候就会开始回收步骤，结束连接 A发送FIN 服务器收到FIN，返回ACK，此时A已经不能向服务器发送消息了，服务器将继续把没发完的发掉 服务器数据发送完毕后，发送FIN A收到后返回ACK，等待2MSL后如果没收到服务器的消息则释放连接资源，此次链接结束 服务器收到ACK，确定A已经关闭，中断连接 至此，从插入网线开始，一次完整的HTTP请求就结束了 HTTP的改进 HTTP/1.1 上面讲述的是一次完整的HTTP/1.1请求，它相比1.0改进了几个部分 长连接，增加了connection报头，通过设置Keep-Alive可以保持HTTP连接不断开，避免了每次请求结束后都要重复释放，重复建立，提高了效率，当客户端像关闭HTTP连接的时候可以再请求头中携带Connction: false来告知服务器关闭请求。 增加了Host请求头，有时候同一个IP地址上会有不同的主机和或网站，因此可以通过携带不同的Host请求头来区分请求的主机。 身份认证，状态管理和缓存机制 断点续传，通过增加range头，请求资源的一部分，响应206 HTTP/2.0 由于1.x版本都是基于文字的，健壮性和性能都受到了挑战，而且长连接并没有解决TCP阻塞问题，于是有了2.0。 头部压缩 2.0版本是基于二进制的，类似于TCP报头一样，规定好了位数，这样只需要在服务端和客户端同时维护一份静态的数据字典，用来确定请求头，省去了大部分重复字段 服务端推送，在1.x时代，当网页同时包含了style.css和style.js时，会再重复两次请求去获取两个文件，但是2.0中，服务端可以主动推送相关文件，客户端需要获取的时候就无需重复请求了 引入了帧和流的概念，实现了多路复用，抽象一点理解： 每一个帧可看做是一个学生，流可以认为是组（流标识符为帧的属性值），一个班级（一个连接）内学生被分为若干个小组，每一个小组分配不同的具体任务。 HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个小组任务都需要建立一个班级，多个小组任务多个班级，1:1比例 HTTP/1.1 Pipeling解决方式为，若干个小组任务排队串行化单线程处理，后面小组任务等待前面小组任务完成才能获得执行机会，一旦有任务处理超时等，后续任务只能被阻塞，毫无办法，也就是人们常说的线头阻塞，因此并未实际使用 HTTP/2多个小组任务可同时并行（严格意义上是并发）在班级内执行。一旦某个小组任务耗时严重，但不会影响到其它小组任务正常执行 这样自始至终就只有一个TCP连接，控制权完全在HTTP手中，而且也能最大化利用每个TCP连接可以传输的带宽 HTTP2.0对以前的1.x版本也提供了兼容，只需要经过一个二进制分帧层就可以将文本信息转化为对应的二进制头 HTTPS 不管http怎么改进，他始终是明文加密的一种传输方式，因此提出了加密方案——SSL协议，TCP/IP四层协议模型中应该是处于应用层，在OSI七层模型中可以算会话层 SSL的1.0版本有重大的安全缺陷，因此从未公开过，到3.0版本已经证明是成熟的方案了，于是在1999年，SSL3.0被更名成了TLS（传输层安全），TLS1.0实际上就是SSL3.1，这样，当HTTP经过了SSL/TLS协议加密后再传输的方式就被称为HTTPS 注：很多教程里说HTTP2.0要求强制使用HTTPS，其实这并不是2.0的要求，它只是规定了HTTP的协议，真正要求HTTPS的是浏览器 至此，我们的这次请求就由HTTP1.1更换为了HTTPS2.0 对于TLS的详解，请见下章 ","link":"http://www.zerokirin.online/post/yi-ci-wan-zheng-de-qing-qiu-ji-gai-jin/"},{"title":"传输层","content":"提供逻辑上进程间通信的功能，使应用看起来像是再两个传输层实体之间有一条端到端的逻辑通信信道 主要协议 UDP和TCP 用户数据报协议 UDP（User Datagram Protocol） 是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 常用于游戏，音视频流媒体等，对数据完整性要求不是很高，但是对实时性有比较高要求的传输 传输控制协议 TCP（Transmission Control Protocol） 是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 由于有拥塞控制，流量控制，及时性必然不如UDP，但可靠 UDP(User Datagram Protocol) 用户数据报协议 伪首部 从IP首部提取出源IP地址和目的IP地址，然后是0x00，然后是IP首部中协议字段的值，UDP是17，然后是UDP的长度，总共12字节。 伪首部仅用作校验和，仅在发送和接收的时候被临时拼出来，计算出校验和后就抛弃，将校验和填入首部 源端口（可选） UDP是无序应答的，因此没有必要记住源端口 目的端口 长度 就是UDP长度，和伪首部中的一样，最小值是8字节，因为首部已经占了8字节了 由于IP数据包的最大值不能超过64K字节（只有两个字节用来标识长度，2^16= 64K），所以最大长度不能超过（65,535 − 8字节UDP报头 − 20字节） 校验和（可选） 若不需要则全部填充0 整体结构，图源维基百科 TCP（Transmission Control Protocol）传输控制协议 TCP结构 序号（sequence number）：为每一个字节都编上序号。这里的值代表本报文发送的数据的第一个字节的序号。例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号（acknowledgement number）：期望收到的下一个报文段的起始序号，也即已经收到的数据的字节长度加1。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 保留字段：6bits，保留今后使用，目前置0处理。（但在RFC 3168和RFC 3540中增加了三个标识符，保留字段只剩3bits） 标识符 URG：紧急比特，1bit，当 URG=1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据) ACK：确认比特，1bit，只有当 ACK=1时确认号字段才有效。当 ACK=0 时，确认号无效 PSH：推送比特，1bit，接收方 TCP 收到推送比特置1的报文段，就尽快地交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付 RST：复位比特，1bit，当RST=1时，表明TCP连接中出现严重差错(如由于主机崩溃或其他原因)，必须释放连接，然后再重新建立运输连接 SYN：同步比特，1bit，同步比特 SYN 置为 1，就表示这是一个连接请求或连接接受报文 FIN：终止比特，1bit，用来释放一个连接。当FIN=1 时，表明此报文段的发送端的数据已发送完毕，并要求释放运输连接 窗口（WIN）：窗口字段用来控制对方发送的数据量，单位为字节。TCP 连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上限。 校验和（checksum）：生成12字节的伪首部然后计算出来 紧急指针：紧急指针指出在本报文段中的紧急数据的最后一个字节的序号。 选项字段：最多40字节。每个选项的开始是1字节的kind字段，说明选项的类型。 0：选项表结束（1字节） 1：无操作（1字节）用于选项字段之间的字边界对齐。 2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。 3：窗口扩大因子（3字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。 4：sackOK—发送端支持并同意使用SACK选项。 5：SACK实际工作的选项。 8：时间戳（10字节，TCP Timestamps Option，TSopt） 发送端的时间戳（Timestamp Value field，TSval，4字节） 时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节） TCP连接过程 三次握手 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个随机的初始序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个随机的初始序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 为什么是三次挥手 通俗但不是根本原因的解释： A--&gt;B--&gt;A--&gt;B这样传三次能保证A有发有收，B也有发有收。多一次浪费少一次不够。 详细版本，来源于知乎问题下的回答TCP 为什么是三次握手，而不是两次或四次？ - 知乎 (zhihu.com)）： TCP可靠传输的精髓在于，由操作系统随机的选取两个32位长的初始序列号（Initial Sequence Number） 假设A的初始序列号为1000，以该序列号为原点对将要发送的每个字节编号，然后把自己的初始序列号（ISN）发送个B，让B有个心理准备，什么编号的数据才是合法的，可靠的，同时B还要对A的数据进行确认，如果A收到的确认号为2001，则证明字节编号1001-2000，一共1000个字节的数据已经被完整接受 （三次握手的过程中，初始x为1000，B的确认码是x+1=1001，所以真正发送的数据的第一个编号是1001，等B收到数据后返回给A的确认码是2001，代表着期望收到2001数据，也就是说，2000以前的数据已经完整收到了） 所以原因是为了让双方创建好初始号ISN，完整的流程应该是四步： A 发送同步信号SYN + A's Initial sequence number A --&gt; B SYN my sequence number is X 第一次握手SYN为1，表示请你记录下我的ISN B 确认收到A的同步信号，并记录 A's ISN 到本地，命名 B's ACK sequence number A &lt;-- B ACK your sequence number is X 第二次握手ACK为1，表示收到了 B发送同步信号SYN + B's Initial sequence number A &lt;-- B SYN my sequence number is Y 第三次握手SYN为1，表示也请你记录下我的ISN A确认收到B的同步信号，并记录 B's ISN 到本地，命名 A's ACK sequence number A --&gt; B ACK your sequence number is Y 第四次握手ACK为1，表示我也受到了你的ISN了，我要开始传数据了哦 很显然2和3这两个步骤可以合并，**只需要三次握手，**可以提高连接的速度与效率 最最根本的原因就是，三次通信过程是能够确保可靠传输的理论最小值，所以三次握手不是TCP的要求，而是为了满足在IP这种不可靠通信上建立可靠通信 三次握手中丢包了 第一个包，A--&gt;B的带有SYN的包没了 A会周期性超时重传，直到B的确认，毕竟是追女孩子，要勤快一点 第二个，B--&gt;A的带有ACK+SYN的包没了 B会周期性重传，直到A的确认，女孩子同意了，怎么男的不回消息了？？？不是你先撩我的？？？我再问问 第三个包，A--&gt;B带有ACK的包没了 A知道B同意了就变为了Established，但B很好奇A怎么什么反应都没有 如果A倒头就睡了打算明天传数据，B就会一直重传问A到底啥情况（对于B来说和 2 情况一样） 如果A直接给B发送了数据，B会自动更改为Established状态并接受状态，原来大猪蹄子只是睡着了没发晚安，不是渣男 如果B要给A发数据是发不了的，毕竟我同意了你竟然一点反应都没有，老娘一肚子火怎么可能跟你说正事，还是会一直重传ACK+SYN，你给老娘个答复！ 到这一步A--&gt;B的ACK必须被B接受才行，这代表双方都承认了关系的建立 现实情况 客户端发送的请求如果在网络中滞留，那么客户端要很长一段时间才能收到服务端的反馈，客户端等待时间过长后会超时重传，但是这个请求最后还是会到达服务器，如果没有保存两个ISN，那么就无法确认数据包是传输中还是建立连接的包，那么就会打开两个连接。如果有三次握手，双方保存了ISN，则发现错误后直接抛弃就好。 四次挥手 ack，seq自始至终的含义是相同的，无需解释，ACK咋建立连接后全都是1，无需分析 A发送释放连接的报文，FIN=1 B收到后还可以继续向A发送数据，但A不能向B发送数据 当B决定终止时向A发送释放连接报文，FIN=1 A收到后发出确认，进入TIME-WAIT状态，等待2个MSL（Maximum Segment Lifetime）时长后释放连接 B收到A的确认后释放连接 Time-Wait A收到B的FIN报文后不是直接close而是先进入TIME-WAIT状态，等待两个MSL的时间，原因有两个： 如果最后一个A--&gt;B的包丢了，那么对于A来说，A时刻+1MSL时还没到达B，B就应该重传了，B重传的时长最多是1MSL，因此A最多等待2MSL就能收到B的重传报文，如果没收到那就证明B已经ok了 让本链接持续时间内所产生的所有报文都从网络消失掉，使下一个新的连接创建的时候不会出现旧的报文 TCP可靠传输 TCP使用重传来实现可靠传输：如果一个已经发送的报文在超时时间内没有收到确认报文，则重传报文 一个报文的往返时间为RTT（Round Trip Time） RTTs=(1-a)*(RTTs)+a*RTT （并未被广泛使用，后来发明了新的算法）a一般为0.8-0.9 超时重传的超时时间为RTO（Restransmission TimeOut）RTO=RTTs+4*RTTd RTO不能小于RTT否则会大量的重传 RTO不能太大，否则延迟会变得很大 因此RTO应该略大于RTT Jacobson / Karels 算法 前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看RFC6289）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思） SRTT = S RTT + α ( RTT – S RTT ) —— 计算平滑RTT DevRTT = (1-β *)* ** DevRTT + β (| RTT-SRTT |) ——计算平滑RTT和真实的差距（加权移动平均） RTO= µ * SRTT + ∂ *DevRTT —— 神一样的公式 （其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中（Linux的源代码在：tcp_rtt_estimator）。 ——来源TCP 的那些事儿（下） | 酷 壳 - CoolShell TCP分段 这里引入两个概念 MTU（Maximum Transmission Unit）最大传输单元，以太网的MTU为1500字节，因此IP包只有1480 MSS（Maximum Segment Size）最大分段大小，这是一个TCP协议中的定义，MSS应该等于MTU-40，也就是1460，但若是双方未指定MSS大小的话，默认情况下MSS大小是536字节，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，网络中不只有以太网，还有很多其他连接方式，而576减去IP头的20个字节和TCP头的20个字节就是536）。 为什么要主动引入MSS呢，看起来不是和MTU差不多吗？ 其实是因为网络层数据包对IP包来说是透明的，像UDP没有引入MSS，且不会主动分段的话，直接交由IP封装的结果就是这样： 等接收方拿到第二个包的时候直接就扔了，也就是UDP不讲究。。。 但是对于可靠传输的TCP，这是完全不能忍受的，因此TCP会自己分段，保证自己发出的时候就不大于IP的MTU，别让IP帮我分 这样第二个包也会被接收端正确解析 TCP滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过TCP报文中的WIN字段告知发送方应该发送多大的数据，发送方收到报文后设置自己的窗口大小。 发送窗口 发送窗口内的字节都允许被发送，如果发送窗口左边的字节已经发送并且收到了确认（ack），那么就讲发送窗口向右滑动一定距离，直到左边第一个没被确认的字节为止。 接收窗口 接收窗口内的字节都允许被接受，接收窗口只会对最后一个按序到达的字节进行确认，确认后向右滑动接收窗口。 例如：接收窗口已经收到了字节{31，34，35...}，其中{31}是按序到达的，因此只对31进行确认，同时向右滑动，当发送方接收到31的确认时，就知道31号之前的都已经被正确接受了 Zero Window 如果某种原因导致接收端返回的确认报文中WIN=0，那么发送端就不会发送数据了，等到接收方的WIN腾出来了应该怎么告诉发送端呢？ 这就是ZWP（Zero Window Probe），发送端在窗口变为0后会发送ZWP包给接收方，让接收方来重新设置WIN大小，具体重传次数和间隔看实现方案。如果多次仍为0，就可以直接RST Silly Window Syndrome 翻译成中文就是“愚蠢窗口综合征”，其实也就是TCP的流量控制部分。如果接收方繁忙，每次都只能腾出一两个字节的WIN，但发送方仍会义无反顾地发送数据，但这样很浪费空间，一两个字节要经过TCP包，IP包的封装，仅仅是报文头部就最少有40个字节 一次传输肯定是越接近MTU最好，这样对带宽的利用率最大，不会浪费，因此为了避免数据包太小，那就憋着，等窗口够大了再发送数据，类似于大巴车等人满了再发车一个道理。发送方和接收方都有解决办法： 接收端： 使用David D Clark’s方案。如果收到的数据或者自己处理太慢了，导致WIN小于某个值，就直接窗口0，啥也别发了，等缓过来，数据大于等于MSS，或者接受buffer腾出一半空间了再设置正常的窗口大小就好 发送端： 使用著名的纳格算法，本质思路也是延迟等待。 if有新資料要傳送 if訊窗大小&gt;= MSS and可傳送的資料&gt;= MSS 立刻傳送完整MSS大小的segment else if管線中有尚未確認的資料 在下一個確認（ACK）封包收到前，將資料排進緩衝區佇列 else 立即傳送資料 有两个条件： 窗口大小&gt;=MSS 且 数据大小&gt;=MSS，立刻发送数据段（Segment） 收到了之前发送的未确认数据的ACK回包，立刻发送数据 不过要注意，纳格算法不能和TCP延迟确认同时开启，TCP延迟确认是将多个ACK回包合并成一个，节约利用资源（毕竟首部太大了），当两者同时开启的时候，一个憋着ACK不放，一个ACK不来不发，两人活生生就憋死了。 另外，纳格算法是默认打开的，但是对于SSH，telnet这种交互性程序，发送的都是小包，就需要主动关闭纳格算法。 TCP拥塞控制 主要有四个阶段： 慢启动（slow start） 拥塞避免（Congestion Avoidance） 拥塞发生 快速恢复（Fast Recovery） 慢启动 连接建立好后初始化一个cwnd（congestion window）=1，表示可以传输一个MSS大小的数据 每当收到一个ACK，cwnd++；线性上升（其实是指数增长） 2的结果是，每当过了一个RTT后，cwnd会刚好变为cwnd*2，因为第一次是一个ACK，所以增加一次，第二次是两个ACK所以增加两次 还有一个ssthresh（slow start threshold）慢启动阈值，cwnd&gt;=ssthresh后会进入拥塞避免阶段 拥塞避免 收到一个ACK时，cwnd = cwnd+1/cwnd；（其实是线性增长） 1的结果是，每当过了一个RTT后，cwnd =cwnd+1；因为cwnd正好等于可以发送的MSS数量大小，因此ACK的数量就等于cwnd 拥塞发生 当丢包的时候，有两种方法 超时重传，也就是超过RTO的时长就重传，同时进行拥塞控制 sshthresh = cwnd/2 cwnd重置为1 进入慢启动过程 快重传（Fast Retransmit），收到三个重复的ACK时就重传，无需等到RTO超时 TCP Tahoe：方法和超时一样 TCP Reno： cwnd = cwnd/2 sshthresh = cwnd 进入快速恢复算法 快速恢复 TCP Reno中定义的快速恢复算法是这样的： cwnd = sshthresh +3（意思是确认有三个数据包收到了） 重传这个重复的ACK指定的数据包 如果还是收到那个重复的ACK，cwnd = cwnd+1 如果收到了新的ACK，那么cwnd = sshthresh 进入拥塞避免状态 然而如果不止重复ACK丢失的话，仅仅重传重复ACK，其他的还是会触发RTO超时重传，但是目前所说的所有方法都没办法知道到底是丢了几个数据包，除非使用SACK字段，但这需要通信双方都支持，基于SACK也有新的FACK算法进行拥塞控制，但若是不支持SACK就没办法了，因此提出了一个新的 TCP New Reno 重传重复的数据包，根据返回的ack和已经发送的seq+长度进行对比，就可以推理出是否有其他包丢失 比如说发送方的seq = 1，长度20，正确的ack应该是21，如果此时收到了三个ack=5，如果说只有5号丢了，那第5号数据发送过去后返回的ack应该时21，如果返回是11，则证明11也丢了，甚至时12，13等等 与正确的ack不匹配的被称作Partial ACK，当发送方接收到Partial ACK后会一直重传没有被ack的第一个包，直到再也收不到Partial ACK，结束了快速恢复状态 进入拥塞避免阶段 本文大量引用他人文章，仅作个人笔记使用 [CS-Notes (gitee.io)](http://cyc2018.gitee.io/cs-notes/#/notes/计算机网络 - 传输层) TCP 的那些事儿（下） | 酷 壳 - CoolShell 万字长文 | 23 个问题 TCP 疑难杂症全解析 - SegmentFault 思否 传输控制协议 - 维基百科，自由的百科全书 (wikipedia.org) 为什么 TCP/IP 协议会拆分数据 - 面向信仰编程 (draveness.me) ","link":"http://www.zerokirin.online/post/chuan-shu-ceng/"},{"title":"网络层","content":"IP协议（Internet Protocol） 数据报格式 版本：ipv4和ipv6 首部长度：一共4位，最多只有15，单位是4字节大小，数据报固定首部长度有20个字节，因此首部长度最短为5 区分服务：一般不使用 总长度：定义了报文的总长度，单位是字节，最短为固定首部长度（20） 标识：唯一的标识一个报文的所有分片，因为分片不一定按顺序到达，重组的时候需要知道顺序 标志：三个bit分别用于： 位0：保留，必须为0； 位1：禁止分片（Don’t Fragment，DF），当DF=0时才允许分片； 位2：更多分片（More Fragment，MF），MF=1代表后面还有分片，MF=0 代表已经是最后一个分片。 如果DF标志被设置为1，但路由要求必须分片报文，此报文会被丢弃。这个标志可被用于发往没有能力组装分片的主机。 片偏移：单位为8字节，当有分片时，指示该分片相对于报文起始地址的偏移量（对于最后一个分片的报文，由于片偏移不为零，尽管MF字段是0，依然能够确定这是个分片的数据包，而不是不分片数据包(MF=0)） 生存时间：定义的是该数据包在互联网中存在的时长，以秒为单位，但后来被用作了跳数计算器，每经历一次转发就将该字段减一，当字段为0时，不在向下跳转，最大值255 协议：指出数据应该交给哪个协议进行处理，例如ICMP，TCP，UDP 首部校验和：只检查首部，每一跳都要重新计算（最起码TTL发生了改变，偏移量和标志位也有可能变化），然后对比，不相同就丢弃 源地址、目标地址：一共32位 可选字段：不常用，1-40字节不等，参考维基百科上的表格 字段 长度（位） 描述 备份 1 当此选项需要被备份到所有分片中时，设为1。 类 2 常规的选项类别，0为“控制”，2为“查错和措施”，1和3保留。 数字 5 指明一个选项。 长度 8 指明整个选项的长度，对于简单的选项此字段可能不存在。 数据 可变 选项相关数据，对于简单的选项此字段可能不存在。 填充：记得最上面的首部长度吗，当有可选字段的时候，首部长度就一定大于20字节了，而首部长度的单位是4字节，因此当可选字段不是4的整数倍的时候，需要填充为EOL（选项列表结束，0x00） IP地址编址方式 IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 分类 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 子网划分 可以看出，两级 IP 地址 不够灵活, 对 IP 地址空间的利用率比较低。如, C 类地址的局域网最多分配 254 个主机号, B 类地址的局域网最多分配 65534 个主机号。如果有个单位有 255 台主机，则只能为其分配一个 B 类地址的 网络号。这样就会浪费很多 IP 地址。 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 无分类 无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 网络地址和广播地址 其实就是特殊的主机地址，由于IP = 网络号+主机号 主机号全为0的时候就是网络地址 全为1的时候就是广播地址 举例： 一个主机的IP地址是202.112.14.137，掩码是255.255.255.224，要求计算这个主机所在网络的网络地址和广播地址 255.255.255.224 转二进制： 11111111 11111111 11111111 11100000 则IP地址的前27位是网络号，后5位是主机号 202.112.14.137转二进制： 11001010 01110000 00001110 100 01001 网络号 主机号 广播地址是11001010 01110000 00001110 100 11111 即202.112.14.159 网络地址是11001010 01110000 00001110 100 00000 即202.112.14.128 地址解析协议ARP（Address Resolution Protocol） 将IP地址转换为MAC地址的协议 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 维基百科中说的更详细一些 1.当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可。 2.如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个广播（ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？” 3.网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是00-BB-00-62-C2-02”，此回应以单播方式。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP高速缓存（ARP cache），下次再向主机B发送信息时，直接从ARP缓存表里查找就可。 网际控制报文协议ICMP（Internet Control Message Protocol） 它用于网际协议（IP）中发送控制消息，提供可能发生在通信环境中的各种问题反馈。通过这些信息，使管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。 ——维基百科 ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 常见应用 Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 路由器的结构 路由器从功能上可以划分为：路由选择和分组转发。 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。 路由转发流程 提取出目的主机的IP地址D，然后得到网络地址N 若N是此路由器直接连着的地址，直接解析，否则就是间接交付 间接交付 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 路由选择协议 用于调整路由表的可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP ","link":"http://www.zerokirin.online/post/wang-luo-ceng/"},{"title":"GMP模型简介","content":" [典藏版] Golang 调度器 GMP 原理与调度全分析 | Go 技术论坛 (learnku.com) 大量文字和图片来源于上文，以下仅为个人理解转述，仅作笔记使用 进程&amp;线程 根本区别： 进程是操作系统资源分配的基本单位 线程是处理器任务调度和执行的基本单位 资源开销： 每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销 线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小 包含关系： 线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 内存分配： 同一进程的线程共享本进程的地址空间和资源 而进程之间的地址空间和资源是相互独立的 影响关系： 一个进程崩溃后，在保护模式下不会对其他进程产生影响 一个线程崩溃整个进程都死掉，所以多进程要比多线程健壮 内核态&amp;用户态 简单的说，用户的应用程序运行在用户态，内核程序运行在内核态，任何资源调度都需要进入内核态执行 详细一点，以32位linux操作系统为例，2^32 = 4G，所以每个进程最多可以访问4G的内存空间（虚拟内存），操作系统将高地址的1G空间分配给了内核态，低地址的3G分配给用户态，又由于内核操作是唯一的，不随用户程序的不同而改变，因此可以说内核态的空间是所有进程共享的，而用户态的空间属于进程独有（实际上大家都是访问的虚拟地址，只不过对于内核态的代码始终映射到了同一空间，用户态就完全随机了） 再详细一点，intel提供了R0-R3一共四个等级的权限，而linux使用了R0和R3两个等级作为区分，R3最低，应用程序运行在3级的时候就是用户态，运行在0级的时候就是内核态，用户态到内核态一共有三种转换方式： 系统调用（主动） 使用系统提供的服务，比如请求键盘输入，这时会从用户态切换到内核态，因为用户态的程序无法调用系统资源，任何资源调用都是由内核态程序完成的 本质就是用户程序向系统发出了一个中断信号int 80h，通过中断信号告诉操作系统来将应用程序调入内核态 异常（被动） 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 外围设备中断（被动） 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 协程 线程的优缺点 缺点 即便他的资源依赖进程，上下文切换的时候无需切换内存空间，但上文提到过，线程是操作系统任务调度的最小资源，也就意味着线程的切换仍然是内核操作，这就会使应用程序频繁的处于用户态内核态的切换中，这中间无疑是对cpu的浪费 创建一个线程需要8MB大小的空间（ubuntu18.04默认的线程栈大小），一千个线程就是8g的空间，非常夸张 优点 系统调度的最小单元，意味着它是真正的并行执行，可以同时运行在多个不同的cpu核心上 协程的概念 根据上文可以看到多线程模型在运算效率上很高，因为它可以充分利用多核优势，但是每次线程的切换都需要内核介入，就导致在某些场景下大量的资源被浪费在程序状态的转换上，有没有可能让内核不介入线程的切换呢？ 协程应运而生，也可以说它是用户态的线程，将线程调度这一概念放到了用户态去做，让用户态的程序自己控制调度程序，避免频繁切换。 协程的执行则是通过绑定到不同的线程去执行，因为只有线程才是执行的最小单位，因此怎么将线程和协程绑定能最大化利用资源则是重中之重 golang中通过提出了goroutine来实现协程这个概念，用go scheduler在用户态做调度。 协程和线程主要区别： 线程是由操作系统调度的，是抢占式的 协程是协作式的，执行完毕由调度器控制自动让出资源 协程说到底还是绑定到线程执行的，因此绑定到同一个线程下的协程只能是串行，无法做到并行处理 GMP模型 提出三个概念 G goroutine 协程 M thread 线程 P processor 它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。 （这图做的是真好，一目了然，都不需要讲什么了） P的数量 通过GOMAXPROCS这个变量来控制整个程序中P的数量，这是在调度器初始化的时候就确定好的，P不随程序运行改变，默认值是cpu核心数，因为整个模型中，P通过绑定M去执行操作，而M也就是线程，最多可以并行执行的数量就是cpu核心数，因此这样可以最大化利用资源，减少浪费 M的数量 由于每个P都必须绑定一个M，通过绑定的M去执行P上的G，因此M的数量至少等于P（休眠状态另算） 当M被阻塞时，P上的G就无法继续执行，此时就会创造一个新的M，因此通常来说M的数量要大于P 调度器初始化的过程 特殊的 M0 和 G0 M0 M0 是启动程序后的编号为 0 的主线程，相当于程序的起点，企业的创始人，在这里初始化了调度器，然后启动第一个G（也就是主函数main），在这后M0就和其他的M一样了，从创始人沦为打工仔 G0 G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，相当于一个总经理把任务G指派给M执行，G0 不指向任何可执行的函数，他自己不干活，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 一个程序运行的全过程 runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。 调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。 示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。 启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。 G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境 M 运行 G G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。 一个goroutine的执行顺序 从上图我们可以分析出几个结论： 有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中； G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行； 一个 M 调度 G 执行的过程是一个循环机制； 当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P； 当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 完整的调度过程全解析 （这图画的真的绝了，看图说话吧） P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 go func() 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。 G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2（偷取其他队列的G直到没有G），从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。 假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。 G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行负载均衡 (把 P1 中本地队列中前一半的 G，还有新创建 G 转移到全局队列) 这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。 G2 创建 G8 时，P1 的本地队列未满（挪走了前一半去全局了），所以 G8 会被加入到 P1 的本地队列。 规定：在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。 假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程**（没有 G 但为运行状态的线程，不断寻找 G）**。 M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：findrunnable()）。M2 从全局队列取的 G 数量符合下面的公式： n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2)) 从全局队列取出差不多平均给每个M-P的数量的G，，不要拿太多，给其他M-P留一些 假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。 假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。 全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。 G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。 为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。 假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M&gt;=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断： 如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定 否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。 本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。 G8 创建了 G9，假如 G8 进行了非阻塞系统调用。 M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。 ","link":"http://www.zerokirin.online/post/gmp-mo-xing-jian-jie/"},{"title":"go语法基础巩固（channel）","content":"channel分为有缓冲和无缓冲 channel有两种定义方式 var c1 = make(chan int) //无缓冲 var c2 = make(chan int,n) //有缓冲 close(c2) 对无缓冲的c1的操作是同步的 必须同时存在接收者和发送者才会执行，否则会阻塞 对有缓冲的c2是存在异步操作的 缓冲区满了则无法继续写入，进入阻塞，未满之前不阻塞程序 缓冲区空了则无法读取，进入阻塞，没有空之前不阻塞 close关闭一个channel 不能对一个关闭了的，或者本来就未通过make()初始化的channel执行关闭操作，会panic 关闭channel在某种角度上讲只是不允许继续写入，对于已经存入缓冲的数据还是可以读取的 func main() { c1 := make(chan int, 5) for i := 0; i &lt; 5; i++ { c1 &lt;- i } close(c1) for i := 0; i &lt; 6; i++ { m, ok := &lt;-c1 fmt.Println(m, ok) } } //结果： //0 true //1 true //2 true //3 true //4 true //0 false， 只有到这一步才因为没有数据而返回了默认的零值 总结一下： 操作\\对象 nil channel closed channel not nil, not closed channel close panic panic 正常关闭 读 &lt;- ch 阻塞 读到对应类型的零值 阻塞或正常读取数据。缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞 写 ch &lt;- 阻塞 panic 阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞 channel的实现原理 深度解密Go语言之channel - SegmentFault 思否 以下内容均为个人转述总结，仅作笔记使用，参考出处如上 channel结构 type hchan struct { // chan 里元素数量 qcount uint // chan 底层循环数组的长度 dataqsiz uint // 指向底层循环数组的指针 // 只针对有缓冲的 channel buf unsafe.Pointer // chan 中元素大小 elemsize uint16 // chan 是否被关闭的标志 closed uint32 // chan 中元素类型 elemtype *_type // element type // 已发送元素在循环数组中的索引 sendx uint // send index // 已接收元素在循环数组中的索引 recvx uint // receive index // 等待接收的 goroutine 队列 recvq waitq // list of recv waiters // 等待发送的 goroutine 队列 sendq waitq // list of send waiters // 保护 hchan 中所有字段 lock mutex } type waitq struct { first *sudog //对goroutine的封装 last *sudog //对goroutine的封装 } 和map一样，底层实际上是一个hchan结构体，调用了makechan()来创建channel，根据创建的时候是否有缓冲决定了buf指针是否有意义，sendx和recvx均为缓冲数组服务 func goroutine(a &lt;-chan int) { val := &lt;- a fmt.Println(&quot;received data: &quot;, val) return } func main(){ var ch = make(chan int, 10) go goroutine(ch) //隐式转换为只读channel go goroutine(ch) //隐式转换为只读channel time.Sleep(time.Second) } 上面go出去了两个读取ch的goroutine，所以此时接收队列应该是两个，结构如下（图源参考文章） 可以看到G1，G2其实就是个sudog结构的双向循环列表，recvq分别通过first和last指向了头尾 发送队列也是个wait结构，因此和接收队列几乎一致 写入 先判断是否有接收队列，如果有则直接拷贝到接收队列中，不复制到buf 对于有缓冲的channel，若还有空间，则将数据拷贝到buf中，同时更改相应的index 若没有空间或非缓冲则阻塞，然后创建一个sudog（sudog实际上是goroutine的封装，因此新的sudog实际就是包括了执行函数的这个goroutine 将新的sudog加入发送队列，当前goroutine被系统挂起，等待接受进程唤醒 读取 先判断是否有缓冲，若无缓冲则直接从发送者的栈拷贝到接收者的栈，发送者是通过遍历sendq找到的 若有缓冲则从buf所指的空间拷贝数据（只要不为空就会一直有数据写入，不会有主动寻找sendq的时机） 若没有数据则将自己挂起到接收队列等待被发送进程找到，也是创建一个sudog ","link":"http://www.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-channel/"},{"title":"go语法基础巩固（string）","content":"字符串不能用下标访问 var str = &quot;Hello, 世界&quot; 在golang中，字符串几乎一定是utf-8编码的，而在utf-8中，中文有些是3个字节，有些是4个字节，英文是一个字节，而字符串这个类型的本质其实是一个字符slice，对str遍历可得 func main() { var str = &quot;Hello, 世界&quot; for i := 0; i &lt; len(str); i++ { fmt.Printf(&quot;%c &quot;, str[i]) } fmt.Println() for i := 0; i &lt; len(str); i++ { fmt.Printf(&quot;%q &quot;, str[i]) } fmt.Println() for i := 0; i &lt; len(str); i++ { fmt.Printf(&quot;%v &quot;, str[i]) } } 结果是 H e l l o , ä ¸  ç   'H' 'e' 'l' 'l' 'o' ',' ' ' 'ä' '¸' '\\u0096' 'ç' '\\u0095' '\\u008c' 72 101 108 108 111 44 32 228 184 150 231 149 140 根据v和q的值可以看到，对于能解析的会被q解析为字符，解析不了的直接输出utf-8编码过后的结果，因此无法直接通过下标访问，但是可以将字符串转为rune数组 var str = &quot;Hello, 世界&quot; fmt.Println(string([]rune(str[7:]))) //结果是 世界 go中对rune的定义是 type rune = int32 在转为rune数组的过程中，会将单个字符的全部字节放入（32位正好是utf-8的可变字符范围) ","link":"http://www.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-string/"},{"title":"go语法基础巩固（map）","content":" map - 《Go 语言问题集(Go Questions)》 - 书栈网 · BookStack map遍历是无序的 参考大佬的文章,本文仅仅是用我个人语言总结了一遍，仅作个人笔记使用 map的结构 type hmap struct { // 元素个数，调用 len(map) 时，直接返回此值 count int flags uint8 // buckets 的对数 log_2 B uint8 // overflow 的 bucket 近似数 noverflow uint16 // 计算 key 的哈希的时候会传入哈希函数 hash0 uint32 // 指向 buckets 数组，大小为 2^B // 如果元素个数为0，就为 nil buckets unsafe.Pointer // 扩容的时候，buckets 长度会是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 指示扩容进度，小于此地址的 buckets 迁移完成 nevacuate uintptr extra *mapextra // optional fields } 首先是经过hash函数（由编译阶段确定是什么hash函数）获得了key，将k-v存在一个bucket（实际上是一个指向bmap的指针）中，bucket个数是2^B hmap[hash(key)]-&gt; bucket[2^B]-&gt; bmap[0:8] 每个bmap最多可以存储8对hash后结果相同的数据，因此还要再bmap中查找一边key，才能找到真正对应的值，属于时间换空间，经过编译器处理后bmap结构如下，当8个不够用时，overflow会指向新的一个bmap type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } 一般来说好的hash算法会尽量让每个bucket被平均分配，而不是一个超过太多，另一个是空的，但是当数据太多一样会发生拥挤，因此有一个指标叫做装载因子 loadFactor := count / (2^B) 两个条件都会触发 装载因子大于6.5的时候 当overflow的bucket过多（bmap并不真正拥有overflow，overflow实际上是hmap中的结构） B&lt;15时，overflow的bucket数量大于2^B B&gt;=15时，overflow的bucket数量大于2^15 此时会触发map的扩容，两种情况不一样 条件一说明虽然很均匀，但是大家都快装满了，因此直接B+1解决问题 有两种可能 不停的插入删除大量数据导致创建了过多的bucket，导致每个bucket都很空，但是都指向了一堆新的bucket，这时候就创建一个新的bucket将旧的bucket全部集中起来 极端情况：hash(key)都一样，怎么移动都没用，此时大家都集中在同一个bmap里面，就会创建很多bucket，但此时hash表已经退化为链表了 由于扩容的时候是不停的key-value的搬迁，因此非常影响性能，所以go是渐进式搬迁，每次插入修改删除key的时候移动两个，旧的bucket并没有真正被搬迁，而是挂载到了hmap的oldbuckets字段，直到完全迁移结束 如果是条件一则bucket变为两倍，如果条件二则不增加 为什么无序？ 因为每次遍历map的时候实际上是遍历bucket，当B加一后，原来后B位的key变化了，多了一位，因此会分配到两个不一样的bucket中（但是同样可能不变），所以无法控制具体情况，自然就是无序的 特殊情况：硬编码map 对于固定的map，不修改则完全不变，但是会给不熟悉的人带来疑惑，所以从go1.0 开始，遍历的时候是随机选择一个bucket中的cell（8个之一）开始，完全杜绝有序情况。 ","link":"http://www.zerokirin.online/post/go-yu-fa-ji-chu-gong-gu-map/"}]}